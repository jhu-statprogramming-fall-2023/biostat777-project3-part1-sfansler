[{"path":"/articles/example-analysis.html","id":"load-the-survival-package-and-other-necessary-packages-for-analysis","dir":"Articles","previous_headings":"","what":"Load the survival package and other necessary packages for analysis","title":"Example Analysis","text":"","code":"library(survival) library(ggsurvfit) #> Warning: package 'ggsurvfit' was built under R version 4.3.2 #> Loading required package: ggplot2 library(tidyverse) #> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── #> ✔ dplyr     1.1.2     ✔ readr     2.1.4 #> ✔ forcats   1.0.0     ✔ stringr   1.5.0 #> ✔ lubridate 1.9.2     ✔ tibble    3.2.1 #> ✔ purrr     1.0.2     ✔ tidyr     1.3.0 #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() #> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(tidytuesdayR) #> Warning: package 'tidytuesdayR' was built under R version 4.3.2"},{"path":"/articles/example-analysis.html","id":"read-the-data","dir":"Articles","previous_headings":"","what":"Read the data","title":"Example Analysis","text":"dataset chose use TidyTuesday powerlifting dataset 2019. dataset includes information powerlifters specific competitions. includes competitor’s name, sex, age, age class, event, equipment used, date competition, bodyweight kg, best three lifts events (squat, bench press, deadlift) kg. question aim answer whether age bodyweight class impact amount time since competitor’s first recorded competition takes male competitor reach “overall international elite” status, defined United States Powerlifting Association. data came TidyTuesday podcast. original data well data dictionary can found https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-10-08","code":"create_dir <- function(){   setwd(dirname(getwd()))   data_dir <- \"data\"      if(!file.exists(data_dir)){     dir.create(data_dir)   } }  save_data <- function(){   data_path <- file.path(\"data\", \"tuesdata.rds\")      if(!file.exists(data_path)){     data <- tidytuesdayR::tt_load('2019-10-08')     saveRDS(data, data_path)   } }  load_data <- function(){   create_dir()   save_data()   data_path <- file.path(\"data\", \"tuesdata.rds\")   data <- readRDS(data_path)   return(data) }  ipf_lifts = load_data()[[1]]"},{"path":"/articles/example-analysis.html","id":"analysis","dir":"Articles","previous_headings":"","what":"Analysis","title":"Example Analysis","text":"Overall, Kaplan-Meier plot shows time since first competition increases, probability getting “international elite” status decreases. Specifically, 3000 days first competition, probability reaching “international elite” status drops 0.5. see whether age bodyweight affect time international elite status reached, ran Cox proportional hazards model using time international elite status outcome age bodyweight predictors. found age significantly increases time international elite status reached, adjusting bodyweight. Functions used dplyr::select dplyr::mutate dplyr::filter dplyr::group_by dplyr::summarize forcats::fct_relevel purrr::compact purrr::purrr::every ggplot2::geom_violin ggplot2::geom_boxplot ggplot2::geom_point ggplot2::facet_wrap survival::survfit survival::coxph","code":"#Converting kgs to lbs, only selecting necessary variables, only including men who competed in all three events ipf_lifts_lbs = ipf_lifts %>%   mutate(bodyweight_lb = 2.205*bodyweight_kg,          squat_lb = 2.205*best3squat_kg,          bench_lb = 2.205*best3bench_kg,          deadlift_lb = 2.205*best3deadlift_kg) %>%   select(name, sex, event, equipment, age, age_class, date, bodyweight_lb, squat_lb, bench_lb, deadlift_lb) %>%   filter(sex == \"M\", event == \"SBD\")   #Creating a binary variable that equals 1 if the lifter was categorized as \"elite\" during this event, and 0 otherwise.  #The criteria for \"international elite\" classification for men was found at https://www.lift.net/2013/05/09/classification-standards-for-raw-elite-uspa/  ipf_lifts_event = ipf_lifts_lbs %>%   mutate(elite = ifelse(sex == \"M\" & bodyweight_lb <114 & squat_lb+bench_lb+deadlift_lb >=1044, 1,                         ifelse(sex == \"M\" & bodyweight_lb >=114 & bodyweight_lb <123 & squat_lb+bench_lb+deadlift_lb >=1135, 1,                                ifelse(sex == \"M\" & bodyweight_lb >=123 & bodyweight_lb <132 & squat_lb+bench_lb+deadlift_lb >=1222, 1,                                       ifelse(sex == \"M\" & bodyweight_lb >=132 & bodyweight_lb <148 & squat_lb+bench_lb+deadlift_lb >=1368, 1,                                              ifelse(sex == \"M\" & bodyweight_lb >=148 & bodyweight_lb <165 & squat_lb+bench_lb+deadlift_lb >=1498, 1,                                                     ifelse(sex == \"M\" & bodyweight_lb >=165 & bodyweight_lb <181 & squat_lb+bench_lb+deadlift_lb >=1611, 1,                                                            ifelse(sex == \"M\" & bodyweight_lb >=181 & bodyweight_lb <198 & squat_lb+bench_lb+deadlift_lb >=1698, 1,                                                                   ifelse(sex == \"M\" & bodyweight_lb >=198 & bodyweight_lb <220 & squat_lb+bench_lb+deadlift_lb >=1790, 1,                                                                           ifelse(sex == \"M\" & bodyweight_lb >=220 & bodyweight_lb <242 & squat_lb+bench_lb+deadlift_lb >=1854, 1,                                                                                 ifelse(sex == \"M\" & bodyweight_lb >=242 & bodyweight_lb <275 & squat_lb+bench_lb+deadlift_lb >=1909, 1,                                                                                        ifelse(sex == \"M\" & bodyweight_lb >=275 & bodyweight_lb <308 & squat_lb+bench_lb+deadlift_lb >=1995, 1,                                                                                               ifelse(sex == \"M\" & bodyweight_lb >=308 & squat_lb+bench_lb+deadlift_lb >=2055, 1, 0)))))))))))))  table(ipf_lifts_event$elite) #>  #>     0     1  #> 13126  4389  #Now creating a \"time\" variable that measures the number of days since the first recorded competition for each player ipf_lifts_time = ipf_lifts_event %>%   group_by(name) %>%   mutate(time = as.numeric(date)-min(as.numeric(date)))  ipf_lifts_time %>%   group_by(name) %>%   summarize(max(time)) #> # A tibble: 9,425 × 2 #>    name              `max(time)` #>    <chr>                   <dbl> #>  1 A Ernandos-Ortega           0 #>  2 A. Avalio                   0 #>  3 A. Candelaria               0 #>  4 A. Croeneboom               0 #>  5 A. De Vega                  0 #>  6 A. Doria                 1099 #>  7 A. Flimu                    0 #>  8 A. George                   0 #>  9 A. Grados                   0 #> 10 A. Gupta                    0 #> # ℹ 9,415 more rows  ggplot(data = ipf_lifts_time, aes(x = equipment, y = squat_lb)) + geom_violin() + labs(y = \"Best squat (lbs)\", title = \"Violin plots of competitors' squat performances\", subtitle = \"In pounds, by equipment used\", caption = \"Violin plot of competitors' best squat lift in three tries. Separated by equipment type.\") #> Warning: Removed 873 rows containing non-finite values #> (`stat_ydensity()`). ggplot(data = ipf_lifts_time, aes(x = bench_lb, group = equipment, fill = equipment)) + geom_boxplot() + labs(x = \"Best bench (lbs)\", title = \"Boxplots of competitors' bench performances\", subtitle = \"In pounds, by equipment used\", caption = \"Boxplots of competitors' best bench lift in three tries. Separated by equipment type.\") #> Warning: Removed 1096 rows containing non-finite values #> (`stat_boxplot()`). g = ggplot(data = ipf_lifts_time, aes(x = bodyweight_lb, y = deadlift_lb)) + geom_point() g + facet_wrap(vars(equipment)) + labs(x = \"Bodyweight\", y = \"Best deadlift (lbs)\", title = \"Scatterplots of best deadlifts vs bodyweight\", subtitle = \"In lbs, separated by equipment type\", caption = \"Scatterplots of best deadlifts vs bodyweight in lbs, separated by equipment type\") #> Warning: Removed 1297 rows containing missing values (`geom_point()`). #Out of the men that competed in all three events (squat, bench press, and deadlift), the \"international elite\" classification was reached 7971 times.   ipf_lifts_time$elite = compact(ipf_lifts_time$elite) some(ipf_lifts_time$elite, is.na) #> [1] TRUE every(ipf_lifts_time$elite, is.na) #> [1] FALSE #So some of the events are NA, but not all of them.     ggsurvfit(survfit(Surv(time, elite) ~ 1, data = ipf_lifts_time)) #using age class head(fct_relevel(ipf_lifts_time$age_class, \"18-19\", after = 2)) #> [1] <NA>  24-34 35-39 20-23 <NA>  <NA>  #> 15 Levels: 13-15 16-17 18-19 20-23 24-34 35-39 40-44 45-49 50-54 ... 80-999  summary(coxph(Surv(time, elite) ~ age_class + bodyweight_lb, data = ipf_lifts_time)) #> Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, : #> Loglik converged before variable 10,11,12,13,14 ; coefficient may be infinite. #> Call: #> coxph(formula = Surv(time, elite) ~ age_class + bodyweight_lb,  #>     data = ipf_lifts_time) #>  #>   n= 15635, number of events= 4115  #>    (3620 observations deleted due to missingness) #>  #>                       coef  exp(coef)   se(coef)      z Pr(>|z|)     #> age_class16-17   3.867e-01  1.472e+00  1.018e+00  0.380 0.704169     #> age_class18-19   1.105e+00  3.018e+00  1.003e+00  1.101 0.270744     #> age_class20-23   1.276e+00  3.584e+00  1.001e+00  1.275 0.202183     #> age_class24-34   6.455e-01  1.907e+00  1.001e+00  0.645 0.519005     #> age_class35-39  -1.484e-01  8.621e-01  1.002e+00 -0.148 0.882275     #> age_class40-44  -1.015e+00  3.624e-01  1.003e+00 -1.012 0.311541     #> age_class45-49  -1.768e+00  1.707e-01  1.007e+00 -1.756 0.079044 .   #> age_class50-54  -2.948e+00  5.244e-02  1.017e+00 -2.900 0.003735 **  #> age_class55-59  -3.545e+00  2.886e-02  1.046e+00 -3.389 0.000702 *** #> age_class60-64  -1.805e+01  1.443e-08  3.883e+02 -0.046 0.962916     #> age_class65-69  -1.835e+01  1.069e-08  4.874e+02 -0.038 0.969962     #> age_class70-74  -1.828e+01  1.157e-08  5.183e+02 -0.035 0.971872     #> age_class75-79  -1.805e+01  1.443e-08  1.050e+03 -0.017 0.986277     #> age_class80-999 -1.793e+01  1.628e-08  2.932e+03 -0.006 0.995120     #> bodyweight_lb   -2.556e-04  9.997e-01  2.696e-04 -0.948 0.343019     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> age_class16-17  1.472e+00  6.793e-01  0.200023   10.8339 #> age_class18-19  3.018e+00  3.314e-01  0.422704   21.5445 #> age_class20-23  3.584e+00  2.791e-01  0.504021   25.4783 #> age_class24-34  1.907e+00  5.244e-01  0.268099   13.5644 #> age_class35-39  8.621e-01  1.160e+00  0.120937    6.1453 #> age_class40-44  3.624e-01  2.759e+00  0.050748    2.5878 #> age_class45-49  1.707e-01  5.859e+00  0.023731    1.2276 #> age_class50-54  5.244e-02  1.907e+01  0.007150    0.3847 #> age_class55-59  2.886e-02  3.465e+01  0.003713    0.2243 #> age_class60-64  1.443e-08  6.929e+07  0.000000       Inf #> age_class65-69  1.069e-08  9.353e+07  0.000000       Inf #> age_class70-74  1.157e-08  8.646e+07  0.000000       Inf #> age_class75-79  1.443e-08  6.931e+07  0.000000       Inf #> age_class80-999 1.628e-08  6.142e+07  0.000000       Inf #> bodyweight_lb   9.997e-01  1.000e+00  0.999216    1.0003 #>  #> Concordance= 0.735  (se = 0.004 ) #> Likelihood ratio test= 4747  on 15 df,   p=<2e-16 #> Wald test            = 1987  on 15 df,   p=<2e-16 #> Score (logrank) test = 3920  on 15 df,   p=<2e-16  #Using continuous age summary(coxph(Surv(time, elite) ~ age + bodyweight_lb, data = ipf_lifts_time)) #> Call: #> coxph(formula = Surv(time, elite) ~ age + bodyweight_lb, data = ipf_lifts_time) #>  #>   n= 15617, number of events= 4112  #>    (3638 observations deleted due to missingness) #>  #>                     coef  exp(coef)   se(coef)       z Pr(>|z|)     #> age           -0.1151230  0.8912565  0.0021494 -53.560   <2e-16 *** #> bodyweight_lb  0.0002720  1.0002720  0.0002679   1.015     0.31     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>               exp(coef) exp(-coef) lower .95 upper .95 #> age              0.8913     1.1220    0.8875     0.895 #> bodyweight_lb    1.0003     0.9997    0.9997     1.001 #>  #> Concordance= 0.733  (se = 0.004 ) #> Likelihood ratio test= 4651  on 2 df,   p=<2e-16 #> Wald test            = 2873  on 2 df,   p=<2e-16 #> Score (logrank) test = 3399  on 2 df,   p=<2e-16"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Terry M Therneau. Author, maintainer. Thomas Lumley. Contributor, translator.            original S->R port R maintainer 2009 Atkinson Elizabeth. Contributor. Crowson Cynthia. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Therneau T (2023). Package Survival Analysis R. R package version 3.5-6, https://CRAN.R-project.org/package=survival. Terry M. Therneau, Patricia M. Grambsch (2000). Modeling Survival Data: Extending Cox Model. Springer, New York. ISBN 0-387-98784-3.","code":"@Manual{survival-package,   title = {A Package for Survival Analysis in R},   author = {Terry M Therneau},   year = {2023},   note = {R package version 3.5-6},   url = {https://CRAN.R-project.org/package=survival}, } @Book{survival-book,   title = {Modeling Survival Data: Extending the {C}ox Model},   author = {{Terry M. Therneau} and {Patricia M. Grambsch}},   year = {2000},   publisher = {Springer},   address = {New York},   isbn = {0-387-98784-3}, }"},{"path":[]},{"path":[]},{"path":"/index.html","id":"website-creator-sam-fansler","dir":"","previous_headings":"","what":"Website creator: Sam Fansler","title":"Survival Analysis","text":"Github link original package: https://github.com/therneau/survival Github link deployed website: https://github.com/jhu-statprogramming-fall-2023/biostat777-project3-part1-sfansler five things customized pkgdown website : 1. Foreground text color 2. Background color 3. Primary color 4. Navbar tab structure 5. Sidebar tab structure","code":""},{"path":"/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Survival Analysis","text":"Contains core survival analysis routines, including definition Surv objects, Kaplan-Meier Aalen-Johansen (multi-state) curves, Cox models, parametric accelerated failure time models.","code":""},{"path":"/index.html","id":"exported-functions","dir":"","previous_headings":"","what":"Exported Functions:","title":"Survival Analysis","text":"Surv: Create survival object, usually used response variable model formula Surv2: Create survival object timeline style data set. almost always response variable formula. Surv2data: multi-state survival functions coxph survfit allow two forms input data. routine converts . function normally called behind scenes Surv2 response. aeqSurv: Adjudicate near ties Surv object aareg: Returns object class “aareg” represents Aalen model. agreg.fit: functions called coxph actual computation. certain situations, e.g. simulation, may advantageous call directly rather usual coxph call using model formula. agexact.fit: Internal survival functions attrassign: “assign” attribute model matrices describes columns come terms model formula. two versions. R uses original version, alternate version found S-plus sometimes useful. blogit: Alternate link functions impose bounds input link function bprobit: Alternate link functions impose bounds input link function bcloglog: Alternate link functions impose bounds input link function blog: Alternate link functions impose bounds input link function brier: Compute Brier score, coxph model basehaz: Compute Brier score, coxph model cch: Returns estimates standard errors relative risk regression fit data case-cohort studies. choice available among Prentice, Self-Prentice Lin-Ying methods unstratified data. stratified data choice Borgan , generalization Self-Prentice estimator unstratified case-cohort data, Borgan II, generalization Lin-Ying estimator. clogit: Estimates logistic regression model maximising conditional likelihood. Uses model formula form case.status~exposure+strata(matched.set). default use exact conditional likelihood, commonly used approximate conditional likelihood provided compatibility older software. cipoisson: Confidence interval calculation Poisson rates. cluster: special function used context survival models. identifies correlated groups observations, used right hand side formula. style now discouraged, use cluster option instead. concordance: concordance statistic compute agreement observed response predictor. closely related Kendall’s tau-tau-b, Goodman’s gamma, Somers’ d, can also calculated results function. concordancefit: working routine behind concordance function. meant called users, available packages use. Input arguments, instance, assumed correct length type, missing values allowed: calling routine responsible things. coxph: Fits Cox proportional hazards regression model. Time dependent variables, time dependent strata, multiple events per subject, extensions incorporated using counting process formulation Andersen Gill. cox.zph: Test proportional hazards assumption Cox regression model fit (coxph). coxph.control: used set various numeric parameters controlling Cox model fit. Typically used call coxph. coxph.detail: Returns individual contributions first second derivative matrix, unique event time. coxph.fit: functions called coxph actual computation. certain situations, e.g. simulation, may advantageous call directly rather usual coxph call using model formula. coxph.wtest: function used internally several survival routines. computes simple quadratic form, properly dealing missings. finegray: Fine-Gray model can fit first creating special data set, fitting weighted Cox model result. routine creates data set. format.Surv: list methods apply Surv objects frailty: frailty function allows one add simple random effects term Cox model. frailty.gamma: frailty function allows one add simple random effects term Cox model. frailty.gaussian: frailty function allows one add simple random effects term Cox model. frailty.t: frailty function allows one add simple random effects term Cox model. .Surv: Create survival object, usually used response variable model formula. Argument matching special function. .na.Surv: list methods apply Surv objects .ratetable: function verifies class attribute, structure object. nsk: Create design matrix natural spline, coefficient resulting fit values function knots. match.ratetable: Internal survival functions neardate: common task medical work find closest lab value index date, subject. psurvreg: Density, cumulative distribution function, quantile function random generation set distributions supported survreg function. qsurvreg: Density, cumulative distribution function, quantile function random generation set distributions supported survreg function. dsurvreg: Density, cumulative distribution function, quantile function random generation set distributions supported survreg function. pseudo: Produce pseudo values survival curve. pspline: Specifies penalised spline basis predictor. done fitting comparatively small set splines penalising integrated second derivative. Traditional smoothing splines use one basis per observation, several authors pointed final results fit indistinguishable number basis functions greater 2-3 times degrees freedom. Eilers Marx point basis functions evenly spaced, leads significant computational simplification, refer result p-spline. pyears: function computes person-years follow-time contributed cohort subjects, stratified subgroups. also computes number subjects contribute cell output table, optionally number events /expected number events cell. ratetableDate: method converts dates various forms internal form used ratetable objects. ratetable: function supports ratetable() terms model statement, within survexp pyears. ridge: used coxph survreg model formula, specifies ridge regression term. likelihood penalised theta/2 time sum squared coefficients. scale=T penalty calculated coefficients based rescaling predictors unit variance. df specified theta chosen based approximate degrees freedom. royston: Compute D statistic proposed Royston Sauerbrei along several pseudo- R square values. rsurvreg: Density, cumulative distribution function, quantile function random generation set distributions supported survreg function. rttright: many survival estimands, one approach redistribute censored observation’s weight observations longer survival time (think distributing estate heirs). compute remaining, uncensored data. statefig: multi-state survival models useful figure shows states possible transitions . function creates simple “box arrows” figure. ’s goal simplicity. strata: special function used context Cox survival model. identifies stratification variables appear right hand side formula. survSplit: Given survival data set set specified cut times, split record multiple subrecords cut time. new data set ‘counting process’ format, start time, stop time, event status record. survcheck: Perform set consistency checks survival data survcondense: Counting process data sets can sometimes grow unweildy, can used compact one. survdiff: family tests, single curve known alternative. survexp: Returns either expected survival cohort subjects, individual expected survival subject. survfit: function creates survival curves either formula (e.g. Kaplan-Meier), previously fitted Cox model, previously fitted accelerated failure time model. survfit0: Add point starting time (time 0) survfit object’s elements. useful plotting. survfit.formula: Computes estimate survival curve censored data using Aalen-Johansen estimator. ordinary (single event) survival reduces Kaplan-Meier estimate. coxsurv.fit: program mainly supplied allow packages invoke survfit.coxph function ‘data’ level rather ‘user’ level. checks input data provided, can lead unexpected errors data wrong. survfitKM: Internal survival functions survfitCI: Internal survival functions survobrien: Peter O’Brien’s test association single variable survival test proposed Biometrics, June 1978. survpenal.fit: Internal survival functions survreg: Fit parametric survival regression model. location-scale models arbitrary transform time variable; common cases use log transformation, leading accelerated failure time models. survreg.control: functions checks packages fitting options survreg survreg.fit: Internal survival functions survreg.distributions: List distributions accelerated failure models. location-scale families transformation time. entry describes cdf survregDtest: routine called survreg verify distribution object valid. tcut: Attaches categories person-year calculations variable without losing underlying continuous representation tmerge: common task survival analysis creation start,stop data sets multiple intervals subject, along covariate values apply interval. function aids creation data sets. untangle.specials: Given terms structure desired special name, returns index appropriate subscripting terms structure another appropriate data frame. yates: Compute population marginal means (PMM) model fit, chosen population statistic. yates_setup: method called yates function, order setup code handle particular model type. Methods glm, coxph, default part survival package. survConcordance: functions temporarily retained compatability older programs, may transition defunct status. survConcordance.fit: functions temporarily retained compatability older programs, may transition defunct status. survfitcoxph.fit: program mainly supplied allow packages invoke survfit.coxph function ‘data’ level rather ‘user’ level. checks input data provided, can lead unexpected errors data wrong.","code":""},{"path":"/index.html","id":"basic-example","dir":"","previous_headings":"","what":"Basic example","title":"Survival Analysis","text":"```{r} library(survival) set.seed(123) event = rbernoulli(100, p = 0.2) time = rpois(100, 10) surv_obj = Surv(time, event) ``` source code “survival” package R. gets posted comprehensive R archive (CRAN) intervals, posting preceded throrough test. (run test suite 800+ packages depend survival.) general, new push CRAN update second term version number, e.g. 2.40-5 2.41-0. Updates github source increment dash. (error found process CRAN submission published CRAN version may x.yy-1 even x.yy-2 3.) directory shadow ‘real’ respository, mercurial machine. don’t use git pull requests. often copy code suggestion, however; don’t get ignored! vignette2 directory contains material posted CRAN. file “tutorial.Rnw”, instance, requires data mstate package. Survival recommended package, packages can depend recommended packages. (allows consistent distribution bundle.) sas.Rnw vignette discussion compute time takes long run, etc. large portion source found noweb directory, based literate programming ideas Knuth. reason allows complete documentation methods. can things like blocks equations, find “real” equations side side code makes much easier get right. Anyone wants study methods advised perform “make code.pdf” noweb directory look relevant portion pdf file. file R src directories starts “automatically generated …” comment modified directly, instead work noweb source. (need noweb package loaded order run Makefile.) able install using following R code: library(devtools); install_github(“therneau/survival”) Note good practice make derived files R/tmerge.R “fly” using configure script; way danger someone trying modify derived file rather actual source (noweb/tmerge.Rnw). However, able create configure file worked reliably platforms, voted usability rather purity.","code":""},{"path":"/reference/aareg.html","id":null,"dir":"Reference","previous_headings":"","what":"Aalen's additive regression model for censored data — aareg","title":"Aalen's additive regression model for censored data — aareg","text":"Returns object class \"aareg\" represents Aalen model.","code":""},{"path":"/reference/aareg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aalen's additive regression model for censored data — aareg","text":"","code":"aareg(formula, data, weights, subset, na.action,    qrtol=1e-07, nmin, dfbeta=FALSE, taper=1,    test = c('aalen', 'variance', 'nrisk'), cluster,     model=FALSE, x=FALSE, y=FALSE)"},{"path":"/reference/aareg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aalen's additive regression model for censored data — aareg","text":"formula formula object, response left `~' operator  terms,  separated + operators, right.  response must Surv object. Due particular computational approach used, model MUST include intercept term.  \"-1\" used model formula program ignore . data data frame interpret variables named formula, subset, weights arguments. may also single number handle speci al cases -- see details. data missing, variables model formula search path. weights vector observation weights. supplied, fitting algorithm minimizes sum weights multiplied squared residuals (see additional technical details). length weights must number observations. weights must nonnegative s recommended strictly positive, since zero weights ambiguous.  exclude particular observations model, use subset argument instead zero weights. subset expression specifying subset observations used fit. Th can logical vector (replicated length equal numb er observations), numeric vector indicating observation numbers included, character vector observation names included.  observations included default. na.action function filter missing data. applied model.fr ame subset argument en applied. default na.fail, returns n error missing values found. alternative na.excl ude, deletes observations contain one missing values. qrtol tolerance detection singularity QR decomposition nmin minimum number observations estimate; defaults 3 times number covariates. essentially truncates computations near tail data set, n small calculations can become numerically unstable. dfbeta array dfbeta residuals computed.  implies computation sandwich variance estimate. residuals always computed cluster term model formula. taper allows smoothed variance estimate. Var(x), x set covariates, important component calculations Aalen regression model.   given time point t, computed subjects still risk time t. tape argument allows smoothing estimates, example taper=(1:4)/4 cause variance estimate used event time weighted average estimated variance matrices last 4 death times, weight 1 current death time decreasing 1/4 prior event times. default value gives standard Aalen model. test selects weighting used, computing overall ``average'' coefficient vector time subsequent test equality zero. cluster clustering group, optional.  variable   searched data argument. model, x, y copies model frame, x matrix predictors, response vector y included saved result.","code":""},{"path":"/reference/aareg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aalen's additive regression model for censored data — aareg","text":"object class \"aareg\" representing fit, following components: n vector containing number observations data set,     number event times, number event times used     computation times vector sorted event times, may contain     duplicates nrisk vector containing number subjects risk,     length times coefficient matrix coefficients, one row per event     one column per covariate test.statistic value test statistic, vector     one element per covariate test.var variance-covariance matrix test test type test; copy test argument     tweight matrix weights used computation, one row per     event call copy call produced result","code":""},{"path":"/reference/aareg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aalen's additive regression model for censored data — aareg","text":"Aalen model assumes cumulative hazard H(t) subject can expressed (t) + X B(t), (t) time-dependent intercept term, X vector covariates subject (possibly time-dependent), B(t) time-dependent matrix coefficients. estimates inherently non-parametric; fit model normally followed one plots estimates. estimates may become unstable near tail data set, since increment B time t based subjects still risk time t.  tolerance /nmin parameters may act truncate estimate last death. taper argument can also used smooth tail curve. practice, addition taper 1:10 appears little effect death times n still reasonably large, can considerably dampen wild occilations tail plot.","code":""},{"path":"/reference/aareg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Aalen's additive regression model for censored data — aareg","text":"Aalen, O.O. (1989). linear regression model analysis life times. Statistics Medicine, 8:907-925. Aalen, O.O (1993). results non-parametric linear model survival analysis.  Statistics Medicine. 12:1569-1588.","code":""},{"path":[]},{"path":[]},{"path":"/reference/aeqSurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjudicate near ties in a Surv object — aeqSurv","title":"Adjudicate near ties in a Surv object — aeqSurv","text":"check tied survival times can fail due   floating point imprecision, can make actual ties appear   distinct values.   Routines depend correct identification ties pairs   give incorrect results, e.g., Cox model.   function rectifies .","code":""},{"path":"/reference/aeqSurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjudicate near ties in a Surv object — aeqSurv","text":"","code":"aeqSurv(x, tolerance = sqrt(.Machine$double.eps))"},{"path":"/reference/aeqSurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjudicate near ties in a Surv object — aeqSurv","text":"x Surv object tolerance tolerance used detect values     considered equal","code":""},{"path":"/reference/aeqSurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjudicate near ties in a Surv object — aeqSurv","text":"routine called survfit coxph   deal issue ties get incorrectly broken due   floating point imprecision.  See short vignette tied times   simple example.  Use timefix argument   survfit coxph.control control option   desired. rule `equality' identical used   .equal routine.  Pairs values within round   error replaced smaller value.   error message generated process causes 0 length   time interval created.","code":""},{"path":"/reference/aeqSurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjudicate near ties in a Surv object — aeqSurv","text":"Surv object identical original, ties restored.","code":""},{"path":"/reference/aeqSurv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adjudicate near ties in a Surv object — aeqSurv","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/aggregate.survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Average survival curves — aggregate.survfit","title":"Average survival curves — aggregate.survfit","text":"survfit object containing multiple curves, create average curves grouping.","code":""},{"path":"/reference/aggregate.survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average survival curves — aggregate.survfit","text":"","code":"# S3 method for survfit aggregate(x, by = NULL, FUN = mean, ...)"},{"path":"/reference/aggregate.survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average survival curves — aggregate.survfit","text":"x survfit object data dimension. optional list vector grouping elements,     long dim(x)['data']. FUN function compute summary statistic interest. ... optional arguments FUN.","code":""},{"path":"/reference/aggregate.survfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Average survival curves — aggregate.survfit","text":"primary use take average multiple survival   curves created modeling function.  ,   marginal estimate survival.   primarily used average multiple predicted curves   Cox model.","code":""},{"path":"/reference/aggregate.survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average survival curves — aggregate.survfit","text":"survfit object lower dimension.","code":""},{"path":[]},{"path":"/reference/aggregate.survfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average survival curves — aggregate.survfit","text":"","code":"cfit <- coxph(Surv(futime, death) ~ sex + age*hgb, data=mgus2) # marginal effect of sex, after adjusting for the others dummy <- rbind(mgus2, mgus2) dummy$sex <- rep(c(\"F\", \"M\"), each=nrow(mgus2)) # population data set dummy <- na.omit(dummy)   # don't count missing hgb in our \"population csurv <- survfit(cfit, newdata=dummy) dim(csurv)  # 2 * 1384 survival curves #> data  #> 2676  csurv2 <- aggregate(csurv, dummy$sex)"},{"path":"/reference/agreg.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Cox model fitting functions — agreg.fit","title":"Cox model fitting functions — agreg.fit","text":"functions called coxph actual   computation.   certain situations, e.g. simulation, may advantageous   call directly rather usual coxph call using   model formula.","code":""},{"path":"/reference/agreg.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cox model fitting functions — agreg.fit","text":"","code":"agreg.fit(x, y, strata, offset, init, control, weights, method, rownames, resid=TRUE, nocenter=NULL) coxph.fit(x, y, strata, offset, init, control, weights, method, rownames, resid=TRUE, nocenter=NULL)"},{"path":"/reference/agreg.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cox model fitting functions — agreg.fit","text":"x Matix predictors.  include     intercept. y Surv object containing either 2 columns (coxph.fit)     3 columns (agreg.fit). strata vector containing stratification, NULL offset optional offset vector init initial values coefficients control result call coxph.control weights optional vector weights method method handling ties, one \"breslow\" \"efron\" rownames needed NULL model, case     contains rownames () original data. resid compute return residuals. nocenter optional list values. column X matrix     whose values lie strictly within set recentered.   Note coxph function (-1, 0, 1) default.","code":""},{"path":"/reference/agreg.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cox model fitting functions — agreg.fit","text":"routine checking arguments proper length type. use know ! resid concordance arguments save compute time calling routines need likelihood, generation permutation distribution instance.","code":""},{"path":"/reference/agreg.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cox model fitting functions — agreg.fit","text":"list containing results fit","code":""},{"path":"/reference/agreg.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cox model fitting functions — agreg.fit","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/aml.html","id":null,"dir":"Reference","previous_headings":"","what":"Acute Myelogenous Leukemia survival data — aml","title":"Acute Myelogenous Leukemia survival data — aml","text":"Survival patients Acute Myelogenous Leukemia.   question time whether standard course chemotherapy extended ('maintainance') additional cycles.","code":""},{"path":"/reference/aml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acute Myelogenous Leukemia survival data — aml","text":"","code":"aml leukemia data(cancer, package=\"survival\")"},{"path":[]},{"path":"/reference/aml.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Acute Myelogenous Leukemia survival data — aml","text":"Rupert G. Miller (1997),   Survival Analysis.   John Wiley & Sons.   ISBN: 0-471-25218-2.","code":""},{"path":"/reference/anova.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Analysis of Deviance for a Cox model. — anova.coxph","title":"Analysis of Deviance for a Cox model. — anova.coxph","text":"Compute analysis deviance table one Cox model fits,   based log partial likelihood.","code":""},{"path":"/reference/anova.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analysis of Deviance for a Cox model. — anova.coxph","text":"","code":"# S3 method for coxph anova(object, ...,  test = 'Chisq')"},{"path":"/reference/anova.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analysis of Deviance for a Cox model. — anova.coxph","text":"object object class coxph ... coxph objects test character string. appropriate test chisquare, choices result test done.","code":""},{"path":"/reference/anova.coxph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analysis of Deviance for a Cox model. — anova.coxph","text":"Specifying single object gives sequential analysis deviance   table fit.  , reductions model   Cox log-partial-likelihood   term formula added turn given   rows table, plus log-likelihoods .   robust variance estimate normally used situations   model may mis-specified, e.g., multiple events per subject.   case comparison likelihood values make   sense (differences longer chi-square distribution),   anova refuse print results. one object specified, table row   degrees freedom loglikelihood model.   first model, change degrees freedom loglik   also given. (make statistical sense models   nested.)  conventional list models smallest   largest, user. table optionally contain test statistics (P values)   comparing reduction loglik row.","code":""},{"path":"/reference/anova.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analysis of Deviance for a Cox model. — anova.coxph","text":"object class \"anova\" inheriting class \"data.frame\".","code":""},{"path":"/reference/anova.coxph.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Analysis of Deviance for a Cox model. — anova.coxph","text":"comparison two models anova    valid   fitted dataset. may problem   missing values.","code":""},{"path":[]},{"path":"/reference/anova.coxph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analysis of Deviance for a Cox model. — anova.coxph","text":"","code":"fit <- coxph(Surv(futime, fustat) ~ resid.ds *rx + ecog.ps, data = ovarian)  anova(fit) #> Analysis of Deviance Table #>  Cox model: response is Surv(futime, fustat) #> Terms added sequentially (first to last) #>  #>              loglik  Chisq Df Pr(>|Chi|)   #> NULL        -34.985                        #> resid.ds    -33.105 3.7594  1    0.05251 . #> rx          -32.269 1.6733  1    0.19582   #> ecog.ps     -31.970 0.5980  1    0.43934   #> resid.ds:rx -30.946 2.0469  1    0.15251   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 fit2 <- coxph(Surv(futime, fustat) ~ resid.ds +rx + ecog.ps, data=ovarian) anova(fit2,fit) #> Analysis of Deviance Table #>  Cox model: response is  Surv(futime, fustat) #>  Model 1: ~ resid.ds + rx + ecog.ps #>  Model 2: ~ resid.ds * rx + ecog.ps #>    loglik  Chisq Df Pr(>|Chi|) #> 1 -31.970                      #> 2 -30.946 2.0469  1     0.1525"},{"path":"/reference/attrassign.html","id":null,"dir":"Reference","previous_headings":"","what":"Create new-style ","title":"Create new-style ","text":"\"assign\" attribute model matrices describes columns come terms model formula. two versions. R uses original version, alternate version found S-plus sometimes useful.","code":""},{"path":"/reference/attrassign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create new-style ","text":"","code":"attrassign(object, ...) # S3 method for default attrassign(object, tt,...) # S3 method for lm attrassign(object,...)"},{"path":"/reference/attrassign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create new-style ","text":"object model matrix linear model object tt terms object ... arguments methods","code":""},{"path":"/reference/attrassign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create new-style ","text":"list names corresponding term names elements  vectors indicating columns come terms","code":""},{"path":"/reference/attrassign.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create new-style ","text":"instance consider following R gives compact assign, vector (0, 1, 2, 3, 3, 3);   can   read ``first column X matrix (intercept) goes none   terms, second column X goes term 1 model   equation, third column X term 2, columns 4-6   term 3''. alternate (S-Plus default) form list","code":"survreg(Surv(time, status) ~ age + sex + factor(ph.ecog), lung) $(Intercept)     1        $age             2        $sex             3        $factor(ph.ecog) 4 5 6"},{"path":[]},{"path":"/reference/attrassign.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create new-style ","text":"","code":"formula <- Surv(time,status)~factor(ph.ecog) tt <- terms(formula) mf <- model.frame(tt,data=lung) mm <- model.matrix(tt,mf) ## a few rows of data mm[1:3,] #>   (Intercept) factor(ph.ecog)1 factor(ph.ecog)2 factor(ph.ecog)3 #> 1           1                1                0                0 #> 2           1                0                0                0 #> 3           1                0                0                0 ## old-style assign attribute attr(mm,\"assign\") #> [1] 0 1 1 1 ## alternate style assign attribute attrassign(mm,tt) #> $`(Intercept)` #> [1] 1 #>  #> $`factor(ph.ecog)` #> [1] 2 3 4 #>"},{"path":"/reference/basehaz.html","id":null,"dir":"Reference","previous_headings":"","what":"Alias for the survfit function — basehaz","title":"Alias for the survfit function — basehaz","text":"Compute predicted survival curve Cox model.","code":""},{"path":"/reference/basehaz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alias for the survfit function — basehaz","text":"","code":"basehaz(fit, newdata, centered=TRUE)"},{"path":"/reference/basehaz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Alias for the survfit function — basehaz","text":"fit coxph fit newdata data frame containing one row predicted     survival curve, said row contains covariate values curve centered ignored newdata argument present.     Otherwise, TRUE return data predicted survival curve     covariate values fit$mean, FALSE return     prediction covariates equal zero.","code":""},{"path":"/reference/basehaz.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Alias for the survfit function — basehaz","text":"function simply alias survfit,   actual work richer set options.     alias exists users look predicted survival   estimates name. function returns data frame containing time,   cumhaz optionally strata (fitted Cox model used   strata statement), copied survfit result.   Results covariates =0 standard form found textbooks,   however, due possible overflow exp() function can   bad idea practice.","code":""},{"path":"/reference/basehaz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Alias for the survfit function — basehaz","text":"data frame variable names hazard, time   optionally strata.  first actually cumulative hazard.","code":""},{"path":[]},{"path":"/reference/bladder.html","id":null,"dir":"Reference","previous_headings":"","what":"Bladder Cancer Recurrences — bladder","title":"Bladder Cancer Recurrences — bladder","text":"Data recurrences bladder cancer, used many people   demonstrate methodology recurrent event modelling. Bladder1 full data set study. contains three treatment arms recurrences 118 subjects; maximum observed number recurrences 9. Bladder data set appears commonly literature.  uses 85 subjects nonzero follow-assigned either thiotepa placebo, first four recurrences patient.  status variable 1 recurrence 0 everything else (including death reason). data set laid competing risks format paper Wei, Lin, Weissfeld. Bladder2 uses subset subjects bladder, formatted (start, stop] Anderson-Gill style.   Note transforming WLW AG style data set quite common programming mistake leads extra follow-time 12 subjects: follow-beyond 4th recurrence. \"follow-\" side effect throwing away events fourth retaining last follow-time variable original data.  bladder2 data set found make mistake, analyses literature done ; results addition small amount immortal time bias  shrinks fitted coefficients towards zero.","code":""},{"path":"/reference/bladder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bladder Cancer Recurrences — bladder","text":"","code":"bladder1 bladder bladder2 data(cancer, package=\"survival\")"},{"path":"/reference/bladder.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Bladder Cancer Recurrences — bladder","text":"bladder1 bladder bladder2","code":""},{"path":"/reference/bladder.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Bladder Cancer Recurrences — bladder","text":"Andrews DF, Hertzberg (1985),  DATA: Collection Problems Many Fields Student  Research Worker, New York: Springer-Verlag. LJ Wei, DY Lin, L Weissfeld (1989),   Regression analysis multivariate incomplete failure time data   modeling marginal distributions.   Journal American Statistical Association,   84.","code":""},{"path":"/reference/blogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Bounded link functions — blogit","title":"Bounded link functions — blogit","text":"Alternate link functions impose bounds input link function","code":""},{"path":"/reference/blogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bounded link functions — blogit","text":"","code":"blogit(edge = 0.05) bprobit(edge= 0.05) bcloglog(edge=.05) blog(edge=.05)"},{"path":"/reference/blogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bounded link functions — blogit","text":"edge input values less cutpoint replaces     cutpoint.  blog input values greater (1-edge)     replaced (1-edge)","code":""},{"path":"/reference/blogit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bounded link functions — blogit","text":"using survival psuedovalues binomial regression, raw data can   outside range (0,1), yet want restrict predicted values   lie within range.  natural way deal use   glm family = gaussian(link= \"logit\").   fail.   reason family object component   linkfun accept values outside (0,1). function used create initial values iteration   step, however. Mapping offending input argument range   (egde, 1-edge) computing link results starting   estimates good enough.  final result fit   different explicit starting estimates given using   etastart mustart arguments.   functions create copies logit, probit, complimentary   log-log families differ standard ones   use bounded input argument, called \"bounded logit\" =   blogit, etc. argument hold using RMST (area curve)   pseudovalues along log link ensure positive predictions,   though case lower boundary needs mapped.","code":""},{"path":"/reference/blogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bounded link functions — blogit","text":"family object form make.family.","code":""},{"path":[]},{"path":"/reference/blogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bounded link functions — blogit","text":"","code":"py <- pseudo(survfit(Surv(time, status) ~1, lung), time=730) #2 year survival range(py) #> [1] -0.335248  1.693831 pfit <- glm(py ~ ph.ecog, data=lung, family=gaussian(link=blogit())) # For each +1 change in performance score, the odds of 2 year survival #  are multiplied by 1/2  = exp of the coefficient."},{"path":"/reference/brier.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the Brier score for a Cox model — brier","title":"Compute the Brier score for a Cox model — brier","text":"Compute Brier score, coxph model","code":""},{"path":"/reference/brier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the Brier score for a Cox model — brier","text":"","code":"brier(fit, times, newdata, ties = TRUE, detail = FALSE, timefix = TRUE,        efron = FALSE)"},{"path":"/reference/brier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the Brier score for a Cox model — brier","text":"fit result coxph fit times time points create score newdata optional, used validate prior fit new data ties TRUE, treate tied event/censoring times properly detail TRUE, returned object detail.  can   useful debugging instruction. timefix deal near ties data.  See tied times vignette. efron use survival estimate NULL model     used coxph call","code":""},{"path":"/reference/brier.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the Brier score for a Cox model — brier","text":"Far details found vignette. time point tau, scaled Brier score essentially R-squared statistic y = 0/1 variable \"event tau\", yhat probability event tau, predicted model, ybar predicted probablity without covariate, normally Kaplan-Meier. \\(R^2= 1- \\sum(y- \\hat y)^2/\\sum (y- \\mu)^2\\), Brier score formally numerator second term.  rescaled value much useful, however. Many, perhaps even algorithms properly deal tied censoring time/event time pair.  tied option present mostly verify get answer, make mistake.  numerical size inaccuracy small; just large enough generate concern function incorrect. sensible argument can made NULL model coxph call covariates, rather Kaplan-Meier; turns effect slight. allowed efron argument.","code":""},{"path":"/reference/brier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the Brier score for a Cox model — brier","text":"list components rsquared \\(R^2\\) value, scaled Brier score.   vector one entry time point. brier brier score, vector one entry per time point times time points score computed","code":""},{"path":"/reference/brier.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the Brier score for a Cox model — brier","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/brier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the Brier score for a Cox model — brier","text":"","code":"cfit <- coxph(Surv(rtime, recur) ~ age + meno + size + pmin(nodes,11),                data= rotterdam) round(cfit$concordance[\"concordance\"], 3)  # some predictive power #> concordance  #>       0.675  brier(cfit, times=c(4,6)*365.25)   # values at 4 and 6 years #> Error in brier(cfit, times = c(4, 6) * 365.25): could not find function \"brier\""},{"path":"/reference/cch.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits proportional hazards regression model to case-cohort data — cch","title":"Fits proportional hazards regression model to case-cohort data — cch","text":"Returns estimates standard errors relative risk regression fit data case-cohort studies. choice available among Prentice, Self-Prentice Lin-Ying methods unstratified data. stratified data choice Borgan , generalization Self-Prentice estimator unstratified case-cohort data, Borgan II, generalization Lin-Ying estimator.","code":""},{"path":"/reference/cch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits proportional hazards regression model to case-cohort data — cch","text":"","code":"cch(formula, data, subcoh, id, stratum=NULL, cohort.size,     method =c(\"Prentice\",\"SelfPrentice\",\"LinYing\",\"I.Borgan\",\"II.Borgan\"),     robust=FALSE)"},{"path":"/reference/cch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits proportional hazards regression model to case-cohort data — cch","text":"formula formula object must Surv object response.  Surv object must type \"right\", type \"counting\". subcoh Vector indicators subjects sampled part   sub-cohort. Code 1 TRUE members   sub-cohort, 0 FALSE others. data   data frame subcoh may one-sided formula. id Vector unique identifiers, formula specifying vector. stratum vector stratum indicators formula specifying   vector cohort.size Vector size stratum original cohort subcohort sampled data optional data frame interpret variables  occurring formula. method Three procedures available. default method \"Prentice\",  options \"SelfPrentice\" \"LinYing\". robust \"LinYing\" , robust=TRUE, use design-based standard errors even   phase ","code":""},{"path":"/reference/cch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits proportional hazards regression model to case-cohort data — cch","text":"object class \"cch\"  incorporating list estimated regression coefficients two estimates  asymptotic variance-covariance matrix. coef regression coefficients. naive.var Self-Prentice model based variance-covariance matrix. var Lin-Ying empirical variance-covariance matrix.","code":""},{"path":"/reference/cch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fits proportional hazards regression model to case-cohort data — cch","text":"Implements methods case-cohort data analysis described Therneau Li (1999). three methods differ choice \"risk sets\" used compare covariate values failure others risk time failure. \"Prentice\" uses sub-cohort members \"risk\" plus failure occurs outside sub-cohort score unbiased. \"SelfPren\" (Self-Prentice) uses just sub-cohort members \"risk\". two asymptotic variance-covariance matrix. \"LinYing\" (Lin-Ying) uses members sub-cohort failures outside sub-cohort \"risk\". methods also differ weights given different score contributions. data argument must missing values variables model.  must censored observations outside subcohort.","code":""},{"path":"/reference/cch.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fits proportional hazards regression model to case-cohort data — cch","text":"Norman Breslow, modified Thomas Lumley","code":""},{"path":"/reference/cch.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fits proportional hazards regression model to case-cohort data — cch","text":"Prentice, RL (1986). case-cohort design epidemiologic cohort studies disease prevention trials. Biometrika 73: 1--11. Self, S Prentice, RL (1988). Asymptotic distribution theory efficiency results case-cohort studies. Annals Statistics 16: 64--81. Lin, DY Ying, Z (1993). Cox regression incomplete covariate measurements. Journal American Statistical Association 88: 1341--1349. Barlow, (1994). Robust variance estimation case-cohort design. Biometrics 50: 1064--1072 Therneau, TM Li, H (1999). Computing Cox model case-cohort designs. Lifetime Data Analysis 5: 99--112. Borgan, \\(O\\), Langholz, B, Samuelsen, , Goldstein, L Pogoda, J (2000)  Exposure stratified case-cohort designs. Lifetime Data Analysis 6, 39-58.","code":""},{"path":[]},{"path":"/reference/cch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fits proportional hazards regression model to case-cohort data — cch","text":"","code":"## The complete Wilms Tumor Data  ## (Breslow and Chatterjee, Applied Statistics, 1999) ## subcohort selected by simple random sampling. ##  subcoh <- nwtco$in.subcohort selccoh <- with(nwtco, rel==1|subcoh==1) ccoh.data <- nwtco[selccoh,] ccoh.data$subcohort <- subcoh[selccoh] ## central-lab histology  ccoh.data$histol <- factor(ccoh.data$histol,labels=c(\"FH\",\"UH\")) ## tumour stage ccoh.data$stage <- factor(ccoh.data$stage,labels=c(\"I\",\"II\",\"III\",\"IV\")) ccoh.data$age <- ccoh.data$age/12 # Age in years  ## ## Standard case-cohort analysis: simple random subcohort  ##  fit.ccP <- cch(Surv(edrel, rel) ~ stage + histol + age, data =ccoh.data,    subcoh = ~subcohort, id=~seqno, cohort.size=4028)   fit.ccP #> Case-cohort analysis,x$method, Prentice  #>  with subcohort of 668 from cohort of 4028  #>  #> Call: cch(formula = Surv(edrel, rel) ~ stage + histol + age, data = ccoh.data,  #>     subcoh = ~subcohort, id = ~seqno, cohort.size = 4028) #>  #> Coefficients: #>               Value         SE        Z            p #> stageII  0.73457084 0.16849620 4.359569 1.303187e-05 #> stageIII 0.59708356 0.17345094 3.442377 5.766257e-04 #> stageIV  1.38413197 0.20481982 6.757803 1.400990e-11 #> histolUH 1.49806307 0.15970515 9.380180 0.000000e+00 #> age      0.04326787 0.02373086 1.823274 6.826184e-02  fit.ccSP <- cch(Surv(edrel, rel) ~ stage + histol + age, data =ccoh.data,    subcoh = ~subcohort, id=~seqno, cohort.size=4028, method=\"SelfPren\")  summary(fit.ccSP) #> Case-cohort analysis,x$method, SelfPrentice  #>  with subcohort of 668 from cohort of 4028  #>  #> Call: cch(formula = Surv(edrel, rel) ~ stage + histol + age, data = ccoh.data,  #>     subcoh = ~subcohort, id = ~seqno, cohort.size = 4028, method = \"SelfPren\") #>  #> Coefficients: #>           Coef    HR  (95%   CI)     p #> stageII  0.736 2.088 1.501 2.905 0.000 #> stageIII 0.597 1.818 1.294 2.553 0.001 #> stageIV  1.392 4.021 2.692 6.008 0.000 #> histolUH 1.506 4.507 3.295 6.163 0.000 #> age      0.043 1.044 0.997 1.094 0.069  ## ## (post-)stratified on instit ## stratsizes<-table(nwtco$instit) fit.BI<- cch(Surv(edrel, rel) ~ stage + histol + age, data =ccoh.data,    subcoh = ~subcohort, id=~seqno, stratum=~instit, cohort.size=stratsizes,    method=\"I.Borgan\")  summary(fit.BI) #> Exposure-stratified case-cohort analysis, I.Borgan method. #>              1   2 #> subcohort  952 202 #> cohort    3622 406 #> Call: cch(formula = Surv(edrel, rel) ~ stage + histol + age, data = ccoh.data,  #>     subcoh = ~subcohort, id = ~seqno, stratum = ~instit, cohort.size = stratsizes,  #>     method = \"I.Borgan\") #>  #> Coefficients: #>           Coef    HR  (95%   CI)     p #> stageII  0.737 2.090 1.501 2.909 0.000 #> stageIII 0.602 1.825 1.301 2.561 0.000 #> stageIV  1.395 4.036 2.702 6.029 0.000 #> histolUH 1.522 4.580 3.450 6.080 0.000 #> age      0.043 1.044 0.996 1.093 0.072"},{"path":"/reference/cgd.html","id":null,"dir":"Reference","previous_headings":"","what":"Chronic Granulotamous Disease data — cgd","title":"Chronic Granulotamous Disease data — cgd","text":"Data placebo controlled trial gamma   interferon chronic granulotomous disease (CGD).   Contains data time serious infections observed   end study patient.","code":""},{"path":"/reference/cgd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chronic Granulotamous Disease data — cgd","text":"","code":"cgd data(cgd)"},{"path":"/reference/cgd.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Chronic Granulotamous Disease data — cgd","text":"id subject identification number center enrolling center random date randomization treatment placebo gamma interferon sex sex age age years, study entry height height cm study entry weight weight kg study entry inherit pattern inheritance steroids use steroids study entry,1=yes propylac use prophylactic antibiotics study entry hos.cat categorization centers 4 groups tstart, tstop start end time interval status 1=interval ends infection enum observation number within subject","code":""},{"path":"/reference/cgd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Chronic Granulotamous Disease data — cgd","text":"cgd0 data set form found references,    one line per patient recoding variables.    cgd data set (one) cast (start, stop]    format one line per event, covariates    center recoded factors    include meaningful labels.","code":""},{"path":"/reference/cgd.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Chronic Granulotamous Disease data — cgd","text":"Fleming Harrington, Counting Processes Survival Analysis,   appendix D.2.","code":""},{"path":[]},{"path":"/reference/cgd0.html","id":null,"dir":"Reference","previous_headings":"","what":"Chronic Granulotomous Disease data — cgd0","title":"Chronic Granulotomous Disease data — cgd0","text":"Data placebo controlled trial gamma   interferon chronic granulotomous disease (CGD).   Contains data time serious infections observed   end study patient.","code":""},{"path":"/reference/cgd0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chronic Granulotomous Disease data — cgd0","text":"","code":"cgd0"},{"path":"/reference/cgd0.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Chronic Granulotomous Disease data — cgd0","text":"id subject identification number center enrolling center random date randomization treatment placebo gamma interferon sex sex age age years, study entry height height cm study entry weight weight kg study entry inherit pattern inheritance steroids use steroids study entry,1=yes propylac use prophylactic antibiotics study entry hos.cat categorization centers 4 groups futime days last follow-etime1-etime7 7 infection times subject","code":""},{"path":"/reference/cgd0.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Chronic Granulotomous Disease data — cgd0","text":"cgdraw data set (one) form found references,    one line per patient recoding variables. cgd data set processed one    line per event, covariates center recoded factors    include meaningful labels.","code":""},{"path":"/reference/cgd0.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Chronic Granulotomous Disease data — cgd0","text":"Fleming Harrington, Counting Processes Survival Analysis,   appendix D.2.","code":""},{"path":[]},{"path":"/reference/cipoisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence limits for the Poisson — cipoisson","title":"Confidence limits for the Poisson — cipoisson","text":"Confidence interval calculation Poisson rates.","code":""},{"path":"/reference/cipoisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence limits for the Poisson — cipoisson","text":"","code":"cipoisson(k, time = 1, p = 0.95, method = c(\"exact\", \"anscombe\"))"},{"path":"/reference/cipoisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence limits for the Poisson — cipoisson","text":"k Number successes time Total time trial p Probability level (two-sided) interval method method computing interval.","code":""},{"path":"/reference/cipoisson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence limits for the Poisson — cipoisson","text":"vector, matrix, array.   k time single values result   vector length 2 containing lower upper limits.   either vectors result matrix two columns.   k matrix array, result array one   dimension; case dimensions dimnames ()  k preserved.","code":""},{"path":"/reference/cipoisson.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence limits for the Poisson — cipoisson","text":"likelihood method based equation 10.10 Feller, relates poisson probabilities tail area gamma distribution. Anscombe approximation based fact sqrt(k + 3/8) nearly constant variance 1/4, along continuity correction. many proposed intervals: Patil Kulkarni list evaluate 19 different suggestions literature!.  exact intervals can overly broad small values k, many approaches try shrink lengths, varying success.","code":""},{"path":"/reference/cipoisson.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Confidence limits for the Poisson — cipoisson","text":"F.J. Anscombe (1949). Transformations Poisson, binomial negative-binomial data. Biometrika, 35:246-254. W.F. Feller (1950). Introduction Probability Theory Applications, Volume 1, Chapter 6, Wiley. V. V. Patil H.F. Kulkarni (2012).  Comparison confidence intervals poisson mean: new aspects. Revstat 10:211-227.","code":""},{"path":[]},{"path":"/reference/cipoisson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence limits for the Poisson — cipoisson","text":"","code":"cipoisson(4) # 95\\% confidence limit  #>     lower     upper  #>  1.089865 10.241589  # lower    upper   # 1.089865 10.24153  ppois(4, 10.24153)     #chance of seeing 4 or fewer events with large rate   #> [1] 0.02500096 # [1] 0.02500096  1-ppois(3, 1.08986)    #chance of seeing 4 or more, with a small rate  #> [1] 0.02499961 # [1] 0.02499961"},{"path":"/reference/clogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional logistic regression — clogit","title":"Conditional logistic regression — clogit","text":"Estimates logistic regression model maximising conditional   likelihood. Uses model formula form   case.status~exposure+strata(matched.set).   default use exact conditional likelihood, commonly   used approximate conditional likelihood provided compatibility   older software.","code":""},{"path":"/reference/clogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional logistic regression — clogit","text":"","code":"clogit(formula, data, weights, subset, na.action,  method=c(\"exact\", \"approximate\", \"efron\", \"breslow\"),  ...)"},{"path":"/reference/clogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional logistic regression — clogit","text":"formula Model formula data data frame weights optional, names variable containing case weights subset optional, subset data na.action optional na.action argument.  default     global option na.action used. method use correct (exact) calculation conditional     likelihood one approximations ... optional arguments, passed   coxph.control","code":""},{"path":"/reference/clogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional logistic regression — clogit","text":"object class \"clogit\", wrapper  \"coxph\" object.","code":""},{"path":"/reference/clogit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Conditional logistic regression — clogit","text":"Thomas Lumley","code":""},{"path":"/reference/clogit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional logistic regression — clogit","text":"turns loglikelihood conditional logistic   regression model = loglik Cox model particular data   structure.  Proving nice homework exercise PhD   statistics class; hard, fact true   surprising. well tested Cox model routine available many packages use   `trick' rather writing new software routine   scratch, clogit routine .   detail,  stratified Cox model case/control group   assigned stratum, time set constant,   status 1=case 0=control,   using exact partial likelihood likelihood formula   conditional logistic regression.  clogit routine creates   necessary dummy variable times (1) strata,   calls coxph. computation exact partial likelihood can slow,   however.  particular strata say 10 events 20 subjects   add denominator involves possible ways   choosing 10 20, 20!/(10! 10!) = 184756 terms. Gail et   al describe fast recursion method partly ameliorates   ; incorporated version 2.36-11 survival   package.  computation remains infeasible large groups   ties, say 100 ties 500 subjects, may even lead integer   overflow subscripts -- latter case routine   refuse undertake task.  Efron approximation normally   sufficiently accurate substitute. time conditional logistic modeling    applied data 1 case + k controls per set,   case approximations ties lead exactly   result.     'approximate' option maps   Breslow approximation Cox model, historical reasons. Case weights allowed exact option used,   likelihood defined fractional weights.   Even integer case weights clear     handled.  instance   two deaths strata, one weight=1 one   weight=2, likelihood calculation consider subsets   size 2 subsets size 3?   Consequently, case weights ignored routine case.","code":""},{"path":[]},{"path":"/reference/clogit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditional logistic regression — clogit","text":"Michell H Gail, Jay H Lubin Lawrence V Rubinstein.  Likelihood calculations matched case-control studies survival studies tied death times.  Biometrika 68:703-707, 1980. John . Logan. multivariate model mobility tables. J Sociology 89:324-349, 1983.","code":""},{"path":"/reference/clogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional logistic regression — clogit","text":"","code":"if (FALSE) clogit(case ~ spontaneous + induced + strata(stratum), data=infert)  # A multinomial response recoded to use clogit #  The revised data set has one copy per possible outcome level, with new #  variable tocc = target occupation for this copy, and case = whether #  that is the actual outcome for each subject. # See the reference below for the data. resp <- levels(logan$occupation) n <- nrow(logan) indx <- rep(1:n, length(resp)) logan2 <- data.frame(logan[indx,],                      id = indx,                      tocc = factor(rep(resp, each=n))) logan2$case <- (logan2$occupation == logan2$tocc) clogit(case ~ tocc + tocc:education + strata(id), logan2) #> Call: #> clogit(case ~ tocc + tocc:education + strata(id), logan2) #>  #>                                  coef  exp(coef)   se(coef)       z        p #> toccfarm                   -1.8964629  0.1500986  1.3807822  -1.373  0.16961 #> toccoperatives              1.1667502  3.2115388  0.5656465   2.063  0.03914 #> toccprofessional           -8.1005492  0.0003034  0.6987244 -11.593  < 2e-16 #> toccsales                  -5.0292297  0.0065438  0.7700862  -6.531 6.54e-11 #> tocccraftsmen:education    -0.3322842  0.7172835  0.0568682  -5.843 5.13e-09 #> toccfarm:education         -0.3702858  0.6905370  0.1164100  -3.181  0.00147 #> toccoperatives:education   -0.4222188  0.6555906  0.0584328  -7.226 4.98e-13 #> toccprofessional:education  0.2782469  1.3208122  0.0510212   5.454 4.94e-08 #> toccsales:education                NA         NA  0.0000000      NA       NA #>  #> Likelihood ratio test=665.5  on 8 df, p=< 2.2e-16 #> n= 4190, number of events= 838"},{"path":"/reference/cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify clusters. — cluster","title":"Identify clusters. — cluster","text":"special function used context survival models.   identifies correlated groups observations, used right hand  side formula. style now discouraged, use cluster option instead.","code":""},{"path":"/reference/cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify clusters. — cluster","text":"","code":"cluster(x)"},{"path":"/reference/cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify clusters. — cluster","text":"x character, factor, numeric variable.","code":""},{"path":"/reference/cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify clusters. — cluster","text":"x","code":""},{"path":"/reference/cluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify clusters. — cluster","text":"function's action semantic, mark variable  cluster indicator. resulting variance known ``working independence'' variance  GEE model. Note one use frailty term cluster term model, first mixed-effects approach correlation second GEE approach, mix.","code":""},{"path":[]},{"path":"/reference/cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify clusters. — cluster","text":"","code":"marginal.model <- coxph(Surv(time, status) ~ rx, data= rats, cluster=litter,                          subset=(sex=='f')) frailty.model  <- coxph(Surv(time, status) ~ rx + frailty(litter), rats,                          subset=(sex=='f'))"},{"path":"/reference/colon.html","id":null,"dir":"Reference","previous_headings":"","what":"Chemotherapy for Stage B/C colon cancer — colon","title":"Chemotherapy for Stage B/C colon cancer — colon","text":"data one first successful trials     adjuvant chemotherapy colon cancer. Levamisole low-toxicity     compound previously used treat worm infestations animals; 5-FU     moderately toxic (things go) chemotherapy agent.   two records per person, one recurrence one death","code":""},{"path":"/reference/colon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chemotherapy for Stage B/C colon cancer — colon","text":"","code":"colon        data(cancer, package=\"survival\")"},{"path":[]},{"path":"/reference/colon.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Chemotherapy for Stage B/C colon cancer — colon","text":"study originally described Laurie (1989).    main report found Moertel (1990).  data set closest   final report Moertel (1991).    version data less follow-time used    paper Lin (1994). Peter Higgins pointed data inconsistency, revealed    table(colon$nodes, colon$node4).  know    two variables actually correct elected 'fix' .    (Real data warts, example data ?)","code":""},{"path":"/reference/colon.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Chemotherapy for Stage B/C colon cancer — colon","text":"JA Laurie, CG Moertel, TR Fleming, HS Wieand, JE Leigh, J Rubin,   GW McCormack, JB Gerstner, JE Krook J Malliard.  Surgical   adjuvant therapy large-bowel carcinoma: evaluation   levamisole combination levamisole fluorouracil:   North Central Cancer Treatment Group Mayo Clinic.   J Clinical Oncology, 7:1447-1456, 1989. DY Lin.  Cox regression analysis multivariate failure time data:   marginal approach.  Statistics Medicine, 13:2233-2247, 1994. CG Moertel, TR Fleming, JS MacDonald,  DG Haller, JA Laurie, PJ Goodman, JS Ungerleider,  WA Emerson, DC Tormey, JH Glick, MH Veeder JA Maillard.  Levamisole fluorouracil adjuvant therapy  resected colon carcinoma. New England J Medicine, 332:352-358, 1990. CG Moertel,  TR Fleming,  JS MacDonald, DG Haller, JA Laurie, CM Tangen,  JS Ungerleider, WA Emerson, DC Tormey, JH Glick, MH Veeder JA  Maillard, Fluorouracil plus Levamisole effective adjuvant  therapy resection stage II colon carcinoma: final report.  Annals Internal Med, 122:321-326, 1991.","code":""},{"path":"/reference/concordance.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the concordance statistic for data or a model — concordance","title":"Compute the concordance statistic for data or a model — concordance","text":"concordance statistic compute agreement observed response predictor.  closely related Kendall's tau-tau-b, Goodman's gamma, Somers' d, can also calculated results function.","code":""},{"path":"/reference/concordance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the concordance statistic for data or a model — concordance","text":"","code":"concordance(object, ...) # S3 method for formula concordance(object, data, weights, subset, na.action,   cluster, ymin, ymax, timewt= c(\"n\", \"S\", \"S/G\", \"n/G2\", \"I\"),   influence=0, ranks = FALSE, reverse=FALSE, timefix=TRUE, keepstrata=10, ...) # S3 method for lm concordance(object, ..., newdata, cluster, ymin, ymax,   influence=0, ranks=FALSE, timefix=TRUE, keepstrata=10) # S3 method for coxph concordance(object, ..., newdata, cluster, ymin, ymax,   timewt= c(\"n\", \"S\", \"S/G\", \"n/G2\", \"I\"), influence=0,   ranks=FALSE, timefix=TRUE, keepstrata=10) # S3 method for survreg concordance(object, ..., newdata, cluster, ymin, ymax,   timewt= c(\"n\", \"S\", \"S/G\", \"n/G2\", \"I\"), influence=0,   ranks=FALSE, timefix=TRUE, keepstrata=10)"},{"path":"/reference/concordance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the concordance statistic for data or a model — concordance","text":"object fitted model formula.  formula   form y ~x  y ~ x + strata(z) single   numeric survival response single predictor.   Counts concordant, discordant tied pairs    computed separately per stratum, added. data data.frame interpret variables named      formula, subset weights     argument. applicable object formula. weights optional vector case weights.     applicable object formula. subset expression indicating subset rows data used      fit.   applicable object formula. na.action missing-data filter function.  applied model.frame     subset argument used.  Default    options()\\$na.action. applicable object formula. ... multiple fitted models allowed.  applicable     object model object. newdata optional, new data frame evaluate (    refit) models cluster optional grouping vector calculating robust     variance ymin, ymax compute concordance restricted range      ymin <= y <= ymax.  (survival data time range.) timewt weighting applied.  overall statistic       weighted mean event times. influence 1= return dfbeta vector, 2= return full     influence matrix, 3 = return ranks TRUE, return data frame containing     scaled ranks make overall score. reverse TRUE assume larger x values predict     smaller response values y; proportional hazards model     common example , larger hazard = shorter survival. timefix correct possible rounding error.  See     vignette tied times explanation. Essentially, exact ties     important part concordance computatation, \"exact\"     can subtle issue floating point numbers. keepstrata either TRUE, FALSE, integer value.     Computations always done within stratum, added.     total number strata greater keepstrata,     keepstrata=FALSE, subtotals kept output.","code":""},{"path":"/reference/concordance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the concordance statistic for data or a model — concordance","text":"concordance estimate   \\(Pr(x_i < x_j | y_i < y_j)\\),   model fit replace \\(x\\) \\(\\hat y\\),   predicted response model.   survival outcome pairs values   comparable, e.g., censored time 5 death time 6,   know first observation outlive   second.  case total number evaluable pairs smaller. Relatations statistics:   continuous x y, 2C- 1 equal Somers' d.   response binary, C equal area receiver   operating curve AUC.   survival response binary predictor C numerator   Gehan-Wilcoxon test. naive compuation requires adding n(n-1)/2 comparisons,   can quite slow large data sets.   routine uses O(n log(n)) algorithm.   uncensored event time y, compute rank x subject   event compared x values others longer   survival, rank value 0 1.   concordance weighted mean ranks,   determined timewt option. rank vector can   efficiently updated subjects added risk set.   details see vignette. variance based infinetesimal jackknife.  One advantage   approach also gives valid covariance   covariance based multiple different predicted values, even   predictions come quite different models.  See instance   example poisson two non-nested Cox models.   useful compare machine learning model Cox   model fit, say.   absolutely critical, however, predicted values line   exactly, observation row; otherwise result   nonsense.  (alert impact missing values.) timewt option applicable censored data.    case default corresponds Harrell's C statistic,   closely related Gehan-Wilcoxon test;   timewt=\"S\" corrsponds Peto-Wilcoxon,   timewt=\"S/G\" suggested Schemper,   timewt=\"n/G2\" corresponds Uno's C.   turns Schemper Uno weights computationally   identical, retained option labels user convenience.   timewt= \"\" option related log-rank   statistic. number strata large, conditional   logistic regression instance (clogit function), much   faster computation available individual strata results   retained; use keepstrata=FALSE keepstrata=0   . general case keepstrata = 10   default simply keeps printout managable: retains prints   per-strata counts number strata <= 10.","code":""},{"path":"/reference/concordance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the concordance statistic for data or a model — concordance","text":"object class concordance containing following   components: concordance estimated concordance value values count vector containing number concordant pairs,      discordant, tied x y, tied y x, tied      x y n number observations var vector containing estimated variance     concordance based infinitesimal jackknife (IJ) method.     multiple models contains estimtated     variance/covariance matrix. cvar vector containing estimated variance(s)     concordance values, based variance formula associated     score test proportional hazards model.  (primary     variance used survConcordance function.) dfbeta optional, vector leverage estimates      concordance influence optional, matrix leverage values      counts, one row per observation ranks optional, data frame containing Somers' d rank      event time, along time weight, case weight      observation.  time weighted sum ranks equal      concordant pairs - discordant pairs.","code":""},{"path":"/reference/concordance.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the concordance statistic for data or a model — concordance","text":"coxph model numeric failure may undefined   predicted values, case concordance NULL. Computation existing coxph model along newdata   subtleties respect extra arguments original call.   include tt() terms model.  supported newdata. subset.  subset clause original call ignored,     .e., applied new data. strata() terms model.  new data expected     strata variable(s) found original data set,     concordance computed within strata.     levels strata variable need     original data. id cluster directives.  yet sorted .","code":""},{"path":"/reference/concordance.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the concordance statistic for data or a model — concordance","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/concordance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the concordance statistic for data or a model — concordance","text":"F Harrell, R Califf, D Pryor, K Lee R Rosati,    Evaluating yield medical tests, J Medical Assoc, 1982. R Peto J Peto,   Asymptotically efficient rank invariant test procedures (  discussion), J Royal Stat Soc , 1972. M Schemper, Cox analysis survival data non-proportional   hazard functions, Statistician, 1992. H Uno, T Cai, M Pencina, R D'Agnostino Lj Wei,   C-statistics evaluating overall adequacy risk          prediction procedures censored survival data, \tStatistics Medicine, 2011.","code":""},{"path":"/reference/concordance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the concordance statistic for data or a model — concordance","text":"","code":"fit1 <- coxph(Surv(ptime, pstat) ~ age + sex + mspike, mgus2) concordance(fit1, timewt=\"n/G2\")  # Uno's weighting #> Call: #> concordance.coxph(object = fit1, timewt = \"n/G2\") #>  #> n= 1373  #> Concordance= 0.6132 se= 0.1026 #> concordant discordant     tied.x     tied.y    tied.xy  #>  461425.07  290956.09     265.66     120.39       0.00   # logistic regression  fit2 <- glm(I(sex=='M') ~ age + log(creatinine), binomial, data= flchain) concordance(fit2)  # equal to the AUC #> Call: #> concordance.lm(object = fit2) #>  #> n= 6524  #> Concordance= 0.8151 se= 0.005304 #> concordant discordant     tied.x     tied.y    tied.xy  #>    8568768    1931502      31474   10689870      56412   # compare multiple models  options(na.action = na.exclude)   # predict all 1384 obs, including missing fit3 <- glm(pstat ~ age + sex + mspike + offset(log(ptime)),              poisson, data= mgus2) fit4 <- coxph(Surv(ptime, pstat) ~ age + sex + mspike, mgus2) fit5 <- coxph(Surv(ptime, pstat) ~ age + sex + hgb + creat, mgus2)  tdata <- mgus2; tdata$ptime <- 60   # prediction at 60 months p3 <- -predict(fit3, newdata=tdata)  p4 <- -predict(fit4) # high risk scores predict shorter survival p5 <- -predict(fit5) options(na.action = na.omit)      # return to the R default  cfit <- concordance(Surv(ptime, pstat) ~p3 +  p4 + p5, mgus2) cfit #> Call: #> concordance.formula(object = Surv(ptime, pstat) ~ p3 + p4 + p5,  #>     data = mgus2) #>  #> n=1338 (46 observations deleted due to missingness) #>    concordance     se #> p3      0.6598 0.0313 #> p4      0.6618 0.0310 #> p5      0.6000 0.0293 #>  #>    concordant discordant tied.x tied.y tied.xy #> p3      51105      26333     74     28       0 #> p4      51258      26180     74     28       0 #> p5      46507      31003      2     28       0 round(coef(cfit), 3) #>    p3    p4    p5  #> 0.660 0.662 0.600  round(cov2cor(vcov(cfit)), 3)  # high correlation #>       [,1]  [,2]  [,3] #> [1,] 1.000 0.994 0.236 #> [2,] 0.994 1.000 0.258 #> [3,] 0.236 0.258 1.000  test <- c(1, -1, 0)  # contrast vector for model 1 - model 2  round(c(difference = test %*% coef(cfit),         sd= sqrt(test %*% vcov(cfit) %*% test)), 3) #> difference         sd  #>     -0.002      0.003"},{"path":"/reference/concordancefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the concordance — concordancefit","title":"Compute the concordance — concordancefit","text":"working routine behind concordance function.  meant called users, available packages use.  Input arguments, instance, assumed correct length type, missing values allowed: calling routine responsible things.","code":""},{"path":"/reference/concordancefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the concordance — concordancefit","text":"","code":"concordancefit(y, x, strata, weights, ymin = NULL, ymax = NULL,  timewt = c(\"n\", \"S\", \"S/G\", \"n/G2\", \"I\"), cluster, influence =0,  ranks = FALSE, reverse = FALSE, timefix = TRUE, keepstrata=10,   std.err = TRUE)"},{"path":"/reference/concordancefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the concordance — concordancefit","text":"y response.  can numeric, factor, Surv object x predictor, numeric vector strata optional numeric vector stratifies data weights options vector case weights ymin, ymax restrict comparison response values     range timewt time weighting used cluster, influence,ranks, reverse, timefix see help     concordance function keepstrata either TRUE, FALSE, integer value.     Computations always done within stratum, added.     total number strata greater keepstrata,     keepstrata=FALSE, subtotals kept output. std.err compute standard error; saves   compute time.","code":""},{"path":"/reference/concordancefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the concordance — concordancefit","text":"function provided want ``direct'' call   concordance calculations, without using formula interface.    primary use packages.   routine minimal   checking input arguments, assumption   already taken care calling routine.","code":""},{"path":"/reference/concordancefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the concordance — concordancefit","text":"list containing results","code":""},{"path":"/reference/concordancefit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the concordance — concordancefit","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/cox.zph.html","id":null,"dir":"Reference","previous_headings":"","what":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","title":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","text":"Test proportional hazards assumption Cox regression model fit  (coxph).","code":""},{"path":"/reference/cox.zph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","text":"","code":"cox.zph(fit, transform=\"km\", terms=TRUE, singledf=FALSE, global=TRUE)"},{"path":"/reference/cox.zph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","text":"fit result fitting Cox regression model, using     coxph coxme functions. transform character string specifying survival times transformed      test performed.      Possible values \"km\", \"rank\", \"identity\"      function one argument. terms TRUE, test term model rather     separate covariate.  factor variable k levels,     instance, lead k-1 degree freedom test.      plot variables single curve evaluating linear     predictor time. singledf use single degree freedom test terms     multiple coefficients, .e., test corresponds     closely plot.  terms=FALSE argument     effect. global global chi-square test done, addition      per-variable per-term tests tests.","code":""},{"path":"/reference/cox.zph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","text":"object class \"cox.zph\", components: table matrix one row variable, optionally last row  global test.  Columns matrix contain score test addition time-dependent term, degrees freedom, two-sided p-value. x transformed time axis. time untransformed time values; one entry event time data strata stratified coxph model, stratum   events y matrix scaled Schoenfeld residuals.  one column per  term per variable (depending terms option ), one row per event.  row labels rounded form original times. var variance matrix covariates, used create   approximate standard error band plots transform transform time used call calling sequence routine.","code":""},{"path":"/reference/cox.zph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","text":"computations require original x matrix Cox model fit.  Thus saves time x=TRUE option used coxph.  function usually followed plot print  result.  plot gives estimate time-dependent coefficient \\(\\beta(t)\\).  proportional hazards assumption holds true \\(\\beta(t)\\) function  horizontal line. table component provides results formal score test slope=0, linear fit plot approximate test. Random effects terms frailty random effects coxme model checked proportional hazards, rather treated fixed offset model. model contains strata covariate interactions, y matrix may contain structural zeros, .e., deaths (rows) role estimation given coefficient (column). marked NA. entire row NA, instance subscripting cox.zph object, row removed.","code":""},{"path":"/reference/cox.zph.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","text":"versions package survival3.0 function   computed fast approximation score test.  Later versions   compute actual score test.","code":""},{"path":"/reference/cox.zph.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","text":"P. Grambsch T. Therneau (1994),  Proportional hazards tests diagnostics based weighted residuals.  Biometrika, 81, 515-26.","code":""},{"path":[]},{"path":"/reference/cox.zph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test the Proportional Hazards Assumption of a Cox Regression — cox.zph","text":"","code":"fit <- coxph(Surv(futime, fustat) ~ age + ecog.ps,                data=ovarian)  temp <- cox.zph(fit)  print(temp)                  # display the results  #>         chisq df    p #> age     0.698  1 0.40 #> ecog.ps 2.371  1 0.12 #> GLOBAL  3.633  2 0.16 plot(temp)                   # plot curves"},{"path":"/reference/coxph.control.html","id":null,"dir":"Reference","previous_headings":"","what":"Ancillary arguments for controlling coxph fits — coxph.control","title":"Ancillary arguments for controlling coxph fits — coxph.control","text":"used set various numeric parameters controlling Cox model fit. Typically used call coxph.","code":""},{"path":"/reference/coxph.control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ancillary arguments for controlling coxph fits — coxph.control","text":"","code":"coxph.control(eps = 1e-09, toler.chol = .Machine$double.eps^0.75, iter.max = 20, toler.inf = sqrt(eps), outer.max = 10, timefix=TRUE)"},{"path":"/reference/coxph.control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ancillary arguments for controlling coxph fits — coxph.control","text":"eps Iteration continues relative change log partial     likelihood less eps, absolute change less     sqrt(eps).  Must positive. toler.chol Tolerance detection singularity Cholesky decomposition variance matrix, .e., detecting redundant predictor variable. iter.max Maximum number iterations attempt convergence. toler.inf Tolerance criteria warning message possible infinite coefficient value. outer.max penalized coxph model, e.g. pspline terms, outer loop iteration determine penalty parameters; maximum number iterations outer loop. timefix Resolve near ties time variables.","code":""},{"path":"/reference/coxph.control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ancillary arguments for controlling coxph fits — coxph.control","text":"list containing values constants","code":""},{"path":"/reference/coxph.control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ancillary arguments for controlling coxph fits — coxph.control","text":"convergence tolerances balance.  Users think want maximum   point likelihood surface, well behaved data sets   quadratic near max high accuracy fairly inexpensive:   number correct digits approximately doubles iteration.   Conversely, drop .0001 maximum given direction   correspond 1/20 standard error change   coefficient.  Statistically, precision straining   gnat.  Based author originally set tolerance   1e-5, relented face multiple   \"answer different package X\" queries. Asking results close machine precision   (double.eps) fool's errand; reasonable critera often   square root precision.  Cholesky decompostion needs   held higher standard overall convergence criterion, however.   tolerance.inf value controls warning message;   small incorrect warnings can appear, large actual cases   infinite coefficient detected. difficult cases data sets MLE coefficient   infinite; example data set death time,   subject largest   covariate value perished.  situation coefficient   increases iteration log-likelihood asymptotes   maximum.  iteration proceeds race condition   condition three endpoint: exp(coef) overflows,   Hessian matrix become singular, change loglik small   enough satisfy convergence criterion.  first two   difficult anticipate lead numeric diffculties,   another argument moderation choice eps. See vignette \"Roundoff error tied times\"   detailed explanation timefix option.  short,   time intervals created via subtraction two time intervals   actually identical can appear different due floating point   round error, turn can make coxph   survfit results dependent   things order operations done   particular computer run .   cases unfortunatedly rare practice.   timefix=TRUE option adds   logic similar .equal ensure reliable results.   analysis simulated data sets, however, often defintion   can duplicates, option often need set    FALSE avoid spurious merging close numeric values.","code":""},{"path":[]},{"path":"/reference/coxph.detail.html","id":null,"dir":"Reference","previous_headings":"","what":"Details of a Cox Model Fit — coxph.detail","title":"Details of a Cox Model Fit — coxph.detail","text":"Returns individual contributions first second derivative matrix, unique event time.","code":""},{"path":"/reference/coxph.detail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Details of a Cox Model Fit — coxph.detail","text":"","code":"coxph.detail(object, riskmat=FALSE, rorder=c(\"data\", \"time\"))"},{"path":"/reference/coxph.detail.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Details of a Cox Model Fit — coxph.detail","text":"object Cox model object, .e., result coxph. riskmat include -risk indicator matrix output? rorder applicable riskmat=TRUE.  rows    riskmat original data order, sorted time within strata.","code":""},{"path":"/reference/coxph.detail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Details of a Cox Model Fit — coxph.detail","text":"list components time vector unique event times nevent number events time points. means matrix one row event time one column variable     Cox model, containing weighted mean variable time,     subjects still risk time.  weights risk     weights exp(x %*% fit$coef). nrisk number subjects risk. score contribution score vector (first derivative log     partial likelihood) time point. imat contribution information matrix (second derivative     log partial likelihood) time point. hazard hazard increment.  Note hazard variance     hazard always particular future subject.  routine     uses object$mean future subject. varhaz variance hazard increment. x,y copies input data. strata present stratified Cox model,     table giving number time points component time     contributed strata. riskmat matrix one row observation one colum      unique event time,     containing 0/1 value indicate whether observation (1)     (0) risk given time point.  Rows order     original data (removal missings     coxph), time order.","code":""},{"path":"/reference/coxph.detail.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Details of a Cox Model Fit — coxph.detail","text":"function may useful wish investigate new methods extensions Cox model.  example shows one way calculate Schoenfeld residuals.","code":""},{"path":[]},{"path":"/reference/coxph.detail.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Details of a Cox Model Fit — coxph.detail","text":"","code":"fit   <- coxph(Surv(futime,fustat) ~ age + rx + ecog.ps, ovarian, x=TRUE) fitd  <- coxph.detail(fit) #  There is one Schoenfeld residual for each unique death.  It is a # vector (covariates for the subject who died) - (weighted mean covariate # vector at that time).  The weighted mean is defined over the subjects # still at risk, with exp(X beta) as the weight.  events <- fit$y[,2]==1 etime  <- fit$y[events,1]   #the event times --- may have duplicates indx   <- match(etime, fitd$time) schoen <- fit$x[events,] - fitd$means[indx,]"},{"path":"/reference/coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Proportional Hazards Regression Model — coxph","title":"Fit Proportional Hazards Regression Model — coxph","text":"Fits Cox proportional hazards regression model.  Time dependent variables, time dependent strata, multiple events per subject,  extensions incorporated using counting process formulation  Andersen Gill.","code":""},{"path":"/reference/coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Proportional Hazards Regression Model — coxph","text":"","code":"coxph(formula, data=, weights, subset,        na.action, init, control,        ties=c(\"efron\",\"breslow\",\"exact\"),        singular.ok=TRUE, robust,        model=FALSE, x=FALSE, y=TRUE, tt, method=ties,       id, cluster, istate, statedata, nocenter=c(-1, 0, 1), ...)"},{"path":"/reference/coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Proportional Hazards Regression Model — coxph","text":"formula formula object, response left ~ operator,      terms right.  response must survival object      returned Surv function.  multi-state model     formula may list formulas. data data.frame interpret variables named      formula, subset weights     argument. weights vector case weights, see note .     thorough discussion see     book Therneau Grambsch. subset expression indicating subset rows data used      fit.    observations included default. na.action missing-data filter function.  applied model.frame          subset argument used.  Default options()\\$na.action. init vector initial values iteration.  Default initial      value zero variables. control Object class coxph.control specifying iteration limit     control options. Default coxph.control(...). ties character string specifying method tie handling.        tied death times methods equivalent.     Efron approximation used default,      accurate dealing tied death times, efficient      computationally. (see multi-state models.)     ``exact partial likelihood''      equivalent conditional logistic model, appropriate     times small set discrete values. singular.ok logical value indicating handle collinearity model matrix.      TRUE, program automatically skip columns X      matrix linear combinations earlier columns.  case      coefficients columns NA, variance matrix      contain zeros. ancillary calculations, linear     predictor,      missing coefficients treated zeros. robust robust variance computed.     default TRUE : cluster argument,     case weights 0 1, id values     one event. id optional variable name identifies subjects.      necessary subject can multiple rows data,     one event type.  variable normally     found data. cluster optional variable clusters observations,     purposes robust variance.  present, implies     robust.     variable normally found data. istate optional variable giving current state start     interval. variable normally found data. statedata optional data set used describe multistate models. model logical value: TRUE, model frame returned component     model. x logical value: TRUE, x matrix returned     component x. y logical value: TRUE, response vector returned     component y. tt optional list time-transform functions. method alternate name ties argument. nocenter columns X matrix whose values lie strictly     within set recentered.  Remember factor     variable becomes set 0/1 columns. ... arguments passed coxph.control","code":""},{"path":"/reference/coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Proportional Hazards Regression Model — coxph","text":"object class coxph representing fit.  See coxph.object coxphms.object details.","code":""},{"path":"/reference/coxph.html","id":"side-effects","dir":"Reference","previous_headings":"","what":"Side Effects","title":"Fit Proportional Hazards Regression Model — coxph","text":"Depending call, predict, residuals, survfit routines may  need reconstruct x matrix created coxph. possible fail, example predict function unable find tform. case add model=TRUE option coxph call obviate need reconstruction, expense larger fit object.","code":"tfun <- function(tform) coxph(tform, data=lung)   fit <- tfun(Surv(time, status) ~ age)   predict(fit)"},{"path":"/reference/coxph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Proportional Hazards Regression Model — coxph","text":"proportional hazards model usually expressed terms  single survival time value person, possible censoring.  Andersen Gill reformulated problem counting process;  time marches onward observe events subject, rather  like watching Geiger counter.  data subject presented multiple rows \"observations\",   applies interval observation (start, stop]. routine internally scales centers data avoid overflow argument exponential function.  actions change result, lead numerical stability. column X matrix whose values lie within nocenter list recentered.  practical consequence default recenter dummy variables corresponding factors. However, arguments offset scaled since situations large offset value purposefully used. general, however, users avoid large numeric values offset due possible loss precision estimates.","code":""},{"path":"/reference/coxph.html","id":"case-weights","dir":"Reference","previous_headings":"","what":"Case weights","title":"Fit Proportional Hazards Regression Model — coxph","text":"Case weights treated replication weights, .e., case weight 2 equivalent 2 copies subject's observation. computers much smaller grouping like subjects together common trick used conserve memory.  Setting weights 2 instance give coefficient estimate halve variance. Efron approximation ties (default) employed replication data give exactly coefficients weights option, case weighted fit arguably correct one. model includes cluster term robust=TRUE option computed variance treats weights sampling weights; setting weights 2 case give variance weights 1.","code":""},{"path":"/reference/coxph.html","id":"special-terms","dir":"Reference","previous_headings":"","what":"Special terms","title":"Fit Proportional Hazards Regression Model — coxph","text":"three special terms may used model equation.  strata term identifies stratified Cox model; separate baseline  hazard functions fit strata.  cluster term used compute robust variance model.  term + cluster(id) value id unique equivalent  specifying robust=TRUE argument. id variable  unique, assumed identifies clusters correlated observations. robust estimate arises many different arguments thus many labels.  variously known Huber sandwich estimator, White's estimate (linear models/econometrics), Horvitz-Thompson estimate (survey sampling), working independence variance (generalized estimating equations), infinitesimal jackknife, Wei, Lin, Weissfeld (WLW) estimate. time-transform term allows variables vary dynamically time.  case tt argument function list functions (one tt() term model) giving appropriate transform.   See examples . One user mistake recently arisen slavishly follow advice coding guides prepend survival:: onto everthing, including special terms, e.g.,   survival::coxph(survival:Surv(time, status) ~ age +     survival::cluster(inst), data=lung) First, unnecessary: arguments within coxph call evaluated within survival namespace, another package's Surv cluster function noticed. (Full qualification coxph call may protective, however.) Second, importantly, call just give correct answer.  specials recognized name, survival::cluster cluster; model treat inst ordinary variable. similar issue arises using stats::offset term, either survival glm models.","code":""},{"path":"/reference/coxph.html","id":"convergence","dir":"Reference","previous_headings":"","what":"Convergence","title":"Fit Proportional Hazards Regression Model — coxph","text":"certain data cases actual MLE estimate  coefficient infinity, e.g., dichotomous variable one  groups events.  happens associated coefficient  grows steady pace race condition exist fitting  routine: either log likelihood converges, information matrix  becomes effectively singular, argument exp becomes large  computer hardware, maximum number interactions exceeded. (often number 1 first occur.) routine attempts detect happened, always successfully. primary consequence user Wald statistic = coefficient/se(coefficient) valid case ignored; likelihood ratio score tests remain valid however.","code":""},{"path":"/reference/coxph.html","id":"ties","dir":"Reference","previous_headings":"","what":"Ties","title":"Fit Proportional Hazards Regression Model — coxph","text":"three possible choices handling tied event times. Breslow approximation easiest program hence became first option coded almost computer routines. ended default option options added order \"maintain backwards compatability\".  Efron option accurate large number ties, default option . practice number ties usually small, case methods statistically indistinguishable. Using \"exact partial likelihood\" approach Cox partial likelihood equivalent matched logistic regression.  (clogit function uses coxph code fit.) technically appropriate time scale discrete unique values, packages refer \"discrete\" option.  also \"exact marginal likelihood\" due Prentice implemented . calculation exact partial likelihood numerically intense. Say instance 180 subjects risk day 7 15 event; code needs compute sums 180-choose-15 > 10^43 different possible subsets size 15.  efficient recursive algorithm task, even computation can insufferably long.  (start, stop) data much worse since recursion needs start anew unique start time. Multi state models difficult case. First , proper extension Efron argument much difficult , author yet fully convinced resulting algorithm defensible.   Secondly, current code Efron case consistently compute extended logic (extension require major changes code).  Due complexity, default ties='breslow' multistate case. ties='efron' selected current code , effect, apply tied transitions type. separate issue artificial ties due floating-point imprecision. See vignette topic full explanation timefix option coxph.control. Users may need add timefix=FALSE simulated data sets.","code":""},{"path":"/reference/coxph.html","id":"penalized-regression","dir":"Reference","previous_headings":"","what":"Penalized regression","title":"Fit Proportional Hazards Regression Model — coxph","text":"coxph can maximise penalised partial likelihood arbitrary user-defined penalty.  Supplied penalty functions include ridge regression (ridge), smoothing splines (pspline), frailty models (frailty).","code":""},{"path":"/reference/coxph.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Proportional Hazards Regression Model — coxph","text":"Andersen, P. Gill, R. (1982).  Cox's regression model counting processes, large sample study.  Annals Statistics 10, 1100-1120. Therneau, T., Grambsch, P., Modeling Survival Data: Extending Cox Model.  Springer-Verlag, 2000.","code":""},{"path":[]},{"path":"/reference/coxph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Proportional Hazards Regression Model — coxph","text":"","code":"# Create the simplest test data set  test1 <- list(time=c(4,3,1,1,2,2,3),                status=c(1,1,1,0,1,1,0),                x=c(0,2,1,1,1,0,0),                sex=c(0,0,0,0,1,1,1))  # Fit a stratified model  coxph(Surv(time, status) ~ x + strata(sex), test1)  #> Call: #> coxph(formula = Surv(time, status) ~ x + strata(sex), data = test1) #>  #>     coef exp(coef) se(coef)     z     p #> x 0.8023    2.2307   0.8224 0.976 0.329 #>  #> Likelihood ratio test=1.09  on 1 df, p=0.2971 #> n= 7, number of events= 5  # Create a simple data set for a time-dependent model  test2 <- list(start=c(1,2,5,2,1,7,3,4,8,8),                stop=c(2,3,6,7,8,9,9,9,14,17),                event=c(1,1,1,1,1,1,1,0,0,0),                x=c(1,0,0,1,0,1,1,1,0,0))  summary(coxph(Surv(start, stop, event) ~ x, test2))  #> Call: #> coxph(formula = Surv(start, stop, event) ~ x, data = test2) #>  #>   n= 10, number of events= 7  #>  #>       coef exp(coef) se(coef)      z Pr(>|z|) #> x -0.02111   0.97912  0.79518 -0.027    0.979 #>  #>   exp(coef) exp(-coef) lower .95 upper .95 #> x    0.9791      1.021    0.2061     4.653 #>  #> Concordance= 0.526  (se = 0.129 ) #> Likelihood ratio test= 0  on 1 df,   p=1 #> Wald test            = 0  on 1 df,   p=1 #> Score (logrank) test = 0  on 1 df,   p=1 #>   # # Create a simple data set for a time-dependent model # test2 <- list(start=c(1, 2, 5, 2, 1, 7, 3, 4, 8, 8),                 stop =c(2, 3, 6, 7, 8, 9, 9, 9,14,17),                 event=c(1, 1, 1, 1, 1, 1, 1, 0, 0, 0),                 x    =c(1, 0, 0, 1, 0, 1, 1, 1, 0, 0) )   summary( coxph( Surv(start, stop, event) ~ x, test2)) #> Call: #> coxph(formula = Surv(start, stop, event) ~ x, data = test2) #>  #>   n= 10, number of events= 7  #>  #>       coef exp(coef) se(coef)      z Pr(>|z|) #> x -0.02111   0.97912  0.79518 -0.027    0.979 #>  #>   exp(coef) exp(-coef) lower .95 upper .95 #> x    0.9791      1.021    0.2061     4.653 #>  #> Concordance= 0.526  (se = 0.129 ) #> Likelihood ratio test= 0  on 1 df,   p=1 #> Wald test            = 0  on 1 df,   p=1 #> Score (logrank) test = 0  on 1 df,   p=1 #>   # Fit a stratified model, clustered on patients   bladder1 <- bladder[bladder$enum < 5, ]  coxph(Surv(stop, event) ~ (rx + size + number) * strata(enum),       cluster = id, bladder1) #> Call: #> coxph(formula = Surv(stop, event) ~ (rx + size + number) * strata(enum),  #>     data = bladder1, cluster = id) #>  #>                               coef exp(coef) se(coef) robust se      z       p #> rx                        -0.52598   0.59097  0.31583   0.31524 -1.669 0.09521 #> size                       0.06961   1.07209  0.10156   0.08863  0.785 0.43220 #> number                     0.23818   1.26894  0.07588   0.07459  3.193 0.00141 #> rx:strata(enum)enum=2     -0.10633   0.89913  0.50424   0.33396 -0.318 0.75019 #> rx:strata(enum)enum=3     -0.17251   0.84155  0.55780   0.39868 -0.433 0.66523 #> rx:strata(enum)enum=4     -0.10945   0.89632  0.65730   0.50636 -0.216 0.82886 #> size:strata(enum)enum=2   -0.14737   0.86298  0.16803   0.11409 -1.292 0.19646 #> size:strata(enum)enum=3   -0.28345   0.75318  0.20894   0.15220 -1.862 0.06255 #> size:strata(enum)enum=4   -0.27607   0.75876  0.25222   0.18904 -1.460 0.14418 #> number:strata(enum)enum=2 -0.10125   0.90370  0.11904   0.11759 -0.861 0.38920 #> number:strata(enum)enum=3 -0.06467   0.93738  0.12925   0.12035 -0.537 0.59101 #> number:strata(enum)enum=4  0.09429   1.09888  0.14594   0.11973  0.788 0.43097 #>  #> Likelihood ratio test=30.09  on 12 df, p=0.002708 #> n= 340, number of events= 112   # Fit a time transform model using current age coxph(Surv(time, status) ~ ph.ecog + tt(age), data=lung,      tt=function(x,t,...) pspline(x + t/365.25)) #> Call: #> coxph(formula = Surv(time, status) ~ ph.ecog + tt(age), data = lung,  #>     tt = function(x, t, ...) pspline(x + t/365.25)) #>  #>                    coef se(coef)     se2   Chisq   DF       p #> ph.ecog          0.4528   0.1178  0.1174 14.7704 1.00 0.00012 #> tt(age), linear  0.0112   0.0093  0.0093  1.4414 1.00 0.22991 #> tt(age), nonlin                           2.6992 3.08 0.45431 #>  #> Iterations: 4 outer, 10 Newton-Raphson #>      Theta= 0.796  #> Degrees of freedom for terms= 1.0 4.1  #> Likelihood ratio test=22.5  on 5.07 df, p=5e-04 #> n= 227, number of events= 164  #>    (1 observation deleted due to missingness)"},{"path":"/reference/coxph.object.html","id":null,"dir":"Reference","previous_headings":"","what":"Proportional Hazards Regression Object — coxph.object","title":"Proportional Hazards Regression Object — coxph.object","text":"class objects returned coxph class functions  represent fitted proportional hazards model.  Objects class methods functions print,  summary, residuals, predict survfit.","code":""},{"path":"/reference/coxph.object.html","id":"components","dir":"Reference","previous_headings":"","what":"Components","title":"Proportional Hazards Regression Object — coxph.object","text":"following components must included legitimate coxph  object.","code":""},{"path":"/reference/coxph.object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proportional Hazards Regression Object — coxph.object","text":"coefficients vector coefficients.   model -determined missing    values vector corresponding redundant columns model    matrix. var variance matrix coefficients.  Rows columns corresponding  missing coefficients set zero. naive.var component present robust option true.  ,  var component contain robust estimate variance,  component contain ordinary estimate. (far better name asymp.var since contains model-based asympotitic variance estimate, necessarily \"naive\"; ship sailed.) loglik vector length 2 containing log-likelihood initial values  final values coefficients. score value efficient score test, initial value coefficients. rscore robust log-rank statistic, robust variance requested. wald.test Wald test whether final coefficients differ initial values. iter number iterations used. linear.predictors vector linear predictors, one per subject.  Note   vector centered, see predict.coxph details. residuals martingale residuals. means vector values used reference covariate.   instance, later call predict(fit, type='risk')   give hazard ratio observation reference.   (covariates contain mean.) n number observations used fit. nevent number events (usually deaths) used fit. concordance vector length 6, containing number pairs   concordant, discordant, tied x, tied y, tied ,   followed standard error concordance statistic. first first derivative vector solution. weights vector case weights, one used. method method used handling tied survival times. na.action na.action attribute, , returned na.action  routine. timefix value timefix option used fit ... object also contain following, documentation see lm  object: terms, assign, formula, call, , optionally, x, y,  /frame.","code":""},{"path":[]},{"path":"/reference/coxph.wtest.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a quadratic form — coxph.wtest","title":"Compute a quadratic form — coxph.wtest","text":"function used internally several survival routines.    computes simple quadratic form, properly dealing missings.","code":""},{"path":"/reference/coxph.wtest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a quadratic form — coxph.wtest","text":"","code":"coxph.wtest(var, b, toler.chol = 1e-09)"},{"path":"/reference/coxph.wtest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a quadratic form — coxph.wtest","text":"var variance matrix b vector toler.chol tolerance internal cholesky decomposition","code":""},{"path":"/reference/coxph.wtest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute a quadratic form — coxph.wtest","text":"Compute b' V-inverse b.  Equivalent sum(b * solve(V,b)), except   case redundant covariates original model, lead   NA values V b.","code":""},{"path":"/reference/coxph.wtest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a quadratic form — coxph.wtest","text":"real number","code":""},{"path":"/reference/coxph.wtest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute a quadratic form — coxph.wtest","text":"Terry Therneau","code":""},{"path":"/reference/coxphms.object.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-state Proportional Hazards Regression Object — coxphms.object","title":"Multi-state Proportional Hazards Regression Object — coxphms.object","text":"class objects returned coxph class functions  represent fitted hazards model, model multiple states.  object inherits coxph class.","code":""},{"path":"/reference/coxphms.object.html","id":"components","dir":"Reference","previous_headings":"","what":"Components","title":"Multi-state Proportional Hazards Regression Object — coxphms.object","text":"object components coxph object,   following additions variations.","code":""},{"path":"/reference/coxphms.object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-state Proportional Hazards Regression Object — coxphms.object","text":"states character vector listing states model cmap coefficient map. matrix containing   column transition row coefficient, value   maps transition/coefficient pair position coefficient   vector.   particular covariate used transition matrix   contain zero position, two transitions share   coefficient matrix contain repeats. smap stratum map.   row labeled `(Baseline)' identifies transitions   share baseline hazard.  rows correspond strata() terms   model, may apply transitions others. rmap mapping residuals linear predictors.  two   column matrix one row element vectors   two columns, first contains data row second   transition.","code":""},{"path":"/reference/coxphms.object.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multi-state Proportional Hazards Regression Object — coxphms.object","text":"multi-state model set intermediate observations created   computation, separate set data rows   transition.  observation (id time interval) risk   one transition instance linear predictor   residual potential transitions.  result vector   linear predictors longer number observations.   rmap matrix shows mapping.","code":""},{"path":[]},{"path":"/reference/coxsurv.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"A direct interface to the `computational engine' of survfit.coxph — coxsurv.fit","title":"A direct interface to the `computational engine' of survfit.coxph — coxsurv.fit","text":"program mainly supplied allow packages invoke   survfit.coxph function `data' level rather `user' level.   checks input data provided, can lead   unexpected errors data wrong.","code":""},{"path":"/reference/coxsurv.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A direct interface to the `computational engine' of survfit.coxph — coxsurv.fit","text":"","code":"coxsurv.fit(ctype, stype, se.fit, varmat, cluster,              y, x, wt, risk, position, strata, oldid,             y2, x2, risk2, strata2, id2, unlist=TRUE)"},{"path":"/reference/coxsurv.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A direct interface to the `computational engine' of survfit.coxph — coxsurv.fit","text":"stype survival curve computation: 1=direct, 2=exp(-cumulative     hazard) ctype cumulative hazard computation: 1=Breslow, 2=Efron se.fit TRUE, compute standard errors varmat variance matrix coefficients cluster vector control robust variance y response variable used Cox model.  (Missing values     removed course.) x covariate matrix used Cox model wt weight vector Cox model. model unweighted     use vector 1s. risk risk score exp(X beta + offset) fitted Cox model. position optional argument controlling counted     'censored'.  Due time dependent covariates, instance,     subject might start, stop times (1,5)(5,30)(30,100).  Times     5 30 'real' censorings.  Position 1 real start,     2 actual end, 3 , 0 neither. strata strata variable used Cox model.     factor. oldid identifier subjects multiple rows     original data. y2, x2, risk2, strata2 variables hypothetical subjects,     prediction desired id2 optional; present NULL     vector identifiers length nrow(x2).     non-null value signifies x2 contains time dependent     covariates, case identifies rows x2 go     subject. unlist FALSE result list one     element strata.  Otherwise strata ``unpacked''     form found survfit object.","code":""},{"path":"/reference/coxsurv.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A direct interface to the `computational engine' of survfit.coxph — coxsurv.fit","text":"list containing nearly components survfit object.  missing add confidence intervals,   type original model's response (coxph object),   class.","code":""},{"path":"/reference/coxsurv.fit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"A direct interface to the `computational engine' of survfit.coxph — coxsurv.fit","text":"source code function   survfit.coxph written using noweb.  complete   documentation see inst/sourcecode.pdf file.","code":""},{"path":"/reference/coxsurv.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A direct interface to the `computational engine' of survfit.coxph — coxsurv.fit","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/diabetic.html","id":null,"dir":"Reference","previous_headings":"","what":"Ddiabetic retinopathy — diabetic","title":"Ddiabetic retinopathy — diabetic","text":"Partial results trial laser coagulation treatment   diabetic retinopathy.","code":""},{"path":"/reference/diabetic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ddiabetic retinopathy — diabetic","text":"","code":"diabetic data(diabetic, package=\"survival\")"},{"path":"/reference/diabetic.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Ddiabetic retinopathy — diabetic","text":"data frame 394 observations following 8 variables. id subject id laser laser type: xenon argon age age diagnosis eye factor levels left right trt treatment: 0 = treatment, 1= laser risk risk group 6-12 time time event last follow-status status 0= censored 1 = visual loss","code":""},{"path":"/reference/diabetic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ddiabetic retinopathy — diabetic","text":"197 patients dataset 50% random sample patients \"high-risk\" diabetic retinopathy defined Diabetic Retinopathy Study (DRS).  patient one eye randomized laser treatment eye received treatment.  eye, event interest time initiation treatment time visual acuity dropped 5/200 two visits row. Thus built-lag time approximately 6 months (visits every 3 months).  Survival times dataset therefore actual time blindness months, minus minimum possible time event (6.5 months).  Censoring caused death, dropout, end study.","code":""},{"path":"/reference/diabetic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ddiabetic retinopathy — diabetic","text":"Huster, Brookmeyer Self, Biometrics, 1989. American Journal Ophthalmology, 1976, 81:4, pp 383-396","code":""},{"path":"/reference/diabetic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ddiabetic retinopathy — diabetic","text":"","code":"# juvenile diabetes is defined as and age less than 20 juvenile <- 1*(diabetic$age < 20) coxph(Surv(time, status) ~ trt + juvenile, cluster= id,             data= diabetic) #> Call: #> coxph(formula = Surv(time, status) ~ trt + juvenile, data = diabetic,  #>     cluster = id) #>  #>              coef exp(coef) se(coef) robust se      z        p #> trt      -0.77893   0.45890  0.16893   0.14851 -5.245 1.56e-07 #> juvenile -0.05388   0.94754  0.16211   0.17864 -0.302    0.763 #>  #> Likelihood ratio test=22.48  on 2 df, p=1.312e-05 #> n= 394, number of events= 155"},{"path":"/reference/dsurvreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Distributions available in survreg. — dsurvreg","title":"Distributions available in survreg. — dsurvreg","text":"Density, cumulative distribution function, quantile function random   generation set distributions   supported survreg function.","code":""},{"path":"/reference/dsurvreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distributions available in survreg. — dsurvreg","text":"","code":"dsurvreg(x, mean, scale=1, distribution='weibull', parms) psurvreg(q, mean, scale=1, distribution='weibull', parms) qsurvreg(p, mean, scale=1, distribution='weibull', parms) rsurvreg(n, mean, scale=1, distribution='weibull', parms)"},{"path":"/reference/dsurvreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distributions available in survreg. — dsurvreg","text":"x vector quantiles.  Missing values (NAs) allowed. q vector quantiles.  Missing values (NAs) allowed. p vector probabilities.  Missing values (NAs) allowed. n number random deviates produce mean vector location (linear predictor) parameters model.   replicated length p, q n. scale vector (positive) scale factors. replicated length p, q n. distribution character string giving name distribution.  must one elements survreg.distributions parms optional parameters, , distribution.  t-distribution degrees freedom.","code":""},{"path":"/reference/dsurvreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distributions available in survreg. — dsurvreg","text":"density (dsurvreg),  probability (psurvreg),  quantile (qsurvreg),  requested distribution mean scale parameters mean  sd.","code":""},{"path":"/reference/dsurvreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distributions available in survreg. — dsurvreg","text":"Elements q  p missing cause corresponding  elements result missing. location scale values survreg. label \"mean\" unfortunate choice (made mimicry qnorm); correct label \"linear predictor\".   Since almost none distributions symmetric location parameter actually mean. survreg routines use parameterization found chapter 2 Kalbfleisch Prentice.  Translation usual parameterization found textbook always obvious. example, Weibull distribution cumulative distribution function \\(F(t) = 1 - e^{-(\\lambda t)^p}\\)1 - exp((-lambda t)^p). actual fit uses fact \\(\\log(t)\\) extreme value distribution, location scale \\(\\alpha, \\sigma\\), location scale parameters reported survreg function. parameters related \\(\\sigma= 1/p\\) \\(\\alpha = -\\log(\\lambda\\). stats::dweibull routine parameterized terms shape scale parameters correspond \\(p\\) \\(1/\\lambda\\) K P notation. Combining see shape = \\(1/\\sigma\\) scale = \\(\\exp{alpha}\\).","code":""},{"path":"/reference/dsurvreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distributions available in survreg. — dsurvreg","text":"Kalbfleisch, J. D. Prentice, R. L. (1970). Statistical Analysis Failure Time Data Wiley, New York.","code":""},{"path":[]},{"path":"/reference/dsurvreg.html","id":"references-1","dir":"Reference","previous_headings":"","what":"References","title":"Distributions available in survreg. — dsurvreg","text":"Kalbfleisch, J. D. Prentice, R. L., statistical analysis   failure time data, Wiley, 2002.","code":""},{"path":[]},{"path":"/reference/finegray.html","id":null,"dir":"Reference","previous_headings":"","what":"Create data for a Fine-Gray model — finegray","title":"Create data for a Fine-Gray model — finegray","text":"Fine-Gray model can fit first creating special data set,   fitting weighted Cox model result.  routine creates   data set.","code":""},{"path":"/reference/finegray.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create data for a Fine-Gray model — finegray","text":"","code":"finegray(formula, data, weights, subset, na.action= na.pass, etype,     prefix=\"fg\", count, id, timefix=TRUE)"},{"path":"/reference/finegray.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create data for a Fine-Gray model — finegray","text":"formula standard model formula, survival left     covariates right. data optional data frame, list environment (object   coercible .data.frame data frame) containing variables   model. weights optional vector observation weights subset optional vector specifying subset observations used     fitting process. na.action function indicates happen data contain     NAs.  default set na.action setting options. etype event type data set generated.  default    use whichever listed first multi-state survival object. prefix routine add 4 variables data set: start    end time interval, status, weight    interval. default names \"fgstart\", \"fgstop\", \"fgstatus\",    \"fgwt\"; prefix argument determines initial portion    new names. count variable name output data set optional    variable contain   replication count row input data.  row   expanded multiple lines contain 1, 2, etc. id optional, variable name data set identifies   subjects. timefix process times aeqSurv function   eliminate potential roundoff issues.","code":""},{"path":"/reference/finegray.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create data for a Fine-Gray model — finegray","text":"function expects multi-state survival expression variable   left hand side formula, e.g. Surv(atime, astat)   astat factor whose first level represents censoring   remaining levels states.  output data set contain simple   survival data (status = 0 1) single endpoint interest.   exposition   call endpoint lump others endpoint B.   output data set subjects experience endpoint B become   censored observations    whose times artificially extended right,   decreasing case weight interval interval.     output data set normally contain many rows   input. algorithm allows delayed entry, limited form   time-dependent covariates.  , subjects endpoint B   extended, future covariate values stay constant;   implicit assumption changes occurred   event intervened follow-longer.    predictable time-dependent covariates final data set   processed fix , included   function.  Geskus example considers example different   calendar epochs, corresponding change standard medical   practice disese, covariate.   dependent covariates.     time dependent covariates delayed entry, e.g.., input data   set Surv(entry, exit, stat) left hand side,   id statement required.  program data checks   case, needs know rows belong subject. output data set often gaps. Say events   time 50 100 (none ) censoring 60, 70, 80.   Formally, non event subjects risk 50 100   different weights   3 intervals 50-60, 60-70, 80-100, middle   interval span event times subsequent Cox model   never use row.  finegray output omits rows. See competing risks vignette details.","code":""},{"path":"/reference/finegray.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create data for a Fine-Gray model — finegray","text":"data frame","code":""},{"path":"/reference/finegray.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create data for a Fine-Gray model — finegray","text":"Fine JP Gray RJ (1999) proportional hazards model   subdistribution competing risk. JASA 94:496-509. Geskus RB (2011). Cause-Specific Cumulative Incidence Estimation   Fine Gray Model Left Truncation Right Censoring.   Biometrics 67, 39-49.","code":""},{"path":"/reference/finegray.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create data for a Fine-Gray model — finegray","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/finegray.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create data for a Fine-Gray model — finegray","text":"","code":"# Treat time to death and plasma cell malignancy as competing risks etime <- with(mgus2, ifelse(pstat==0, futime, ptime)) event <- with(mgus2, ifelse(pstat==0, 2*death, 1)) event <- factor(event, 0:2, labels=c(\"censor\", \"pcm\", \"death\"))  # FG model for PCM pdata <- finegray(Surv(etime, event) ~ ., data=mgus2) fgfit <- coxph(Surv(fgstart, fgstop, fgstatus) ~ age + sex,                      weight=fgwt, data=pdata)  # Compute the weights separately by sex adata <- finegray(Surv(etime, event) ~ . + strata(sex),              data=mgus2, na.action=na.pass)"},{"path":"/reference/flchain.html","id":null,"dir":"Reference","previous_headings":"","what":"Assay of serum free light chain for 7874 subjects. — flchain","title":"Assay of serum free light chain for 7874 subjects. — flchain","text":"stratified random sample containing 1/2 subjects   study relationship serum free light chain (FLC)   mortality.  original sample contains samples   approximately 2/3 residents Olmsted County aged 50 greater.","code":""},{"path":"/reference/flchain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assay of serum free light chain for 7874 subjects. — flchain","text":"","code":"flchain data(flchain, package=\"survival\")"},{"path":"/reference/flchain.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Assay of serum free light chain for 7874 subjects. — flchain","text":"data frame 7874 persons containing following variables. age age years sex F=female, M=male sample.yr calendar year blood sample       obtained kappa serum free light chain, kappa portion lambda serum free light chain, lambda portion flc.grp FLC group subject, used       original analysis creatinine serum creatinine mgus 1 subject diagnosed       monoclonal gammapothy (MGUS) futime days enrollment death.  Note       3 subjects whose sample obtained death date. death 0=alive last contact date, 1=dead chapter died, grouping       primary cause death chapter headings International       Code Diseases ICD-9","code":""},{"path":"/reference/flchain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assay of serum free light chain for 7874 subjects. — flchain","text":"1995 Dr. Robert Kyle embarked study determine   prevalence monoclonal gammopathy undetermined significance   (MGUS) Olmsted County, Minnesota, condition   normally found chance test (serum electrophoresis)   ordered causes.  Later work suggested one   component immunoglobulin production, serum free light chain,   might possible marker immune disregulation.  2010   Dr. Angela Dispenzieri colleagues assayed FLC levels   samples original study patient permission   sufficient material remained testing.  found   elevated FLC levels indeed associated higher death   rates. Patients recruited came clinic   appointments, final random sample yet   visit since study began.  interesting side question   whether differences early, mid, late recruits. data set contains age sex stratified random sample   includes 7874 original 15759 subjects.  original subject   identifiers dates removed protect patient identity.   Subsampling done protect information.","code":""},{"path":"/reference/flchain.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Assay of serum free light chain for 7874 subjects. — flchain","text":"primary investigator (Dispenzieri) statistician (T   Therneau) study.","code":""},{"path":"/reference/flchain.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Assay of serum free light chain for 7874 subjects. — flchain","text":"Dispenzieri, J Katzmann, R Kyle, D Larson, T Therneau, C Colby,          R Clark, G Mead, S Kumar,           LJ Melton III  SV Rajkumar (2012).     Use monclonal serum immunoglobulin free light chains predict              overall survival general population,     Mayo Clinic Proceedings 87:512-523. R Kyle, T Therneau, SV Rajkumar,             D Larson, M Plevak, J Offord,             Dispenzieri, J Katzmann, LJ Melton, III, 2006, \t    Prevalence monoclonal gammopathy undetermined significance, \t    New England J Medicine 354:1362-1369.","code":""},{"path":"/reference/flchain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assay of serum free light chain for 7874 subjects. — flchain","text":"","code":"data(flchain) age.grp <-  cut(flchain$age, c(49,54, 59,64, 69,74,79, 89, 110),                labels= paste(c(50,55,60,65,70,75,80,90),                              c(54,59,64,69,74,79,89,109), sep='-')) table(flchain$sex, age.grp) #>    age.grp #>     50-54 55-59 60-64 65-69 70-74 75-79 80-89 90-109 #>   F   881   766   625   589   541   408   459     81 #>   M   796   714   591   524   405   269   202     23"},{"path":"/reference/frailty.html","id":null,"dir":"Reference","previous_headings":"","what":"Random effects terms — frailty","title":"Random effects terms — frailty","text":"frailty function allows one add simple random effects term Cox model.","code":""},{"path":"/reference/frailty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random effects terms — frailty","text":"","code":"frailty(x, distribution=\"gamma\", ...) frailty.gamma(x, sparse = (nclass > 5), theta, df, eps = 1e-05,          method = c(\"em\",\"aic\", \"df\", \"fixed\"), ...)  frailty.gaussian(x, sparse = (nclass > 5), theta, df,          method =c(\"reml\",\"aic\", \"df\", \"fixed\"), ...) frailty.t(x, sparse = (nclass > 5), theta, df, eps = 1e-05, tdf = 5,          method = c(\"aic\", \"df\", \"fixed\"), ...)"},{"path":"/reference/frailty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random effects terms — frailty","text":"x variable entered random effect.       always treated factor. distribution either gamma,      gaussian t     distribution may specified.     routines frailty.gamma,     frailty.gaussian      frailty.t actual work. ... Arguments specific distribution, including (    limited ) sparse cutoff using sparse coding data matrix.       total number levels x larger     value, sparse matrix approximation used.     correct cutoff still matter exploration: number     levels large (thousands) non-sparse calculation may     feasible terms memory compute time.     Likewise, accuracy sparse approximation appears related     maximum proportion subjects one class, best     one class large membership. theta specified, fixes variance random effect.     , variance parameter, best solution sought.     Specifying implies method='fixed'. df specified, fixes degrees freedom random effect.     Specifying implies method='df'.     one theta      df specified. method method used select solution theta, variance     random effect.       fixed corresponds user-specified     value, iteration done.     df selects variance     degrees freedom random effect matches user specified value.     aic method seeks      maximize Akaike's information criteria      2*(partial likelihood - df).     em reml     methods specific Cox models gamma gaussian random effects,     respectively.     Please see discussion . tdf degrees freedom t-distribution. eps convergence criteria iteration theta.","code":""},{"path":"/reference/frailty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random effects terms — frailty","text":"function used model statement either coxph survreg. results used internally.","code":""},{"path":"/reference/frailty.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random effects terms — frailty","text":"frailty plugs general penalized modeling framework provided coxph  survreg routines.   framework deals likelihood, penalties, degrees freedom; aspects work well either parent routine. Therneau, Grambsch, Pankratz show maximum likelihood estimation Cox model gamma frailty can accomplished using general penalized routine, Ripatti Palmgren work similar argument Cox model gaussian frailty.  specific Cox model.   Use gamma/ml gaussian/reml  survreg lead valid results. extensible structure penalized methods penalty function, frailty pspine, completely separate modeling routine.  strength user can plug penalization routine choose.  weakness difficult modeling routine know whether sensible penalty routine supplied. Note use frailty term implies mixed effects model use cluster term implies GEE approach; mixed. coxme package superseded method.  faster, stable, flexible.","code":""},{"path":"/reference/frailty.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random effects terms — frailty","text":"S Ripatti J Palmgren, Estimation multivariate frailty  models using penalized partial likelihood, Biometrics, 56:1016-1022, 2000. T Therneau, P Grambsch VS Pankratz, Penalized survival models frailty, J Computational Graphical Statistics, 12:156-175, 2003.","code":""},{"path":[]},{"path":"/reference/frailty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random effects terms — frailty","text":"","code":"# Random institutional effect coxph(Surv(time, status) ~ age + frailty(inst, df=4), lung) #> Call: #> coxph(formula = Surv(time, status) ~ age + frailty(inst, df = 4),  #>     data = lung) #>  #>                          coef se(coef)     se2   Chisq   DF     p #> age                   0.01937  0.00933 0.00925 4.31149 1.00 0.038 #> frailty(inst, df = 4)                          3.33459 3.99 0.501 #>  #> Iterations: 3 outer, 10 Newton-Raphson #>      Variance of random effect= 0.038   I-likelihood = -743.6  #> Degrees of freedom for terms= 1 4  #> Likelihood ratio test=9.96  on 4.97 df, p=0.08 #> n= 227, number of events= 164  #>    (1 observation deleted due to missingness)  # Litter effects for the rats data rfit2a <- coxph(Surv(time, status) ~ rx +                   frailty.gaussian(litter, df=13, sparse=FALSE), rats,                   subset= (sex=='f')) rfit2b <- coxph(Surv(time, status) ~ rx +                   frailty.gaussian(litter, df=13, sparse=TRUE), rats,                   subset= (sex=='f'))"},{"path":"/reference/gbsg.html","id":null,"dir":"Reference","previous_headings":"","what":"Breast cancer data sets used in Royston and Altman (2013) — gbsg","title":"Breast cancer data sets used in Royston and Altman (2013) — gbsg","text":"gbsg data set contains patient records 1984-1989 trial  conducted German Breast Cancer Study Group (GBSG) 720 patients node positive breast cancer; retains 686 patients  complete data prognostic variables.","code":""},{"path":"/reference/gbsg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Breast cancer data sets used in Royston and Altman (2013) — gbsg","text":"","code":"gbsg data(cancer, package=\"survival\")"},{"path":"/reference/gbsg.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Breast cancer data sets used in Royston and Altman (2013) — gbsg","text":"data set 686 observations 11 variables. pid patient identifier age age, years meno menopausal status (0= premenopausal, 1= postmenopausal) size tumor size, mm grade tumor grade nodes number positive lymph nodes pgr progesterone receptors (fmol/l) er estrogen receptors (fmol/l) hormon hormonal therapy, 0= , 1= yes rfstime recurrence free survival time; days first reccurence, death last follow-status 0= alive without recurrence, 1= recurrence death","code":""},{"path":"/reference/gbsg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Breast cancer data sets used in Royston and Altman (2013) — gbsg","text":"data sets used paper Royston Altman. Rotterdam data used create fitted model, GBSG data  validation model.  paper gives references data source.","code":""},{"path":[]},{"path":"/reference/gbsg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Breast cancer data sets used in Royston and Altman (2013) — gbsg","text":"Patrick Royston Douglas Altman, External validation Cox prognostic model: principles methods.  BMC Medical Research Methodology 2013, 13:33","code":""},{"path":"/reference/heart.html","id":null,"dir":"Reference","previous_headings":"","what":"Stanford Heart Transplant data — heart","title":"Stanford Heart Transplant data — heart","text":"Survival patients waiting list Stanford   heart transplant program.","code":""},{"path":"/reference/heart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stanford Heart Transplant data — heart","text":"","code":"heart data(heart, package=\"survival\")"},{"path":"/reference/heart.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Stanford Heart Transplant data — heart","text":"jasa: original data jasa1, heart: processed data","code":""},{"path":[]},{"path":"/reference/heart.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Stanford Heart Transplant data — heart","text":"J Crowley M Hu (1977),   Covariance analysis heart transplant survival data.   Journal American Statistical Association,   72, 27--36.","code":""},{"path":"/reference/hoel.html","id":null,"dir":"Reference","previous_headings":"","what":"Mouse cancer data — hoel","title":"Mouse cancer data — hoel","text":"Days occurence cancer male mice","code":""},{"path":"/reference/hoel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mouse cancer data — hoel","text":"","code":"data(\"cancer\")"},{"path":"/reference/hoel.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mouse cancer data — hoel","text":"data frame 181 observations following 4 variables. trt treatment assignment: Control Germ-free days days death outcome outcome: codecensor, thymic \tlymphoma, reticulum cell sarcoma causes id mouse id","code":""},{"path":"/reference/hoel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mouse cancer data — hoel","text":"Two groups male mice given 300 rads radiation followed   cancer incidence.  One group maintained germ free   environment.  data set used example competing risks   Kalbfleisch Prentice.  germ-free environment little effect   rate occurence thymic lymphoma, significantly delays   causes death.","code":""},{"path":"/reference/hoel.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Mouse cancer data — hoel","text":"Ontology Search website defines reticulm cell sarcoma   \"antiquated term refers non-Hodgkin lymphoma composed   diffuse infiltrates large, often anaplastic lymphocytes\".","code":""},{"path":"/reference/hoel.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Mouse cancer data — hoel","text":"data can found appendix Kalbfleisch Prentice.","code":""},{"path":"/reference/hoel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mouse cancer data — hoel","text":"Hoel, D.G. (1972), representation mortality data competing risks.  Biometrics 33, 1-30. Kalbfleisch, J.D. Prentice, R.L. (1980). statistical analysis failure time data.","code":""},{"path":"/reference/hoel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mouse cancer data — hoel","text":"","code":"hsurv <- survfit(Surv(days, outcome) ~ trt, data = hoel, id= id) #> Error in eval(expr, p): object 'hoel' not found plot(hsurv, lty=1:2, col=rep(1:3, each=2), lwd=2, xscale=30.5,       xlab=\"Months\", ylab= \"Death\") #> Error in eval(expr, envir, enclos): object 'hsurv' not found legend(\"topleft\", c(\"Lymphoma control\", \"Lymphoma germ free\",                     \"Sarcoma control\", \"Sarcoma germ free\",                     \"Other control\", \"Other germ free\"),        col=rep(1:3, each=2), lty=1:2, lwd=2, bty='n') #> Error in (function (s, units = \"user\", cex = NULL, font = NULL, vfont = NULL,     ...) {    if (!is.null(vfont))         vfont <- c(typeface = pmatch(vfont[1L], Hershey$typeface),             fontindex = pmatch(vfont[2L], Hershey$fontindex))    .External.graphics(C_strWidth, as.graphicsAnnot(s), pmatch(units,         c(\"user\", \"figure\", \"inches\")), cex, font, vfont, ...)})(dots[[1L]][[1L]], cex = dots[[2L]][[1L]], font = dots[[3L]][[1L]],     units = \"user\"): plot.new has not been called yet hfit <- coxph(Surv(days, outcome) ~ trt, data= hoel, id = id) #> Error in eval(expr, envir, enclos): object 'hoel' not found"},{"path":"/reference/is.ratetable.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify that an object is of class ratetable. — is.ratetable","title":"Verify that an object is of class ratetable. — is.ratetable","text":"function verifies class attribute,  structure object.","code":""},{"path":"/reference/is.ratetable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify that an object is of class ratetable. — is.ratetable","text":"","code":"is.ratetable(x, verbose=FALSE)"},{"path":"/reference/is.ratetable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify that an object is of class ratetable. — is.ratetable","text":"x object verified. verbose TRUE object ratetable,  return character string describing way(s) x  fails proper ratetable object.","code":""},{"path":"/reference/is.ratetable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify that an object is of class ratetable. — is.ratetable","text":"returns TRUE x ratetable, FALSE description .","code":""},{"path":"/reference/is.ratetable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify that an object is of class ratetable. — is.ratetable","text":"Rate tables used pyears survexp functions, normally  contain death rates population, categorized age, sex,  variables.  fairly rigid structure, verbose option  can help creating new rate table.","code":""},{"path":[]},{"path":"/reference/is.ratetable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify that an object is of class ratetable. — is.ratetable","text":"","code":"is.ratetable(survexp.us)  # True #> [1] TRUE is.ratetable(lung)        # False #> [1] FALSE"},{"path":"/reference/kidney.html","id":null,"dir":"Reference","previous_headings":"","what":"Kidney catheter data — kidney","title":"Kidney catheter data — kidney","text":"Data recurrence times infection, point insertion   catheter, kidney patients using portable dialysis equipment.   Catheters may removed reasons infection, case   observation censored.  patient exactly 2 observations. data often used illustrate use random effects (frailty) survival model.  However, one males (id 21) large outlier, much longer survival peers.  observation removed evidence remains random subject effect.","code":""},{"path":"/reference/kidney.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kidney catheter data — kidney","text":"","code":"kidney data(cancer, package=\"survival\")"},{"path":[]},{"path":"/reference/kidney.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Kidney catheter data — kidney","text":"original paper ignored issue tied times   exactly reproduced survival package.","code":""},{"path":"/reference/kidney.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Kidney catheter data — kidney","text":"CA McGilchrist, CW Aisbett (1991),   Regression frailty survival analysis.    Biometrics 47, 461--66.","code":""},{"path":"/reference/kidney.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kidney catheter data — kidney","text":"","code":"kfit <- coxph(Surv(time, status)~ age + sex + disease + frailty(id), kidney) kfit0 <- coxph(Surv(time, status)~ age + sex + disease, kidney) kfitm1 <- coxph(Surv(time,status) ~ age + sex + disease +      frailty(id, dist='gauss'), kidney)"},{"path":"/reference/levels.Surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the states of a multi-state Surv object — levels.Surv","title":"Return the states of a multi-state Surv object — levels.Surv","text":"multi-state Surv object, return names   states.","code":""},{"path":"/reference/levels.Surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the states of a multi-state Surv object — levels.Surv","text":"","code":"# S3 method for Surv levels(x)"},{"path":"/reference/levels.Surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the states of a multi-state Surv object — levels.Surv","text":"x Surv object","code":""},{"path":"/reference/levels.Surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the states of a multi-state Surv object — levels.Surv","text":"multi-state Surv object, vector state names   (excluding censoring); NULL ordinary Surv object","code":""},{"path":"/reference/levels.Surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return the states of a multi-state Surv object — levels.Surv","text":"","code":"y1 <- Surv(c(1,5, 9, 17,21, 30),            factor(c(0, 1, 2,1,0,2), 0:2, c(\"censored\", \"progression\", \"death\"))) levels(y1) #> [1] \"progression\" \"death\"        y2 <- Surv(1:6, rep(0:1, 3)) y2 #> [1] 1+ 2  3+ 4  5+ 6  levels(y2) #> NULL"},{"path":"/reference/lines.survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Lines or Points to a Survival Plot — lines.survfit","title":"Add Lines or Points to a Survival Plot — lines.survfit","text":"Often used add expected survival curve(s) Kaplan-Meier plot  generated plot.survfit.","code":""},{"path":"/reference/lines.survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Lines or Points to a Survival Plot — lines.survfit","text":"","code":"# S3 method for survfit lines(x, type=\"s\", pch=3, col=1, lty=1,         lwd=1, cex=1, mark.time=FALSE, xmax,         fun, conf.int=FALSE,         conf.times, conf.cap=.005, conf.offset=.012,         conf.type = c(\"log\", \"log-log\", \"plain\", \"logit\", \"arcsin\"),         mark, noplot=\"(s0)\", cumhaz= FALSE,  ...) # S3 method for survexp lines(x, type=\"l\", ...) # S3 method for survfit points(x, fun, censor=FALSE, col=1, pch,         noplot=\"(s0)\", cumhaz=FALSE, ...)"},{"path":"/reference/lines.survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Lines or Points to a Survival Plot — lines.survfit","text":"x survival object, generated survfit survexp functions. type line type, described lines.  default step function  survfit objects, connected line survexp objects. arguments lines.survexp identical lines.survfit. col, lty, lwd, cex vectors giving mark symbol, color, line type, line width   character size added curves.  set color   applicable points. pch plotting characters points,  style   matplot, .e., either single string characters   first used first curve, etc; vector   characters integers, one element per curve. mark historical alias pch censor censoring times displayed points   function? mark.time controls labeling curves.    FALSE, labeling done.    TRUE, curves marked censoring time.    mark.time numeric vector, curves marked   specified time points. xmax optional cutoff right hand curves. fun arbitrary function defining transformation survival curve.  example fun=log alternative way draw log-survival curve  (axis labeled log(S) values).  Four often used transformations can specified character  argument instead: \"log\" using log=T option,  \"event\" plots cumulative events (f(y) = 1-y),  \"cumhaz\" plots cumulative hazard function (f(y) = -log(y))  \"cloglog\" creates complimentary log-log survival plot   (f(y) = log(-log(y))) along log scale x-axis. conf.int TRUE, confidence bands curves also plotted.  set \"\", CI bands plotted, curve  left .    can useful fine control colors line types plot. numeric value, e.g. conf.int = .90, can used conf.times optional vector times place     confidence bar curve(s).  present, used     instead confidence bands. conf.cap width horizontal cap top confidence     bars; used conf.times used.  value 1 width     plot region. conf.offset offset confidence bars,     multiple curves plot.  value 1 width plot     region. single number curve's bars offset     amount prior curve's bars, vector values     used directly. conf.type One \"plain\", \"log\" (default), \t\"log-log\", \"logit\", \"none\".  \tenough string uniquely identify necessary. \tfirst option causes confidence intervals \tgenerated.  second causes standard intervals \tcurve +- k *se(curve), k determined \tconf.int.  log option calculates intervals based \tcumulative hazard log(survival). log-log option bases \tintervals log hazard log(-log(survival)), \tlogit option log(survival/(1-survival)). noplot multi-state models, curves label     plotted.  default corresponds unspecified state. cumhaz plot cumulative hazard, rather survival     probability state. ... graphical parameters","code":""},{"path":"/reference/lines.survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Lines or Points to a Survival Plot — lines.survfit","text":"list components x y, containing coordinates  last point curves (confidence limits).  may useful labeling.","code":""},{"path":"/reference/lines.survfit.html","id":"side-effects","dir":"Reference","previous_headings":"","what":"Side Effects","title":"Add Lines or Points to a Survival Plot — lines.survfit","text":"one curves added current plot.","code":""},{"path":[]},{"path":"/reference/lines.survfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Lines or Points to a Survival Plot — lines.survfit","text":"survfit function creates multi-state survival curve   resulting object class `survfitms'.  difference   plots defaults curve goes lower   left upper right (starting 0), survival curves default   starting 1 going .  options identical. user set explicit range earlier plot.survfit   call, e.g. via xlim xmax, subsequent calls   function remember right hand cutoff. memory can   erased options(plot.survfit) <- NULL.","code":""},{"path":"/reference/lines.survfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Lines or Points to a Survival Plot — lines.survfit","text":"","code":"fit <- survfit(Surv(time, status==2) ~ sex, pbc,subset=1:312) plot(fit, mark.time=FALSE, xscale=365.25,         xlab='Years', ylab='Survival') lines(fit[1], lwd=2)    #darken the first curve and add marks   # Add expected survival curves for the two groups, #   based on the US census data # The data set does not have entry date, use the midpoint of the study efit <- survexp(~sex, data=pbc, times= (0:24)*182, ratetable=survexp.us,                   rmap=list(sex=sex, age=age*365.35, year=as.Date('1979/01/01'))) temp <- lines(efit, lty=2, lwd=2:1) text(temp, c(\"Male\", \"Female\"), adj= -.1) #labels just past the ends title(main=\"Primary Biliary Cirrhosis, Observed and Expected\")"},{"path":"/reference/logan.html","id":null,"dir":"Reference","previous_headings":"","what":"Data from the 1972-78 GSS data used by Logan — logan","title":"Data from the 1972-78 GSS data used by Logan — logan","text":"Intergenerational occupational mobility data covariates.","code":""},{"path":"/reference/logan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data from the 1972-78 GSS data used by Logan — logan","text":"","code":"logan data(logan, package=\"survival\")"},{"path":"/reference/logan.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data from the 1972-78 GSS data used by Logan — logan","text":"data frame 838 observations following 4 variables. occupation subject's occupation, factor levels       farm, operatives, craftsmen, sales,        professional focc father's occupation education total years schooling, 0 20 race levels non-black black","code":""},{"path":"/reference/logan.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data from the 1972-78 GSS data used by Logan — logan","text":"General Social Survey data, see web site detailed information   variables.   https://gss.norc.org/.","code":""},{"path":"/reference/logan.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data from the 1972-78 GSS data used by Logan — logan","text":"Logan, John . (1983). Multivariate Model Mobility Tables.   American Journal Sociology 89: 324-349.","code":""},{"path":"/reference/logLik.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"logLik method for a Cox model — logLik.coxph","title":"logLik method for a Cox model — logLik.coxph","text":"logLik function survival models","code":""},{"path":"/reference/logLik.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logLik method for a Cox model — logLik.coxph","text":"","code":"# S3 method for coxph logLik(object, ...) # S3 method for survreg logLik(object, ...)"},{"path":"/reference/logLik.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"logLik method for a Cox model — logLik.coxph","text":"object result coxph survreg fit ... optional arguments instances method","code":""},{"path":"/reference/logLik.coxph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"logLik method for a Cox model — logLik.coxph","text":"logLik function used summary functions R  AIC.  Cox model, method returns partial likelihood.  number degrees freedom (df) used fit effective  number observations (nobs) added attributes.  Per Raftery others, effective number observations  taken number events data set. survreg model proper value effective number  observations still open question (least author).  right censored data approach logLik.coxph  possible sensible, interval censored observations  result unclear.  code currently add nobs  attribute.","code":""},{"path":"/reference/logLik.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"logLik method for a Cox model — logLik.coxph","text":"object class logLik","code":""},{"path":"/reference/logLik.coxph.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"logLik method for a Cox model — logLik.coxph","text":"Robert E. Kass Adrian E. Raftery (1995). \"Bayes Factors\". J.    American Statistical Assoc. 90 (430): 791. Raftery .E. (1995), \"Bayesian Model Selection Social Research\",    Sociological methodology, 111-196.","code":""},{"path":[]},{"path":"/reference/logLik.coxph.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"logLik method for a Cox model — logLik.coxph","text":"Terry Therneau","code":""},{"path":"/reference/lung.html","id":null,"dir":"Reference","previous_headings":"","what":"NCCTG Lung Cancer Data — lung","title":"NCCTG Lung Cancer Data — lung","text":"Survival patients advanced lung cancer North   Central Cancer Treatment Group.  Performance   scores rate well patient can perform usual daily activities.","code":""},{"path":"/reference/lung.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NCCTG Lung Cancer Data — lung","text":"","code":"lung data(cancer, package=\"survival\")"},{"path":[]},{"path":"/reference/lung.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"NCCTG Lung Cancer Data — lung","text":"use 1/2 alive/dead instead usual 0/1 historical   footnote.   data contained punch cards, IBM 360 Fortran treated blank zero,   led policy within section Biostatistics never   use \"0\" data value since one distinguish   missing value.   policy became habit, often case; 1/2 coding   endured long beyond demise punch cards Fortran.","code":""},{"path":"/reference/lung.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NCCTG Lung Cancer Data — lung","text":"Terry Therneau","code":""},{"path":"/reference/lung.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"NCCTG Lung Cancer Data — lung","text":"Loprinzi CL. Laurie JA. Wieand HS. Krook JE. Novotny PJ.   Kugler JW. Bartel J. Law M. Bateman M. Klatt NE. et al.   Prospective evaluation prognostic variables patient-completed   questionnaires. North Central Cancer Treatment Group.   Journal Clinical Oncology. 12(3):601-7, 1994.","code":""},{"path":"/reference/mgus.html","id":null,"dir":"Reference","previous_headings":"","what":"Monoclonal gammopathy data — mgus","title":"Monoclonal gammopathy data — mgus","text":"Natural history 241 subjects monoclonal gammopathy undetermined significance (MGUS).","code":""},{"path":"/reference/mgus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monoclonal gammopathy data — mgus","text":"","code":"mgus mgus1 data(cancer, package=\"survival\")"},{"path":"/reference/mgus.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Monoclonal gammopathy data — mgus","text":"mgus: data frame 241 observations following 12 variables. mgus1: data set start,stop format. Contains id, age, sex,   laboratory variable described along ","code":""},{"path":"/reference/mgus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monoclonal gammopathy data — mgus","text":"Plasma cells responsible manufacturing immunoglobulins, important part immune defense. given time estimated \\(10^6\\) different immunoglobulins circulation one time.  patient plasma cell malignancy distribution become dominated single isotype, product malignant clone, visible spike serum protein electrophoresis. Monoclonal gammopathy undertermined significance (MGUS) presence spike, patient evidence overt malignancy.  data set 241 sequential subjects Mayo Clinic groundbreaking study defining natural history subjects. Due diligence principle investigator 0 subjects lost follow-. Three subjects MGUS detected day death.  data set mgus1 subjects time MGUS coded .5 day death order avoid tied times. data sets updated Jan 2015 correct small errors.","code":""},{"path":"/reference/mgus.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Monoclonal gammopathy data — mgus","text":"Mayo Clinic data courtesy Dr. Robert Kyle.","code":""},{"path":"/reference/mgus.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Monoclonal gammopathy data — mgus","text":"R Kyle, Benign monoclonal gammopathy -- 20 35 years  follow-,  Mayo Clinic Proc 1993; 68:26-36.","code":""},{"path":"/reference/mgus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monoclonal gammopathy data — mgus","text":"","code":"# Create the competing risk curves for time to first of death or PCM sfit <- survfit(Surv(start, stop, event) ~ sex, mgus1, id=id,                 subset=(enum==1)) print(sfit)  # the order of printout is the order in which they plot #> Call: survfit(formula = Surv(start, stop, event) ~ sex, data = mgus1,  #>     subset = (enum == 1), id = id) #>  #>                     n nevent   rmean* #> sex=female, (s0)  104      0 5762.379 #> sex=male, (s0)    137      0 4543.293 #> sex=female, pcm   104     33 2881.500 #> sex=male, pcm     137     31 2478.026 #> sex=female, death 104     63 5681.121 #> sex=male, death   137    100 7303.682 #>    *restricted mean time in state (max time = 14325 )  plot(sfit, xscale=365.25, lty=c(2,2,1,1), col=c(1,2,1,2),      xlab=\"Years after MGUS detection\", ylab=\"Proportion\") legend(0, .8, c(\"Death/male\", \"Death/female\", \"PCM/male\", \"PCM/female\"),        lty=c(1,1,2,2), col=c(2,1,2,1), bty='n')  title(\"Curves for the first of plasma cell malignancy or death\")  # The plot shows that males have a higher death rate than females (no # surprise) but their rates of conversion to PCM are essentially the same."},{"path":"/reference/mgus2.html","id":null,"dir":"Reference","previous_headings":"","what":"Monoclonal gammopathy data — mgus2","title":"Monoclonal gammopathy data — mgus2","text":"Natural history 1341 sequential patients monoclonal   gammopathy undetermined significance (MGUS).  superset   mgus data, later point accrual process","code":""},{"path":"/reference/mgus2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monoclonal gammopathy data — mgus2","text":"","code":"mgus2 data(cancer, package=\"survival\")"},{"path":"/reference/mgus2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Monoclonal gammopathy data — mgus2","text":"data frame 1384 observations following 10 variables. id subject identifier age age diagnosis, years sex factor levels F M dxyr year diagnosis hgb hemoglobin creat creatinine mspike size monoclonal serum splike ptime time progression plasma cell       malignancy (PCM) last contact, months pstat occurrence PCM: 0=, 1=yes futime time death last contact, months death occurrence death: 0=, 1=yes","code":""},{"path":"/reference/mgus2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monoclonal gammopathy data — mgus2","text":"extension study found mgus data set,   containing enrollment 1994 follow-1999.","code":""},{"path":"/reference/mgus2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Monoclonal gammopathy data — mgus2","text":"Mayo Clinic data courtesy Dr. Robert Kyle.  patient   identifiers removed, age rounded nearest year,   follow-times rounded nearest month.","code":""},{"path":"/reference/mgus2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Monoclonal gammopathy data — mgus2","text":"R. Kyle, T. Therneau, V. Rajkumar, J. Offord, D. Larson, M. Plevak,   L. J. Melton III, long-terms study prognosis monoclonal   gammopathy undertermined significance. New Engl J Med, 346:564-569 (2002).","code":""},{"path":"/reference/model.frame.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Model.frame method for coxph objects — model.frame.coxph","title":"Model.frame method for coxph objects — model.frame.coxph","text":"Recreate model frame coxph fit.","code":""},{"path":"/reference/model.frame.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model.frame method for coxph objects — model.frame.coxph","text":"","code":"# S3 method for coxph model.frame(formula, ...)"},{"path":"/reference/model.frame.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model.frame method for coxph objects — model.frame.coxph","text":"formula result coxph fit ... arguments model.frame","code":""},{"path":"/reference/model.frame.coxph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model.frame method for coxph objects — model.frame.coxph","text":"details, see manual page generic function.   function rarely called user, mostly used   inside functions like residual need recreate data   set model order calculations.","code":""},{"path":"/reference/model.frame.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model.frame method for coxph objects — model.frame.coxph","text":"model frame used original fit, parallel one   new data.","code":""},{"path":"/reference/model.frame.coxph.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model.frame method for coxph objects — model.frame.coxph","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/model.matrix.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Model.matrix method for coxph models — model.matrix.coxph","title":"Model.matrix method for coxph models — model.matrix.coxph","text":"Reconstruct model matrix cox model.","code":""},{"path":"/reference/model.matrix.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model.matrix method for coxph models — model.matrix.coxph","text":"","code":"# S3 method for coxph model.matrix(object, data=NULL, contrast.arg =  object$contrasts, ...)"},{"path":"/reference/model.matrix.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model.matrix method for coxph models — model.matrix.coxph","text":"object result coxph model data optional, data frame obtain data contrast.arg optional, contrasts object describing     factors coded ... possible argument model.frame","code":""},{"path":"/reference/model.matrix.coxph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model.matrix method for coxph models — model.matrix.coxph","text":"data argument function differs   model.matrix methods response variable   original formula required data. data frame contains terms attribute   assumed result call model.frame, otherwise   call model.frame applied data argument.","code":""},{"path":"/reference/model.matrix.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model.matrix method for coxph models — model.matrix.coxph","text":"model matrix fit","code":""},{"path":"/reference/model.matrix.coxph.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model.matrix method for coxph models — model.matrix.coxph","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/model.matrix.coxph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model.matrix method for coxph models — model.matrix.coxph","text":"","code":"fit1 <- coxph(Surv(time, status) ~ age + factor(ph.ecog), data=lung) xfit <- model.matrix(fit1)  fit2 <- coxph(Surv(time, status) ~ age + factor(ph.ecog), data=lung,                                  x=TRUE) all.equal(model.matrix(fit1), fit2$x) #> [1] TRUE"},{"path":"/reference/myeloid.html","id":null,"dir":"Reference","previous_headings":"","what":"Acute myeloid leukemia — myeloid","title":"Acute myeloid leukemia — myeloid","text":"simulated data set based trial acute myeloid   leukemia.","code":""},{"path":"/reference/myeloid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acute myeloid leukemia — myeloid","text":"","code":"myeloid data(cancer, package=\"survival\")"},{"path":"/reference/myeloid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Acute myeloid leukemia — myeloid","text":"data frame 646 observations following 9 variables. id subject identifier, 1-646 trt treatment arm B sex f=female, m=male futime time death last follow-death 1 futime death, 0 censoring txtime time hematropetic stem cell transplant crtime time complete response rltime time relapse disease","code":""},{"path":"/reference/myeloid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Acute myeloid leukemia — myeloid","text":"data set used illustrate multi-state survival curves.   correlation within-subject event times strongly resembles   actual trial, none actual data values   source.","code":""},{"path":"/reference/myeloid.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Acute myeloid leukemia — myeloid","text":"Le-Rademacher JG, Peterson RA, Therneau TM, Sanford BL, Stone RM,   Mandrekar SJ.  Application multi-state models cancer clinical trials.    Clin Trials. 2018 Oct; 15 (5):489-498","code":""},{"path":"/reference/myeloid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acute myeloid leukemia — myeloid","text":"","code":"coxph(Surv(futime, death) ~ trt, data=myeloid) #> Call: #> coxph(formula = Surv(futime, death) ~ trt, data = myeloid) #>  #>         coef exp(coef) se(coef)      z       p #> trtB -0.3457    0.7077   0.1122 -3.081 0.00206 #>  #> Likelihood ratio test=9.52  on 1 df, p=0.002029 #> n= 646, number of events= 320  # See the mstate vignette for a more complete analysis"},{"path":"/reference/myeloma.html","id":null,"dir":"Reference","previous_headings":"","what":"Survival times of patients with multiple myeloma — myeloma","title":"Survival times of patients with multiple myeloma — myeloma","text":"Survival times 3882 subjects multiple myeloma, seen Mayo Clinic 1947--1996.","code":""},{"path":"/reference/myeloma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Survival times of patients with multiple myeloma — myeloma","text":"","code":"myeloma data(\"cancer\", package=\"survival\")"},{"path":"/reference/myeloma.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Survival times of patients with multiple myeloma — myeloma","text":"data frame 3882 observations following 5 variables. id subject identifier year year entry study entry time diagnosis MM entry (days) futime follow time (days) death status last follow-: 0 = alive, 1 = death","code":""},{"path":"/reference/myeloma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Survival times of patients with multiple myeloma — myeloma","text":"Subjects diagnosed Mayo entry =0, diagnosed elsewhere later referred positive values.","code":""},{"path":"/reference/myeloma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Survival times of patients with multiple myeloma — myeloma","text":"R. Kyle, Long term survival multiple myeloma.   New Eng J Medicine, 1997","code":""},{"path":"/reference/myeloma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Survival times of patients with multiple myeloma — myeloma","text":"","code":"# Incorrect survival curve, which ignores left truncation fit1 <- survfit(Surv(futime, death) ~ 1, myeloma) # Correct curve fit2 <- survfit(Surv(entry, futime, death) ~1, myeloma)"},{"path":"/reference/nafld.html","id":null,"dir":"Reference","previous_headings":"","what":"Non-alcohol fatty liver disease — nafld","title":"Non-alcohol fatty liver disease — nafld","text":"Data sets containing data population study non-alcoholic   fatty liver disease (NAFLD).  Subjects condition set   matched control subjects followed forward metabolic   conditions, cardiac endpoints, death.","code":""},{"path":"/reference/nafld.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non-alcohol fatty liver disease — nafld","text":"","code":"nafld1        nafld2        nafld3 data(nafld, package=\"survival\")"},{"path":"/reference/nafld.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Non-alcohol fatty liver disease — nafld","text":"nafld1 data frame 17549 observations following 10 variables. id subject identifier age age entry study male 0=female, 1=male weight weight kg height height cm bmi body mass index case.id id NAFLD case subject       matched futime time death last follow-status 0= alive last follow-, 1=dead nafld2 data frame 400123 observations 4 variables   containing laboratory data id subject identifier days days since index date test type value recorded value numeric value nafld3 data frame 34340 observations 3 variables   containing outcomes id subject identifier days days since index date event endpoint occurred","code":""},{"path":"/reference/nafld.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Non-alcohol fatty liver disease — nafld","text":"primary reference NAFLD study Allen (2018). incidence non-alcoholic fatty liver disease (NAFLD) rising rapidly last decade now one main drivers hepatology practice Tapper2018. essentially presence excess fat liver, parallels ongoing obesity epidemic. Approximately 20-25% NAFLD patients develop inflammatory state non-alcoholic steatohepatitis (NASH), leading fibrosis  eventual end-stage liver disease. NAFLD can accurately diagnosed MRI methods,  NASH diagnosis currently requires biopsy. current study constructed population cohort adult NAFLD subjects 1997 2014  along 4 potential controls case. protect patient confidentiality time intervals days since index date; none dates original data retained. Subject age integer age index date, subject identifier arbitrary integer.  final protection, include 90% random sample data. consequence analyses results exactly match original paper. 3 data sets: nafld1 contains baseline data one observation per subject, nafld2 one observation (time dependent) continuous measurement, nafld3 one observation yes/outcome occured.","code":""},{"path":"/reference/nafld.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Non-alcohol fatty liver disease — nafld","text":"Data obtained author.","code":""},{"path":"/reference/nafld.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Non-alcohol fatty liver disease — nafld","text":"Allen, TM Therneau, JJ Larson, Coward, VK Somers PS Kamath,    Nonalcoholic Fatty Liver Disease Incidence Impact Metabolic             Burden Death: 20 Year Community Study,    Hepatology 67:1726-1736, 2018.","code":""},{"path":"/reference/neardate.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the index of the closest value in data set 2, for each entry in\r\n  data set one. — neardate","title":"Find the index of the closest value in data set 2, for each entry in\r\n  data set one. — neardate","text":"common task medical work find closest lab value   index date, subject.","code":""},{"path":"/reference/neardate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the index of the closest value in data set 2, for each entry in\r\n  data set one. — neardate","text":"","code":"neardate(id1, id2, y1, y2, best = c(\"after\", \"prior\"), nomatch = NA_integer_)"},{"path":"/reference/neardate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the index of the closest value in data set 2, for each entry in\r\n  data set one. — neardate","text":"id1 vector subject identifiers index group id2 vector identifiers reference group y1 normally vector dates index group,     orderable data type allowed y2 reference set dates best best='prior' find index first     y2 value less equal     target y1 value, subject.     best='' find first y2 value greater     equal target y1 value, subject. nomatch value return items without match","code":""},{"path":"/reference/neardate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find the index of the closest value in data set 2, for each entry in\r\n  data set one. — neardate","text":"routine closely related match   findInterval, first finds exact matches   second closest matches.  finds closest matching date   within sets exactly matching identifiers.     Closest date matching often needed clinical studies.    example data set 1 might contain subject identifier date   procedure data set set 2 dates values   laboratory tests, query find first   test value intervention closer 7 days. id1 id2 arguments similar match   searching instances id1 found   id2, result length id1.   However, instead returning first match id2   routine returns one best matches respect y1. y1 y2 arguments need dates, function   works data type expression   c(y1, y2) gives sensible, sortable result.   careful matching Date DateTime values impact   time zones, however, see .POSIXct.    y1 y2 class user   .   Since exist pairs unmatched data types result   sensible, routine case proceed assumption   \"user knows \".  Caveat emptor.","code":""},{"path":"/reference/neardate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the index of the closest value in data set 2, for each entry in\r\n  data set one. — neardate","text":"index matching observations second data set,   nomatch value successful match","code":""},{"path":"/reference/neardate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Find the index of the closest value in data set 2, for each entry in\r\n  data set one. — neardate","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/neardate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the index of the closest value in data set 2, for each entry in\r\n  data set one. — neardate","text":"","code":"data1 <- data.frame(id = 1:10,                     entry.dt = as.Date(paste(\"2011\", 1:10, \"5\", sep='-'))) temp1 <- c(1,4,5,1,3,6,9, 2,7,8,12,4,6,7,10,12,3) data2 <- data.frame(id = c(1,1,1,2,2,4,4,5,5,5,6,8,8,9,10,10,12),                     lab.dt = as.Date(paste(\"2011\", temp1, \"1\", sep='-')),                     chol = round(runif(17, 130, 280)))  #first cholesterol on or after enrollment indx1 <- neardate(data1$id, data2$id, data1$entry.dt, data2$lab.dt) data2[indx1, \"chol\"] #>  [1] 165 180  NA 232 256 225  NA  NA  NA 201  # Closest one, either before or after.  #  indx2 <- neardate(data1$id, data2$id, data1$entry.dt, data2$lab.dt,                     best=\"prior\") ifelse(is.na(indx1), indx2, # none after, take before        ifelse(is.na(indx2), indx1, #none before        ifelse(abs(data2$lab.dt[indx2]- data1$entry.dt) <               abs(data2$lab.dt[indx1]- data1$entry.dt), indx2, indx1))) #>  [1]  1  5 NA  6  9 11 NA 13 14 15  # closest date before or after, but no more than 21 days prior to index indx2 <- ifelse((data1$entry.dt - data2$lab.dt[indx2]) >21, NA, indx2) ifelse(is.na(indx1), indx2, # none after, take before        ifelse(is.na(indx2), indx1, #none before        ifelse(abs(data2$lab.dt[indx2]- data1$entry.dt) <               abs(data2$lab.dt[indx1]- data1$entry.dt), indx2, indx1))) #>  [1]  1  5 NA  6  9 11 NA NA NA 15"},{"path":"/reference/nsk.html","id":null,"dir":"Reference","previous_headings":"","what":"Natural splines with knot heights as the basis. — nsk","title":"Natural splines with knot heights as the basis. — nsk","text":"Create design matrix natural spline, coefficient resulting fit values function knots.","code":""},{"path":"/reference/nsk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Natural splines with knot heights as the basis. — nsk","text":"","code":"nsk(x, df = NULL, knots = NULL, intercept = FALSE, b = 0.05,      Boundary.knots = quantile(x, c(b, 1 - b), na.rm = TRUE))"},{"path":"/reference/nsk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Natural splines with knot heights as the basis. — nsk","text":"x predictor variable.  Missing values allowed. df degrees freedom. One can supply df rather knots; ns()     chooses df - 1 - intercept knots suitably chosen quantiles x     (ignore missing values).     default, df = NULL, sets number inner knots length(knots). knots breakpoints define spline. default knots;     together natural boundary conditions results     basis linear regression x.     Typical values mean median one knot, quantiles          knots. See also Boundary.knots. intercept TRUE, intercept included basis; default FALSE b default placement boundary knots.  value     bs=0 replicate default behavior ns. Boundary.knots boundary points impose natural boundary conditions   anchor B-spline basis.  Beyond points function   assumed linear.   knots Boundary.knots supplied, basis parameters   depend x. Data can extend beyond Boundary.knots","code":""},{"path":"/reference/nsk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Natural splines with knot heights as the basis. — nsk","text":"nsk function behaves identically ns function,   two exceptions.  primary one returned basis   coefficients correspond value fitted function   knot points.  intercept = FALSE, k-1   coefficients corresponding k knots, difference   predicted value knots 2-k knot 1.   primary advantage basis coefficients   directly interpretable.  second tests linear   non-linear components simple contrasts. second differnce ns one opinion respect   default position boundary knots.  default   closer found rms::rcs function. function trial new idea, future inclusion   package yet guarranteed.","code":""},{"path":"/reference/nsk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Natural splines with knot heights as the basis. — nsk","text":"matrix dimension length(x) * df either df supplied ,   knots supplied, df = length(knots) + 1 + intercept.   Attributes returned correspond arguments kns,   explicitly give knots, Boundary.knots etc use predict.kns().","code":""},{"path":"/reference/nsk.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Natural splines with knot heights as the basis. — nsk","text":"thin flexible metal wooden strip called spline,   traditional method laying smooth curve, e.g., ship's   hull airplane wing.  Pins put board strip   passed , pin 'knot'. mathematical spline piecewise function knot.    linear spline set connected line segments, quadratic   spline set connected local quadratic functions, constrained   continuous first derivative, cubic spline cubic   knot, constrained continuous first second   derivatives, etc.  Mathematical splines exact   representation natural splines: physical object wood   metal strip continuous derivatives orders.  Cubic   splines commonly used sufficiently smooth   look natural human eye. mathematical spline constrained linear beyond   end knots, often called 'natural spline', due   fact wooden metal spline also linear beyond last   knots.  Another name object 'restricted cubic   spline', since achieved code adding constraints.   Given vector data points set knots, possible   create basis matrix X one column per knot, ordinary   regression X y fit cubic spline function, hence   also called 'regression splines'. (One three labels   better worse another, opinion). Given basis matrix X k columns,   matrix Z= XT k k nonsingular matrix T also basis   matrix, result identical predicted values, new set   coefficients gamma = (T-inverse) beta place beta.  One can   choose basis functions X easy construct,   make regression numerically stable, make tests easier, based   considerations.   seems though every spline library returns different basis   set, unfortunately makes fits difficult compare packages.   yet one basis set, chosen make coefficients   interpretable.","code":""},{"path":[]},{"path":"/reference/nsk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Natural splines with knot heights as the basis. — nsk","text":"","code":"# make some dummy data tdata <- data.frame(x= lung$age, y = 10*log(lung$age-35) + rnorm(228, 0, 2)) fit1 <- lm(y ~ -1 + nsk(x, df=4, intercept=TRUE) , data=tdata) fit2 <- lm(y ~ nsk(x, df=3), data=tdata)  # the knots (same for both fits) knots <- unlist(attributes(fit1$model[[2]])[c('Boundary.knots', 'knots')]) sort(unname(knots)) #> [1] 45.35 59.00 67.00 75.00 unname(coef(fit1))  # predictions at the knot points #> [1] 22.19575 32.41028 34.22713 36.72817  unname(coef(fit1)[-1] - coef(fit1)[1])  # differences: yhat[2:4] - yhat[1] #> [1] 10.21453 12.03138 14.53243 unname(coef(fit2))[-1]                  # ditto #> [1] 10.21453 12.03138 14.53243  if (FALSE) { plot(y ~ x, data=tdata) points(sort(knots), coef(fit1), col=2, pch=19) coef(fit)[1] + c(0, coef(fit)[-1]) }"},{"path":"/reference/nwtco.html","id":null,"dir":"Reference","previous_headings":"","what":"Data from the National Wilm's Tumor Study — nwtco","title":"Data from the National Wilm's Tumor Study — nwtco","text":"Measurement error example. Tumor histology predicts   survival, prediction stronger central lab histology   local institution determination.","code":""},{"path":"/reference/nwtco.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data from the National Wilm's Tumor Study — nwtco","text":"","code":"nwtco data(nwtco, package=\"survival\")"},{"path":"/reference/nwtco.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data from the National Wilm's Tumor Study — nwtco","text":"data frame 4028 observations following 9 variables. seqno id number instit Histology local institution histol Histology central lab stage Disease stage study study rel indicator relapse edrel time relapse age age months .subcohort Included subcohort example     paper","code":""},{"path":"/reference/nwtco.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data from the National Wilm's Tumor Study — nwtco","text":"NE Breslow N Chatterjee (1999),   Design analysis two-phase studies binary outcome applied   Wilms tumour prognosis.   Applied Statistics 48, 457--68.","code":""},{"path":"/reference/nwtco.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data from the National Wilm's Tumor Study — nwtco","text":"","code":"with(nwtco, table(instit,histol)) #>       histol #> instit    1    2 #>      1 3493  129 #>      2   76  330 anova(coxph(Surv(edrel,rel)~histol+instit,data=nwtco)) #> Analysis of Deviance Table #>  Cox model: response is Surv(edrel, rel) #> Terms added sequentially (first to last) #>  #>         loglik    Chisq Df Pr(>|Chi|)     #> NULL   -4666.3                            #> histol -4532.5 267.6667  1    < 2e-16 *** #> instit -4531.0   3.0397  1    0.08125 .   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 anova(coxph(Surv(edrel,rel)~instit+histol,data=nwtco)) #> Analysis of Deviance Table #>  Cox model: response is Surv(edrel, rel) #> Terms added sequentially (first to last) #>  #>         loglik   Chisq Df Pr(>|Chi|)     #> NULL   -4666.3                           #> instit -4577.5 177.714  1  < 2.2e-16 *** #> histol -4531.0  92.992  1  < 2.2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/reference/ovarian.html","id":null,"dir":"Reference","previous_headings":"","what":"Ovarian Cancer Survival Data — ovarian","title":"Ovarian Cancer Survival Data — ovarian","text":"Survival randomised trial comparing two treatments     ovarian cancer","code":""},{"path":"/reference/ovarian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ovarian Cancer Survival Data — ovarian","text":"","code":"ovarian data(cancer, package=\"survival\")"},{"path":[]},{"path":"/reference/ovarian.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Ovarian Cancer Survival Data — ovarian","text":"Terry Therneau","code":""},{"path":"/reference/ovarian.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ovarian Cancer Survival Data — ovarian","text":"Edmunson, J.H., Fleming, T.R., Decker, D.G.,     Malkasian, G.D., Jefferies, J.., Webb, M.J., Kvols, L.K.,     Different Chemotherapeutic Sensitivities Host Factors Affecting     Prognosis Advanced Ovarian Carcinoma vs. Minimal Residual Disease.     Cancer Treatment Reports, 63:241-47, 1979.","code":""},{"path":"/reference/pbc.html","id":null,"dir":"Reference","previous_headings":"","what":"Mayo Clinic Primary Biliary Cholangitis Data — pbc","title":"Mayo Clinic Primary Biliary Cholangitis Data — pbc","text":"Primary sclerosing cholangitis autoimmune disease leading   destruction small bile ducts liver.  Progression   slow inexhortable, eventually leading cirrhosis liver   decompensation.   condition recognised since least 1851 named   \"primary biliary cirrhosis\" 1949.   cirrhosis feature advanced disease, change   name \"primary biliary cholangitis\" proposed patient   advocacy groups 2014. data Mayo Clinic trial PBC conducted 1974 1984.   total 424 PBC patients, referred Mayo Clinic ten-year interval, met eligibility criteria randomized placebo controlled trial drug D-penicillamine.  first 312 cases data set participated randomized trial contain largely complete data.  additional 112 cases participate clinical trial, consented basic measurements recorded followed survival.  Six cases lost follow-shortly diagnosis, data additional 106 cases well 312 randomized participants. nearly identical data set found appendix D Fleming Harrington; version fewer missing values.","code":""},{"path":"/reference/pbc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mayo Clinic Primary Biliary Cholangitis Data — pbc","text":"","code":"pbc data(pbc, package=\"survival\")"},{"path":[]},{"path":"/reference/pbc.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Mayo Clinic Primary Biliary Cholangitis Data — pbc","text":"T Therneau P Grambsch (2000),   Modeling Survival Data: Extending Cox Model,   Springer-Verlag, New York.   ISBN: 0-387-98784-3.","code":""},{"path":[]},{"path":"/reference/pbcseq.html","id":null,"dir":"Reference","previous_headings":"","what":"Mayo Clinic Primary Biliary Cirrhosis, sequential data — pbcseq","title":"Mayo Clinic Primary Biliary Cirrhosis, sequential data — pbcseq","text":"data continuation PBC data set, contains follow-laboratory data study patient. analysis based data can found Murtagh, et. al. primary PBC data set contains baseline measurements  laboratory  parameters.  data set contains multiple laboratory results, 312 randomized patients.  baseline data values file differ original PBC file, instance, data errors prothrombin time age discovered original analysis (see Fleming Harrington, figure 4.6.7). One \"feature\" data deserves special comment.  last observation death liver transplant often many missing covariates data rows.  original clinical protocol patients specified visits 6 months, 1 year, annually thereafter.  protocol visits lab values obtained large pre-specified battery tests.  \"Extra\" visits, often undertaken worsening medical condition, necessarily lab work.  missing values thus potentially informative.","code":""},{"path":"/reference/pbcseq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mayo Clinic Primary Biliary Cirrhosis, sequential data — pbcseq","text":"","code":"pbcseq data(pbc, package=\"survival\")"},{"path":[]},{"path":"/reference/pbcseq.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Mayo Clinic Primary Biliary Cirrhosis, sequential data — pbcseq","text":"T Therneau P Grambsch,   \"Modeling Survival Data: Extending Cox Model\",   Springer-Verlag, New York, 2000.   ISBN: 0-387-98784-3.","code":""},{"path":[]},{"path":"/reference/pbcseq.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mayo Clinic Primary Biliary Cirrhosis, sequential data — pbcseq","text":"Murtaugh PA. Dickson ER. Van Dam GM. Malinchoc M. Grambsch PM.   Langworthy AL. Gips CH.  \"Primary biliary cirrhosis: prediction short-term   survival based repeated patient visits.\" Hepatology. 20(1.1):126-34, 1994. Fleming T Harrington D., \"Counting Processes Survival Analysis\",   Wiley, New York, 1991.","code":""},{"path":"/reference/pbcseq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mayo Clinic Primary Biliary Cirrhosis, sequential data — pbcseq","text":"","code":"# Create the start-stop-event triplet needed for coxph first <- with(pbcseq, c(TRUE, diff(id) !=0)) #first id for each subject last  <- c(first[-1], TRUE)  #last id  time1 <- with(pbcseq, ifelse(first, 0, day)) time2 <- with(pbcseq, ifelse(last,  futime, c(day[-1], 0))) event <- with(pbcseq, ifelse(last,  status, 0))  fit1 <- coxph(Surv(time1, time2, event) ~ age + sex + log(bili), pbcseq) #> Warning: Invalid status value, converted to NA"},{"path":"/reference/plot.aareg.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an aareg object. — plot.aareg","title":"Plot an aareg object. — plot.aareg","text":"Plot estimated coefficient function(s) fit Aalen's additive regression model.","code":""},{"path":"/reference/plot.aareg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an aareg object. — plot.aareg","text":"","code":"# S3 method for aareg plot(x, se=TRUE, maxtime, type='s', ...)"},{"path":"/reference/plot.aareg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an aareg object. — plot.aareg","text":"x result call aareg function se TRUE, standard error bands included plot maxtime upper limit x-axis. type graphical parameter type line, default \"steps\". ... graphical parameters line type, color, axis labels.","code":""},{"path":"/reference/plot.aareg.html","id":"side-effects","dir":"Reference","previous_headings":"","what":"Side Effects","title":"Plot an aareg object. — plot.aareg","text":"plot produced current graphical device.","code":""},{"path":"/reference/plot.aareg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot an aareg object. — plot.aareg","text":"Aalen, O.O. (1989). linear regression model analysis life times. Statistics Medicine, 8:907-925.","code":""},{"path":[]},{"path":"/reference/plot.cox.zph.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphical Test of Proportional Hazards — plot.cox.zph","title":"Graphical Test of Proportional Hazards — plot.cox.zph","text":"Displays graph scaled Schoenfeld residuals, along smooth curve.","code":""},{"path":"/reference/plot.cox.zph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphical Test of Proportional Hazards — plot.cox.zph","text":"","code":"# S3 method for cox.zph plot(x, resid=TRUE, se=TRUE, df=4, nsmo=40, var,         xlab=\"Time\", ylab, lty=1:2, col=1, lwd=1, hr=FALSE, ...)"},{"path":"/reference/plot.cox.zph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphical Test of Proportional Hazards — plot.cox.zph","text":"x result cox.zph function. resid logical value, TRUE residuals included plot, well smooth fit. se logical value, TRUE, confidence bands two standard errors  added. df degrees freedom fitted natural spline, df=2 leads  linear fit. nsmo number points use lines var set variables plots desired.  default, plots  produced turn variable model.  Selection single variable  allows features added plot, e.g., horizontal line  zero main title. superseded subscripting method; see example . hr TRUE, label y-axis using estimated hazard ratio   rather estimated coefficient.  (plot change,   axis label.) xlab label x-axis plot ylab optional label y-axis plot.  missing   default label provided.  can vector labels. lty, col, lwd line type, color, line width overlaid   curve.  can vector length 2, case   second element used confidence interval. ... additional graphical arguments passed plot function.","code":""},{"path":"/reference/plot.cox.zph.html","id":"side-effects","dir":"Reference","previous_headings":"","what":"Side Effects","title":"Graphical Test of Proportional Hazards — plot.cox.zph","text":"plot produced current graphics device.","code":""},{"path":[]},{"path":"/reference/plot.cox.zph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graphical Test of Proportional Hazards — plot.cox.zph","text":"","code":"vfit <- coxph(Surv(time,status) ~ trt + factor(celltype) +                karno + age, data=veteran, x=TRUE)  temp <- cox.zph(vfit)  plot(temp, var=3)      # Look at Karnofsy score, old way of doing plot  plot(temp[3])     # New way with subscripting  abline(0, 0, lty=3)  # Add the linear fit as well   abline(lm(temp$y[,3] ~ temp$x)$coefficients, lty=4, col=3)   title(main=\"VA Lung Study\")"},{"path":"/reference/plot.survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for survfit objects — plot.survfit","title":"Plot method for survfit objects — plot.survfit","text":"plot survival curves produced, one curve strata.  log=T option extra work avoid log(0), try create  pleasing result.  zeros, plotted default  0.8 times smallest non-zero value curve(s). Curves plotted order listed print (gives 1 line summary ). order col, lty, etc used.","code":""},{"path":"/reference/plot.survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for survfit objects — plot.survfit","text":"","code":"# S3 method for survfit plot(x, conf.int=, mark.time=FALSE,   pch=3, col=1, lty=1, lwd=1, cex=1, log=FALSE, xscale=1, yscale=1,    xlim, ylim, xmax, fun,   xlab=\"\", ylab=\"\", xaxs=\"r\",  conf.times, conf.cap=.005,  conf.offset=.012,  conf.type = c(\"log\", \"log-log\", \"plain\", \"logit\", \"arcsin\"),  mark, noplot=\"(s0)\", cumhaz=FALSE,  firstx, ymin, ...)"},{"path":"/reference/plot.survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for survfit objects — plot.survfit","text":"x object class survfit, usually returned     survfit function. conf.int determines whether pointwise confidence intervals plotted.     default      1 curve, .e., strata, using 95% confidence     intervals     Alternatively, can numeric value giving desired     confidence level. mark.time controls labeling curves.  set FALSE,     labeling done.      TRUE, curves marked censoring time.     mark     numeric vector curves marked specified time points. pch vector characters used label curves.      points help file contains examples possible marks.     single string \"abcd\" treated vector     c(\"\", \"b\", \"c\", \"d\").     vector reused cyclically shorter number     curves.  present implies mark.time = TRUE. col vector integers specifying colors curve.      default value 1. lty vector integers specifying line types curve.      default value 1. lwd vector numeric values line widths. default value 1. cex numeric value specifying size marks.      treated vector; marks size. log logical value, TRUE y axis wll log scale.      Alternately, one standard character strings \"x\", \"y\", \"xy\"     can given specific logarithmic horizontal /vertical axes. xscale numeric value used like yscale labels x axis.       value 365.25 give labels years instead original days. yscale numeric value used multiply labels y axis.      value 100, instance, used give percent scale.      labels      changed, actual plot coordinates, adding curve      \"lines(surv.exp(...))\", say,       perform without yscale argument. xlim,ylim optional limits plotting region. xmax maximum horizontal plot coordinate.  can used shrink     range plot.  shortens curve plotting ,     unlike using xlim graphical parameter, warning     messages bounds points generated. fun arbitrary function defining transformation survival     (probability state, cumulative hazard) curves.      example fun=log alternative way draw log-survival curve      (axis labeled log(S) values),      fun=sqrt generate curve square root scale.      Four often used transformations can specified character      argument instead: \"S\" gives usual survival curve,     \"log\" using log=T option,      \"event\" \"F\" plots empirical CDF \\(F(t)= 1-S(t)\\)     (f(y) = 1-y),     \"cloglog\" creates complimentary log-log survival plot (f(y) =      log(-log(y)) along log scale x-axis).     terms \"identity\" \"surv\"     allowed synonyms type=\"S\".     argument \"cumhaz\" causes cumulative hazard function     plotted. xlab label given x-axis. ylab label given y-axis. xaxs either \"S\" survival curve standard x axis style     listed par; \"r\" (regular) R default.     Survival curves historically displayed curve     touching y-axis,     touching bounding box plot 3 sides,     Type \"S\" accomplishes manipulating plot range     using \"\" style internally.     \"S\" style becoming increasingly less common, however. conf.times optional vector times place     confidence bar curve(s).  present, used     instead confidence bands. conf.cap width horizontal cap top confidence     bars; used conf.times used.  value 1 width     plot region. conf.offset offset confidence bars,     multiple curves plot.  value 1 width plot     region. single number curve's bars offset     amount prior curve's bars, vector values     used directly. conf.type One \"plain\", \"log\" (default), \t\"log-log\" \"logit\".  \tenough string uniquely identify necessary. \tfirst option causes confidence intervals \tgenerated.  second causes standard intervals \tcurve +- k *se(curve), k determined \tconf.int.  log option calculates intervals based \tcumulative hazard log(survival). log-log option bases \tintervals log hazard log(-log(survival)), \tlogit option log(survival/(1-survival)). mark historical alias pch noplot multi-state models, curves label     plotted.  (Also see istate0 argument     survcheck.) cumhaz plot cumulative hazard rather probability     state survival.  Optionally, can numeric vector     specifying columns cumhaz component plot. ymin normally given part ylim     argument firstx normally given part xlim     argument. ... arguments passed forward     underlying plot method, xlab ylab.","code":""},{"path":"/reference/plot.survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for survfit objects — plot.survfit","text":"list components x y, containing coordinates last point  curves (confidence limits).    may useful labeling.","code":""},{"path":"/reference/plot.survfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot method for survfit objects — plot.survfit","text":"object contains cumulative hazard curve,   fun='cumhaz' plot curve, otherwise plot   -log(S) approximation.  Theoretically, S =   \\(\\exp(-\\Lambda)\\) S survival   \\(\\Lambda\\) cumulative hazard.  relationship   holds estimates S \\(\\Lambda\\) special cases,   approximation often close. survfit function creates multi-state survival curve   resulting object also class `survfitms'.   Competing risk curves common case.   situation fun argument ignored. conf.times argument used, confidence bars   offset conf.offset units avoid overlap.   bar curve confidence interval time point   bar drawn, .e., different time points curve.   curves steep point, visual impact can sometimes   substantially differ positive negative values   conf.offset.","code":""},{"path":"/reference/plot.survfit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Plot method for survfit objects — plot.survfit","text":"prior versions behavior xscale   yscale differed: first changed scale plot   subsequent actions adding legend, whereas yscale   affected axis label.  normalized version 2-36.4,   parameters now affect labeling. versions prior approximately 2.36 survfit object   contain cumulative hazard separate result, use   fun=\"cumhaz\" plot approximation -log(surv) cumulative   hazard.  cumulative hazards added object,   cumhaz=TRUE argument plotting function added.   version 2.3-8 use fun=\"cumhaz\" became synonym   cumhaz=TRUE.","code":""},{"path":[]},{"path":"/reference/plot.survfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for survfit objects — plot.survfit","text":"","code":"leukemia.surv <- survfit(Surv(time, status) ~ x, data = aml)  plot(leukemia.surv, lty = 2:3)  legend(100, .9, c(\"Maintenance\", \"No Maintenance\"), lty = 2:3)  title(\"Kaplan-Meier Curves\\nfor AML Maintenance Study\")   lsurv2 <- survfit(Surv(time, status) ~ x, aml, type='fleming')  plot(lsurv2, lty=2:3, fun=\"cumhaz\",    xlab=\"Months\", ylab=\"Cumulative Hazard\")"},{"path":"/reference/predict.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions for a Cox model — predict.coxph","title":"Predictions for a Cox model — predict.coxph","text":"Compute fitted values regression terms model fitted   coxph","code":""},{"path":"/reference/predict.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions for a Cox model — predict.coxph","text":"","code":"# S3 method for coxph predict(object, newdata, type=c(\"lp\", \"risk\", \"expected\", \"terms\", \"survival\"), se.fit=FALSE, na.action=na.pass, terms=names(object$assign), collapse, reference=c(\"strata\", \"sample\", \"zero\"),  ...)"},{"path":"/reference/predict.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions for a Cox model — predict.coxph","text":"object results coxph fit. newdata Optional new data predictions.   absent predictions  data frame used original   fit.    coxph called formula argument created another   context, .e., coxph called within another function   formula passed argument function, can   problems finding data set.  See note . type type predicted value.  Choices linear predictor (\"lp\"), risk score exp(lp) (\"risk\"),  expected number events given covariates follow-time  (\"expected\"), terms linear predictor (\"terms\"). survival probability subject equal exp(-expected). se.fit TRUE, pointwise standard errors produced predictions. na.action applies newdata argument present, defines   missing value action new data.  default include   observations.   newdata, behavior missing dictated   na.action option original fit. terms type=\"terms\", argument can used specify terms  included; default . collapse optional vector subject identifiers.   specified, output contain one entry per subject rather one  entry per observation. reference reference centering predictions, see details ... future methods","code":""},{"path":"/reference/predict.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions for a Cox model — predict.coxph","text":"vector matrix predictions, list containing predictions  (element \"fit\") standard errors (element \"se.fit\") se.fit  option TRUE.","code":""},{"path":"/reference/predict.coxph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predictions for a Cox model — predict.coxph","text":"Cox model relative risk model; predictions type \"linear predictor\", \"risk\", \"terms\" relative sample came.  default, reference value mean covariate within strata. underlying reason statistical practial. First, Cox model predicts relative risks pairs subjects within strata, hence addition constant covariate, either overall within particular stratum, effect fitted results. Second, downstream calculations depend risk score exp(linear predictor), fall prey numeric overflow linear predictor greater .Machine\\$double.max.exp. coxph routines try approximately center predictors self protection. Using reference=\"strata\" option safest centering, since strata occassionally different means. results predict used calculations may desirable use single reference level observations. Use reference=\"sample\" use overall means, agrees linear.predictors component coxph object (uses overall mean backwards compatability older code). Predictions type=\"terms\" almost invariably passed forward calculation, default using sample reference. reference \"zero\" causes centering done. Predictions type \"expected\" incorporate baseline hazard thus absolute instead relative; reference option effect . values depend follow-time future subjects well covariates newdata argument needs include right left hand side variables formula. (status variable used, required since underlying code needs reconstruct entire formula.) Models contain frailty term special case: due technical difficulty, newdata argument predictions always random effect zero.","code":""},{"path":"/reference/predict.coxph.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Predictions for a Cox model — predict.coxph","text":"predictions can obtained directly coxph object, others necessary routine entirety original data set, e.g., type = terms standard errors requested. extra information saved coxph object model=TRUE, original data reconstructed. known residuals required overall execution slightly faster model information saved. cases reconstruction can fail. common coxph called inside another function formula passed one arguments enclosing function.  Another data set changed original call time prediction call. simple solution add model=TRUE original coxph call.","code":""},{"path":[]},{"path":"/reference/predict.coxph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions for a Cox model — predict.coxph","text":"","code":"options(na.action=na.exclude) # retain NA in predictions fit <- coxph(Surv(time, status) ~ age + ph.ecog + strata(inst), lung) #lung data set has status coded as 1/2 mresid <- (lung$status-1) - predict(fit, type='expected') #Martingale resid  predict(fit,type=\"lp\") #>            1            2            3            4            5            6  #>  0.215495605 -0.423532231 -0.559265038  0.183469551 -0.539432878  0.248095483  #>            7            8            9           10           11           12  #>  0.406461814  0.489169379 -0.047448917  0.327284344  0.040389888  0.550315552  #>           13           14           15           16           17           18  #> -0.115925255           NA  0.055807340  0.110906025  0.050567124  0.493760215  #>           19           20           21           22           23           24  #>  0.557645717 -0.004245606 -0.127236322 -0.621260082 -0.319524466 -0.575882288  #>           25           26           27           28           29           30  #> -0.345688084  0.202851214 -0.428371074  1.313400384 -0.021210624  0.761244928  #>           31           32           33           34           35           36  #>  0.191540147  0.749933860  0.180240469  0.459827013  0.672213041  0.625512121  #>           37           38           39           40           41           42  #>  0.565173220  0.085767683  0.761244928  0.076972823  0.330513426  0.511791514  #>           43           44           45           46           47           48  #> -0.439682141  0.660901974 -0.164699618  0.496950353 -0.381077937  0.091073865  #>           49           50           51           52           53           54  #> -0.354839644 -0.175654221  0.192873470 -0.447487689 -0.450985298 -0.562055013  #>           55           56           57           58           59           60  #>  0.063012023 -0.516810744 -0.297203343  0.474684682  0.034518529  0.076972823  #>           61           62           63           64           65           66  #>  0.678283893 -0.045992266  0.176731471 -0.149858457  0.158940268  0.718790633  #>           67           68           69           70           71           72  #>  0.539004484 -0.308514410 -0.543216443  0.153500561 -0.479261384 -0.078592144  #>           73           74           75           76           77           78  #>  0.946919127 -0.073531430 -0.049489875  0.214162281 -0.641232484  0.029078821  #>           79           80           81           82           83           84  #> -0.276488357 -0.392389004 -0.439682141  0.001411510 -0.410013004 -0.151289480  #>           85           86           87           88           89           90  #> -0.292311495  0.198744830 -0.039921414 -0.530162769 -0.123010230  0.738622793  #>           91           92           93           94           95           96  #> -0.743642023  0.050567124  0.285269157  0.108857156 -0.437633273  0.796634781  #>           97           98           99          100          101          102  #>  0.158940268  0.214162281 -0.161169524 -0.400910096 -0.562055013  0.176122695  #>          103          104          105          106          107          108  #>  0.012722577  0.108256292  0.617817211  0.157606945 -0.189452466  0.110906025  #>          109          110          111          112          113          114  #> -0.026867740  0.797968104 -0.411394980 -0.149248522  0.369011703 -0.344354760  #>          115          116          117          118          119          120  #>  0.006456686  0.783867062  0.503880355  0.693378524  0.527693417  0.244122624  #>          121          122          123          124          125          126  #> -0.464038972  0.449575370  0.158940268  0.500480446 -0.426322206  0.005322855  #>          127          128          129          130          131          132  #> -0.368298829  0.134984810  0.652115157 -0.617153698  0.131479291 -0.190511890  #>          133          134          135          136          137          138  #> -0.643882217  0.001411510 -0.460255408  0.666972826  0.067118407  0.583884010  #>          139          140          141          142          143          144  #> -0.036137850 -0.399002948  0.747892903  0.215495605  0.630552446  0.088283890  #>          145          146          147          148          149          150  #> -0.240346995 -0.200763533 -0.558074111 -0.179200822 -0.232577411 -0.524505653  #>          151          152          153          154          155          156  #>  0.171077519 -0.633704981 -0.331136545 -0.190511890  0.477441161           NA  #>          157          158          159          160          161          162  #> -0.031097524  0.736573925  0.123673743 -0.013515715 -0.585704233 -0.038186718  #>          163          164          165          166          167          168  #>  0.466547245  0.108256292 -0.209943887 -0.716429053 -0.206413793 -0.699828778  #>          169          170          171          172          173          174  #>  0.085634157 -0.424865554  0.069277914 -0.441093652  0.107445646 -0.874783994  #>          175          176          177          178          179          180  #> -0.047448917  0.046655779  0.557645717  0.001411510 -0.047448917 -0.667994646  #>          181          182          183          184          185          186  #> -0.513194586 -0.776965291 -0.614629447  0.019390401 -0.583220496 -0.651086900  #>          187          188          189          190          191          192  #>  0.859584155 -0.536642904  0.063145548 -0.712882451  0.024398388  0.369338475  #>          193          194          195          196          197          198  #> -0.023370131  0.076972823  0.061878192 -0.368310218 -0.003231734  0.074931865  #>          199          200          201          202          203          204  #> -0.629921417 -0.037164935  0.063145548  0.084500326 -0.574393166 -0.627131442  #>          205          206          207          208          209          210  #> -0.658814293  0.302547317 -0.410314015  0.516017606  0.131487202 -0.302547317  #>          211          212          213          214          215          216  #> -0.539432878  0.153500561  0.119700884  0.409991908 -0.149858457 -0.149858457  #>          217          218          219          220          221          222  #> -0.156943432  0.781826105  0.477858312 -0.452404719  0.016633922 -0.081992053  #>          223          224          225          226          227          228  #>  0.212705630  0.224016697 -0.750726998  0.703662506  0.142189494 -0.085165683  predict(fit,type=\"expected\") #>          1          2          3          4          5          6          7  #> 0.74602570 0.57892506 1.28411487 0.65144995 2.53474317 2.59935704 0.94925558  #>          8          9         10         11         12         13         14  #> 1.07812821 0.63137435 0.55866807 0.31809979 1.96068120 2.96879741         NA  #>         15         16         17         18         19         20         21  #> 2.14464916 0.39248100 1.01652225 2.53985878 0.23734050 0.15454932 0.41781121  #>         22         23         24         25         26         27         28  #> 0.03725873 1.07425239 0.73304358 0.71922541 1.96068538 0.91425760 0.50868712  #>         29         30         31         32         33         34         35  #> 1.07651355 0.10727131 1.64348011 0.22335391 1.34246079 0.18355514 0.25427967  #>         36         37         38         39         40         41         42  #> 0.57948554 3.87217595 1.42062915 0.50341133 2.84274107 1.90670187 0.39302876  #>         43         44         45         46         47         48         49  #> 1.67374788 0.56009982 1.95081502 0.39930277 0.62185372 1.18384892 1.08920268  #>         50         51         52         53         54         55         56  #> 1.36922169 2.72429090 0.31557423 0.04821232 0.41960993 3.07164840 0.12000994  #>         57         58         59         60         61         62         63  #> 0.07406041 0.17908976 1.74520134 1.10195998 1.47697029 0.54523697 0.51461493  #>         64         65         66         67         68         69         70  #> 0.14292300 0.18117365 0.20227027 0.70028855 1.00636733 0.31133532 0.64126839  #>         71         72         73         74         75         76         77  #> 0.96177399 0.46743320 0.53451717 0.16345589 0.86294287 1.44797843 1.06953116  #>         78         79         80         81         82         83         84  #> 1.19014609 0.03668315 0.33061179 1.90397464 0.08944145 0.20857044 0.28585781  #>         85         86         87         88         89         90         91  #> 1.15723874 0.87295638 1.19851949 0.14216346 1.37338069 0.92021616 1.05096221  #>         92         93         94         95         96         97         98  #> 0.27465006 0.47403241 0.26750987 1.01622540 0.08901343 0.32456045 0.93961618  #>         99        100        101        102        103        104        105  #> 0.85179714 0.14362313 0.89733451 1.74403467 0.70225748 0.15754565 0.36065915  #>        106        107        108        109        110        111        112  #> 0.41227011 0.29089093 0.02759911 2.54485283 1.57705739 0.02915789 0.51482474  #>        113        114        115        116        117        118        119  #> 1.51254632 0.24392791 1.95773713 0.16855572 0.69132758 2.65613080 1.04014324  #>        120        121        122        123        124        125        126  #> 0.89157179 0.40187641 0.23829273 1.56065440 0.17535194 1.02778525 0.18442460  #>        127        128        129        130        131        132        133  #> 0.08051722 0.20596405 1.70473379 0.86354367 0.72017118 0.27146814 0.48487446  #>        134        135        136        137        138        139        140  #> 1.10114414 0.51567846 1.46035831 0.93950468 1.54314328 1.12143879 0.60372302  #>        141        142        143        144        145        146        147  #> 1.46022571 0.88081136 0.66047105 0.18347489 0.51981101 0.28761918 0.50825077  #>        148        149        150        151        152        153        154  #> 0.15268490 0.06671446 0.32571666 0.39746179 0.39772440 0.38939509 0.20940447  #>        155        156        157        158        159        160        161  #> 0.62171971         NA 0.34080256 0.46159657 0.47539058 1.00662370 0.21472196  #>        162        163        164        165        166        167        168  #> 0.54619593 0.50111574 0.24481910 0.51248548 0.19954882 0.25566706 0.78817717  #>        169        170        171        172        173        174        175  #> 0.44798249 0.43113659 0.44847984 1.48341994 0.46620310 0.37028208 0.86812344  #>        176        177        178        179        180        181        182  #> 0.43844817 0.94494334 0.25935783 0.37625255 0.20649507 0.25048304 0.37569346  #>        183        184        185        186        187        188        189  #> 0.40334526 0.39324727 0.36799524 0.39552828 1.77501387 0.24422514 0.38021709  #>        190        191        192        193        194        195        196  #> 0.21501843 0.51818689 0.08032921 0.22774986 0.71502728 0.36774267 0.39500663  #>        197        198        199        200        201        202        203  #> 0.38445105 0.97727710 0.43520510 0.16869554 0.17219830 0.05878035 0.21716448  #>        204        205        206        207        208        209        210  #> 0.18384556 0.18192355 0.64682101 0.35975276 0.70106697 1.03414013 0.35317899  #>        211        212        213        214        215        216        217  #> 0.42921059 0.47944086 0.40234009 0.25017393 0.04470913 0.27054309 0.22137404  #>        218        219        220        221        222        223        224  #> 1.18698635 0.50681607 0.11190719 0.11327702 0.28954125 0.33611081 0.74776723  #>        225        226        227        228  #> 0.12225025 0.00000000 0.35218786 0.10231300  predict(fit,type=\"risk\",se.fit=TRUE) #> $fit #>         1         2         3         4         5         6         7         8  #> 1.2404765 0.6547301 0.5716290 1.2013784 0.5830788 1.2815823 1.5014958 1.6309609  #>         9        10        11        12        13        14        15        16  #> 0.9536592 1.3871959 1.0412167 1.7338000 0.8905418        NA 1.0573939 1.1172899  #>        17        18        19        20        21        22        23        24  #> 1.0518675 1.6384656 1.7465558 0.9957634 0.8805256 0.5372670 0.7264944 0.5622086  #>        25        26        27        28        29        30        31        32  #> 0.7077332 1.2248902 0.6515696 3.7187976 0.9790127 2.1409399 1.2111135 2.1168600  #>        33        34        35        36        37        38        39        40  #> 1.1975053 1.5838000 1.9585669 1.8692030 1.7597526 1.0895532 2.1409399 1.0800127  #>        41        42        43        44        45        46        47        48  #> 1.3916825 1.6682773 0.6442412 1.9365383 0.8481484 1.6437009 0.6831246 1.0953499  #>        49        50        51        52        53        54        55        56  #> 0.7012859 0.8389080 1.2127293 0.6392321 0.6370002 0.5700364 1.0650396 0.5964197  #>        57        58        59        60        61        62        63        64  #> 0.7428929 1.6075072 1.0351212 1.0800127 1.9704933 0.9550493 1.1933106 0.8608298  #>        65        66        67        68        69        70        71        72  #> 1.1722679 2.0519501 1.7142994 0.7345374 0.5808769 1.1659084 0.6192406 0.9244169  #>        73        74        75        76        77        78        79        80  #> 2.5777557 0.9291069 0.9517148 1.2388237 0.5266429 1.0295057 0.7584424 0.6754413  #>        81        82        83        84        85        86        87        88  #> 0.6442412 1.0014125 0.6636416 0.8595988 0.7465360 1.2198707 0.9608649 0.5885092  #>        89        90        91        92        93        94        95        96  #> 0.8842546 2.0930510 0.4753794 1.0518675 1.3301200 1.1150031 0.6455625 2.2180641  #>        97        98        99       100       101       102       103       104  #> 1.1722679 1.2388237 0.8511478 0.6697103 0.5700364 1.1925844 1.0128039 1.1143333  #>       105       106       107       108       109       110       111       112  #> 1.8548748 1.1707060 0.8274120 1.1172899 0.9734900 2.2210235 0.6627251 0.8613550  #>       113       114       115       116       117       118       119       120  #> 1.4463045 0.7086775 1.0064776 2.1899245 1.6551313 2.0004627 1.6950181 1.2765009  #>       121       122       123       124       125       126       127       128  #> 0.6287391 1.5676464 1.1722679 1.6495136 0.6529059 1.0053370 0.6919104 1.1445194  #>       129       130       131       132       133       134       135       136  #> 1.9195968 0.5394778 1.1405143 0.8265359 0.5252493 1.0014125 0.6311224 1.9483304  #>       137       138       139       140       141       142       143       144  #> 1.0694221 1.7929889 0.9645073 0.6709887 2.1125440 1.2404765 1.8786481 1.0922982  #>       145       146       147       148       149       150       151       152  #> 0.7863550 0.8181059 0.5723102 0.8359380 0.7924884 0.5918479 1.1865827 0.5306222  #>       153       154       155       156       157       158       159       160  #> 0.7181071 0.8265359 1.6119444        NA 0.9693810 2.0887670 1.1316466 0.9865752  #>       161       162       163       164       165       166       167       168  #> 0.5567137 0.9625332 1.5944793 1.1143333 0.8106297 0.4884935 0.8134964 0.4966703  #>       169       170       171       172       173       174       175       176  #> 1.0894077 0.6538577 1.0717340 0.6433325 1.1134303 0.4169521 0.9536592 1.0477613  #>       177       178       179       180       181       182       183       184  #> 1.7465558 1.0014125 0.9536592 0.5127358 0.5985803 0.4597993 0.5408413 1.0195796  #>       185       186       187       188       189       190       191       192  #> 0.5580981 0.5214787 2.3621782 0.5847079 1.0651819 0.4902291 1.0246985 1.4467772  #>       193       194       195       196       197       198       199       200  #> 0.9769008 1.0800127 1.0638328 0.6919025 0.9967735 1.0778107 0.5326337 0.9635172  #>       201       202       203       204       205       206       207       208  #> 1.0651819 1.0881732 0.5630464 0.5341218 0.5174645 1.3533017 0.6634419 1.6753425  #>       209       210       211       212       213       214       215       216  #> 1.1405233 0.7389335 0.5830788 1.1659084 1.1271597 1.5068056 0.8608298 0.8608298  #>       217       218       219       220       221       222       223       224  #> 0.8547524 2.1854595 1.6126170 0.6360967 1.0167730 0.9212793 1.2370205 1.2510919  #>       225       226       227       228  #> 0.4720233 2.0211416 1.1527951 0.9183601  #>  #> $se.fit #>           1           2           3           4           5           6  #> 0.094027169 0.096340319 0.096185061 0.110144705 0.091221886 0.124003567  #>           7           8           9          10          11          12  #> 0.106470052 0.135893441 0.104263809 0.115204660 0.048057506 0.157626321  #>          13          14          15          16          17          18  #> 0.058398830          NA 0.078593550 0.044525715 0.047523899 0.139753275  #>          19          20          21          22          23          24  #> 0.246130195 0.051683778 0.050651208 0.106747848 0.121191090 0.095563151  #>          25          26          27          28          29          30  #> 0.135232494 0.077970827 0.084316589 0.541641696 0.047411370 0.244541270  #>          31          32          33          34          35          36  #> 0.067316853 0.236761412 0.222247496 0.143779967 0.246770836 0.214866749  #>          37          38          39          40          41          42  #> 0.186808694 0.027994134 0.244541270 0.017746688 0.094899948 0.150429986  #>          43          44          45          46          47          48  #> 0.082038635 0.251128992 0.071539989 0.172653479 0.157627962 0.046664065  #>          49          50          51          52          53          54  #> 0.203630081 0.147427688 0.071868116 0.087051165 0.126710133 0.091078334  #>          55          56          57          58          59          60  #> 0.030346404 0.094111921 0.072518580 0.232795318 0.092391388 0.017746688  #>          61          62          63          64          65          66  #> 0.207337260 0.162712161 0.126511646 0.038549743 0.042876315 0.234595146  #>          67          68          69          70          71          72  #> 0.151669341 0.068462840 0.112880428 0.068678027 0.124246473 0.184637680  #>          73          74          75          76          77          78  #> 0.325442016 0.174862073 0.090441588 0.089040153 0.108376599 0.057550307  #>          79          80          81          82          83          84  #> 0.188633743 0.150191651 0.082038635 0.027564795 0.181878087 0.172125872  #>          85          86          87          88          89          90  #> 0.142365056 0.114741553 0.035859182 0.096819023 0.132484179 0.229864932  #>          91          92          93          94          95          96  #> 0.120689668 0.047523899 0.070339929 0.055381362 0.123547581 0.253870138  #>          97          98          99         100         101         102  #> 0.042876315 0.089040153 0.035190905 0.106227011 0.091078334 0.091298269  #>         103         104         105         106         107         108  #> 0.017787711 0.028641480 0.194430169 0.039989624 0.075782969 0.044525715  #>         109         110         111         112         113         114  #> 0.071209628 0.254965259 0.163546509 0.185211877 0.241649528 0.139074790  #>         115         116         117         118         119         120  #> 0.076796420 0.262556790 0.348185429 0.211911041 0.146845572 0.149423594  #>         121         122         123         124         125         126  #> 0.150969692 0.156065943 0.042876315 0.142648758 0.129688202 0.004890619  #>         127         128         129         130         131         132  #> 0.113985419 0.031310085 0.248637733 0.121183075 0.041502912 0.067248608  #>         133         134         135         136         137         138  #> 0.115359144 0.027564795 0.112511267 0.200585657 0.069255092 0.201817172  #>         139         140         141         142         143         144  #> 0.094786456 0.075667327 0.240338975 0.094027169 0.216098624 0.024974398  #>         145         146         147         148         149         150  #> 0.066191299 0.084423319 0.167625233 0.058808327 0.221289168 0.105873833  #>         151         152         153         154         155         156  #> 0.140449741 0.098993713 0.063583542 0.067248608 0.230942129          NA  #>         157         158         159         160         161         162  #> 0.067558237 0.245408761 0.032338223 0.075589234 0.101745759 0.174851413  #>         163         164         165         166         167         168  #> 0.125897325 0.028641480 0.048065722 0.111659253 0.045260623 0.125085448  #>         169         170         171         172         173         174  #> 0.020095538 0.093808006 0.037378627 0.093118562 0.031761359 0.135544076  #>         175         176         177         178         179         180  #> 0.104263809 0.016586035 0.246130195 0.027564795 0.104263809 0.174088607  #>         181         182         183         184         185         186  #> 0.109727836 0.166211707 0.139230772 0.017941579 0.106388490 0.137198131  #>         187         188         189         190         191         192  #> 0.304795981 0.089505183 0.043311645 0.114439474 0.131445121 0.192173147  #>         193         194         195         196         197         198  #> 0.144436340 0.017746688 0.058484070 0.121193159 0.002956631 0.025613128  #>         199         200         201         202         203         204  #> 0.104623286 0.033429233 0.043311645 0.080773833 0.103942128 0.124008736  #>         205         206         207         208         209         210  #> 0.118294076 0.078206752 0.080505144 0.235804861 0.079727031 0.057789591  #>         211         212         213         214         215         216  #> 0.091221886 0.068678027 0.029421496 0.124248857 0.038549743 0.038549743  #>         217         218         219         220         221         222  #> 0.158976598 0.269332667 0.130275218 0.089792820 0.015369862 0.085131550  #>         223         224         225         226         227         228  #> 0.148494109 0.160862263 0.138362860 0.225740927 0.057778343 0.074788433  #>  predict(fit,type=\"terms\",se.fit=TRUE) #> $fit #>              age     ph.ecog #> 1    0.130878057  0.03032716 #> 2    0.063011653 -0.54083428 #> 3   -0.072721154 -0.54083428 #> 4   -0.061410086  0.03032716 #> 5   -0.027476885 -0.54083428 #> 6    0.130878057  0.03032716 #> 7    0.063011653  0.60148859 #> 8    0.096944855  0.60148859 #> 9   -0.106654355  0.03032716 #> 10  -0.016165817  0.60148859 #> 11  -0.061410086  0.03032716 #> 12   0.063011653  0.60148859 #> 13   0.063011653  0.03032716 #> 14            NA          NA #> 15  -0.061410086  0.03032716 #> 16   0.051700586  0.03032716 #> 17   0.085633788  0.03032716 #> 18   0.006456317  0.60148859 #> 19  -0.072721154  0.60148859 #> 20  -0.061410086  0.03032716 #> 21   0.051700586  0.03032716 #> 22  -0.151898625 -0.54083428 #> 23  -0.140587557  0.03032716 #> 24  -0.050099019 -0.54083428 #> 25   0.108255923 -0.54083428 #> 26   0.085633788  0.03032716 #> 27  -0.027476885 -0.54083428 #> 28   0.085633788  1.17265002 #> 29  -0.106654355  0.03032716 #> 30   0.130878057  0.60148859 #> 31   0.074322721  0.03032716 #> 32   0.119566990  0.60148859 #> 33  -0.163209692  0.60148859 #> 34  -0.027476885  0.60148859 #> 35  -0.016165817  0.60148859 #> 36  -0.004854750  0.60148859 #> 37   0.029078452  0.60148859 #> 38   0.040389519  0.03032716 #> 39   0.130878057  0.60148859 #> 40   0.017767384  0.03032716 #> 41   0.085633788  0.03032716 #> 42   0.119566990  0.60148859 #> 43  -0.038787952 -0.54083428 #> 44  -0.027476885  0.60148859 #> 45   0.063011653  0.03032716 #> 46   0.153500192  0.60148859 #> 47   0.130878057 -0.54083428 #> 48   0.006456317  0.03032716 #> 49   0.130878057 -0.54083428 #> 50  -0.140587557  0.03032716 #> 51   0.108255923  0.03032716 #> 52   0.006456317 -0.54083428 #> 53   0.063011653 -0.54083428 #> 54  -0.050099019 -0.54083428 #> 55  -0.038787952  0.03032716 #> 56  -0.004854750 -0.54083428 #> 57   0.029078452 -0.54083428 #> 58  -0.061410086  0.60148859 #> 59  -0.050099019  0.03032716 #> 60   0.017767384  0.03032716 #> 61   0.142189124  0.60148859 #> 62  -0.163209692  0.03032716 #> 63   0.119566990  0.03032716 #> 64   0.029078452  0.03032716 #> 65   0.074322721  0.03032716 #> 66   0.063011653  0.60148859 #> 67   0.051700586  0.60148859 #> 68   0.017767384 -0.54083428 #> 69   0.063011653 -0.54083428 #> 70   0.051700586  0.03032716 #> 71   0.006456317 -0.54083428 #> 72  -0.163209692  0.03032716 #> 73   0.130878057  0.60148859 #> 74  -0.253698230  0.03032716 #> 75  -0.106654355  0.03032716 #> 76   0.096944855  0.03032716 #> 77  -0.129276490 -0.54083428 #> 78  -0.072721154  0.03032716 #> 79   0.210055528 -0.54083428 #> 80   0.119566990 -0.54083428 #> 81  -0.038787952 -0.54083428 #> 82  -0.084032221  0.03032716 #> 83  -0.231076095  0.03032716 #> 84  -0.208453961  0.03032716 #> 85  -0.208453961  0.03032716 #> 86   0.096944855  0.03032716 #> 87  -0.004854750  0.03032716 #> 88  -0.016165817 -0.54083428 #> 89  -0.208453961  0.03032716 #> 90   0.108255923  0.60148859 #> 91   0.006456317 -0.54083428 #> 92   0.085633788  0.03032716 #> 93   0.040389519  0.03032716 #> 94  -0.061410086  0.03032716 #> 95   0.074322721 -0.54083428 #> 96   0.108255923  0.60148859 #> 97   0.074322721  0.03032716 #> 98   0.096944855  0.03032716 #> 99   0.017767384  0.03032716 #> 100  0.085633788 -0.54083428 #> 101 -0.050099019 -0.54083428 #> 102  0.074322721  0.03032716 #> 103 -0.072721154  0.03032716 #> 104  0.006456317  0.03032716 #> 105 -0.038787952  0.60148859 #> 106  0.040389519  0.03032716 #> 107 -0.095343288  0.03032716 #> 108  0.051700586  0.03032716 #> 109 -0.084032221  0.03032716 #> 110  0.142189124  0.60148859 #> 111  0.074322721 -0.54083428 #> 112 -0.208453961  0.03032716 #> 113  0.198744461  0.03032716 #> 114  0.142189124 -0.54083428 #> 115 -0.095343288  0.03032716 #> 116  0.153500192  0.60148859 #> 117 -0.151898625  0.60148859 #> 118  0.063011653  0.60148859 #> 119  0.040389519  0.60148859 #> 120  0.198744461  0.03032716 #> 121  0.142189124 -0.54083428 #> 122 -0.027476885  0.60148859 #> 123  0.074322721  0.03032716 #> 124  0.108255923  0.60148859 #> 125  0.085633788 -0.54083428 #> 126  0.040389519  0.03032716 #> 127 -0.140587557  0.03032716 #> 128  0.017767384  0.03032716 #> 129  0.164811259  0.60148859 #> 130 -0.163209692 -0.54083428 #> 131 -0.038787952  0.03032716 #> 132 -0.106654355  0.03032716 #> 133 -0.174520759 -0.54083428 #> 134 -0.084032221  0.03032716 #> 135  0.051700586 -0.54083428 #> 136  0.130878057  0.60148859 #> 137 -0.050099019  0.03032716 #> 138 -0.072721154  0.60148859 #> 139 -0.095343288  0.03032716 #> 140 -0.072721154 -0.54083428 #> 141  0.119566990  0.60148859 #> 142  0.130878057  0.03032716 #> 143  0.153500192  0.60148859 #> 144  0.029078452  0.03032716 #> 145 -0.061410086  0.03032716 #> 146 -0.106654355  0.03032716 #> 147  0.096944855 -0.54083428 #> 148 -0.095343288  0.03032716 #> 149  0.221366595 -0.54083428 #> 150 -0.038787952 -0.54083428 #> 151  0.085633788  0.03032716 #> 152 -0.027476885 -0.54083428 #> 153 -0.004854750 -0.54083428 #> 154 -0.106654355  0.03032716 #> 155 -0.084032221  0.60148859 #> 156           NA          NA #> 157  0.063011653  0.03032716 #> 158 -0.004854750  0.60148859 #> 159  0.006456317  0.03032716 #> 160 -0.072721154  0.03032716 #> 161 -0.004854750 -0.54083428 #> 162 -0.208453961  0.03032716 #> 163  0.074322721  0.60148859 #> 164  0.006456317  0.03032716 #> 165  0.017767384  0.03032716 #> 166 -0.061410086 -0.54083428 #> 167 -0.027476885  0.03032716 #> 168 -0.185831826 -0.54083428 #> 169 -0.016165817  0.03032716 #> 170  0.029078452 -0.54083428 #> 171 -0.016165817  0.03032716 #> 172 -0.050099019 -0.54083428 #> 173 -0.072721154  0.03032716 #> 174 -0.219765028 -0.54083428 #> 175 -0.106654355  0.03032716 #> 176 -0.038787952  0.03032716 #> 177 -0.072721154  0.60148859 #> 178 -0.084032221  0.03032716 #> 179 -0.106654355  0.03032716 #> 180  0.130878057 -0.54083428 #> 181 -0.027476885 -0.54083428 #> 182 -0.265009297 -0.54083428 #> 183  0.040389519 -0.54083428 #> 184  0.029078452  0.03032716 #> 185 -0.129276490 -0.54083428 #> 186 -0.197142894 -0.54083428 #> 187  0.108255923  0.60148859 #> 188 -0.050099019 -0.54083428 #> 189  0.017767384  0.03032716 #> 190 -0.106654355 -0.54083428 #> 191  0.108255923  0.03032716 #> 192 -0.117965423  0.60148859 #> 193 -0.140587557  0.03032716 #> 194  0.017767384  0.03032716 #> 195  0.096944855  0.03032716 #> 196  0.085633788 -0.54083428 #> 197  0.006456317  0.03032716 #> 198  0.017767384  0.03032716 #> 199 -0.117965423 -0.54083428 #> 200 -0.027476885  0.03032716 #> 201  0.017767384  0.03032716 #> 202  0.119566990  0.03032716 #> 203  0.006456317 -0.54083428 #> 204 -0.140587557 -0.54083428 #> 205  0.006456317 -0.54083428 #> 206 -0.004854750  0.60148859 #> 207 -0.084032221 -0.54083428 #> 208 -0.140587557  0.60148859 #> 209  0.074322721  0.03032716 #> 210 -0.038787952  0.03032716 #> 211 -0.027476885 -0.54083428 #> 212  0.051700586  0.03032716 #> 213  0.074322721  0.03032716 #> 214  0.017767384  0.60148859 #> 215  0.029078452  0.03032716 #> 216  0.029078452  0.03032716 #> 217 -0.242387163  0.03032716 #> 218  0.153500192  0.60148859 #> 219  0.085633788  0.60148859 #> 220 -0.061410086 -0.54083428 #> 221  0.051700586  0.03032716 #> 222  0.096944855  0.03032716 #> 223  0.153500192  0.03032716 #> 224  0.164811259  0.03032716 #> 225 -0.265009297 -0.54083428 #> 226  0.142189124  0.60148859 #> 227  0.040389519  0.03032716 #> 228 -0.050099019  0.03032716 #>  #> $se.fit #>             age     ph.ecog #> 1   0.119930635 0.007395102 #> 2   0.057740983 0.131879319 #> 3   0.066638322 0.131879319 #> 4   0.056273380 0.007395102 #> 5   0.025178554 0.131879319 #> 6   0.119930635 0.007395102 #> 7   0.057740983 0.146669523 #> 8   0.088835809 0.146669523 #> 9   0.097733148 0.007395102 #> 10  0.014813612 0.146669523 #> 11  0.056273380 0.007395102 #> 12  0.057740983 0.146669523 #> 13  0.057740983 0.007395102 #> 14           NA          NA #> 15  0.056273380 0.007395102 #> 16  0.047376041 0.007395102 #> 17  0.078470867 0.007395102 #> 18  0.005916272 0.146669523 #> 19  0.066638322 0.146669523 #> 20  0.056273380 0.007395102 #> 21  0.047376041 0.007395102 #> 22  0.139192917 0.131879319 #> 23  0.128827975 0.007395102 #> 24  0.045908438 0.131879319 #> 25  0.099200751 0.131879319 #> 26  0.078470867 0.007395102 #> 27  0.025178554 0.131879319 #> 28  0.078470867 0.285943945 #> 29  0.097733148 0.007395102 #> 30  0.119930635 0.146669523 #> 31  0.068105925 0.007395102 #> 32  0.109565693 0.146669523 #> 33  0.149557859 0.146669523 #> 34  0.025178554 0.146669523 #> 35  0.014813612 0.146669523 #> 36  0.004448670 0.146669523 #> 37  0.026646156 0.146669523 #> 38  0.037011098 0.007395102 #> 39  0.119930635 0.146669523 #> 40  0.016281214 0.007395102 #> 41  0.078470867 0.007395102 #> 42  0.109565693 0.146669523 #> 43  0.035543496 0.131879319 #> 44  0.025178554 0.146669523 #> 45  0.057740983 0.007395102 #> 46  0.140660519 0.146669523 #> 47  0.119930635 0.131879319 #> 48  0.005916272 0.007395102 #> 49  0.119930635 0.131879319 #> 50  0.128827975 0.007395102 #> 51  0.099200751 0.007395102 #> 52  0.005916272 0.131879319 #> 53  0.057740983 0.131879319 #> 54  0.045908438 0.131879319 #> 55  0.035543496 0.007395102 #> 56  0.004448670 0.131879319 #> 57  0.026646156 0.131879319 #> 58  0.056273380 0.146669523 #> 59  0.045908438 0.007395102 #> 60  0.016281214 0.007395102 #> 61  0.130295577 0.146669523 #> 62  0.149557859 0.007395102 #> 63  0.109565693 0.007395102 #> 64  0.026646156 0.007395102 #> 65  0.068105925 0.007395102 #> 66  0.057740983 0.146669523 #> 67  0.047376041 0.146669523 #> 68  0.016281214 0.131879319 #> 69  0.057740983 0.131879319 #> 70  0.047376041 0.007395102 #> 71  0.005916272 0.131879319 #> 72  0.149557859 0.007395102 #> 73  0.119930635 0.146669523 #> 74  0.232477395 0.007395102 #> 75  0.097733148 0.007395102 #> 76  0.088835809 0.007395102 #> 77  0.118463033 0.131879319 #> 78  0.066638322 0.007395102 #> 79  0.192485229 0.131879319 #> 80  0.109565693 0.131879319 #> 81  0.035543496 0.131879319 #> 82  0.077003264 0.007395102 #> 83  0.211747511 0.007395102 #> 84  0.191017627 0.007395102 #> 85  0.191017627 0.007395102 #> 86  0.088835809 0.007395102 #> 87  0.004448670 0.007395102 #> 88  0.014813612 0.131879319 #> 89  0.191017627 0.007395102 #> 90  0.099200751 0.146669523 #> 91  0.005916272 0.131879319 #> 92  0.078470867 0.007395102 #> 93  0.037011098 0.007395102 #> 94  0.056273380 0.007395102 #> 95  0.068105925 0.131879319 #> 96  0.099200751 0.146669523 #> 97  0.068105925 0.007395102 #> 98  0.088835809 0.007395102 #> 99  0.016281214 0.007395102 #> 100 0.078470867 0.131879319 #> 101 0.045908438 0.131879319 #> 102 0.068105925 0.007395102 #> 103 0.066638322 0.007395102 #> 104 0.005916272 0.007395102 #> 105 0.035543496 0.146669523 #> 106 0.037011098 0.007395102 #> 107 0.087368206 0.007395102 #> 108 0.047376041 0.007395102 #> 109 0.077003264 0.007395102 #> 110 0.130295577 0.146669523 #> 111 0.068105925 0.131879319 #> 112 0.191017627 0.007395102 #> 113 0.182120287 0.007395102 #> 114 0.130295577 0.131879319 #> 115 0.087368206 0.007395102 #> 116 0.140660519 0.146669523 #> 117 0.139192917 0.146669523 #> 118 0.057740983 0.146669523 #> 119 0.037011098 0.146669523 #> 120 0.182120287 0.007395102 #> 121 0.130295577 0.131879319 #> 122 0.025178554 0.146669523 #> 123 0.068105925 0.007395102 #> 124 0.099200751 0.146669523 #> 125 0.078470867 0.131879319 #> 126 0.037011098 0.007395102 #> 127 0.128827975 0.007395102 #> 128 0.016281214 0.007395102 #> 129 0.151025461 0.146669523 #> 130 0.149557859 0.131879319 #> 131 0.035543496 0.007395102 #> 132 0.097733148 0.007395102 #> 133 0.159922801 0.131879319 #> 134 0.077003264 0.007395102 #> 135 0.047376041 0.131879319 #> 136 0.119930635 0.146669523 #> 137 0.045908438 0.007395102 #> 138 0.066638322 0.146669523 #> 139 0.087368206 0.007395102 #> 140 0.066638322 0.131879319 #> 141 0.109565693 0.146669523 #> 142 0.119930635 0.007395102 #> 143 0.140660519 0.146669523 #> 144 0.026646156 0.007395102 #> 145 0.056273380 0.007395102 #> 146 0.097733148 0.007395102 #> 147 0.088835809 0.131879319 #> 148 0.087368206 0.007395102 #> 149 0.202850171 0.131879319 #> 150 0.035543496 0.131879319 #> 151 0.078470867 0.007395102 #> 152 0.025178554 0.131879319 #> 153 0.004448670 0.131879319 #> 154 0.097733148 0.007395102 #> 155 0.077003264 0.146669523 #> 156          NA          NA #> 157 0.057740983 0.007395102 #> 158 0.004448670 0.146669523 #> 159 0.005916272 0.007395102 #> 160 0.066638322 0.007395102 #> 161 0.004448670 0.131879319 #> 162 0.191017627 0.007395102 #> 163 0.068105925 0.146669523 #> 164 0.005916272 0.007395102 #> 165 0.016281214 0.007395102 #> 166 0.056273380 0.131879319 #> 167 0.025178554 0.007395102 #> 168 0.170287743 0.131879319 #> 169 0.014813612 0.007395102 #> 170 0.026646156 0.131879319 #> 171 0.014813612 0.007395102 #> 172 0.045908438 0.131879319 #> 173 0.066638322 0.007395102 #> 174 0.201382569 0.131879319 #> 175 0.097733148 0.007395102 #> 176 0.035543496 0.007395102 #> 177 0.066638322 0.146669523 #> 178 0.077003264 0.007395102 #> 179 0.097733148 0.007395102 #> 180 0.119930635 0.131879319 #> 181 0.025178554 0.131879319 #> 182 0.242842337 0.131879319 #> 183 0.037011098 0.131879319 #> 184 0.026646156 0.007395102 #> 185 0.118463033 0.131879319 #> 186 0.180652685 0.131879319 #> 187 0.099200751 0.146669523 #> 188 0.045908438 0.131879319 #> 189 0.016281214 0.007395102 #> 190 0.097733148 0.131879319 #> 191 0.099200751 0.007395102 #> 192 0.108098090 0.146669523 #> 193 0.128827975 0.007395102 #> 194 0.016281214 0.007395102 #> 195 0.088835809 0.007395102 #> 196 0.078470867 0.131879319 #> 197 0.005916272 0.007395102 #> 198 0.016281214 0.007395102 #> 199 0.108098090 0.131879319 #> 200 0.025178554 0.007395102 #> 201 0.016281214 0.007395102 #> 202 0.109565693 0.007395102 #> 203 0.005916272 0.131879319 #> 204 0.128827975 0.131879319 #> 205 0.005916272 0.131879319 #> 206 0.004448670 0.146669523 #> 207 0.077003264 0.131879319 #> 208 0.128827975 0.146669523 #> 209 0.068105925 0.007395102 #> 210 0.035543496 0.007395102 #> 211 0.025178554 0.131879319 #> 212 0.047376041 0.007395102 #> 213 0.068105925 0.007395102 #> 214 0.016281214 0.146669523 #> 215 0.026646156 0.007395102 #> 216 0.026646156 0.007395102 #> 217 0.222112453 0.007395102 #> 218 0.140660519 0.146669523 #> 219 0.078470867 0.146669523 #> 220 0.056273380 0.131879319 #> 221 0.047376041 0.007395102 #> 222 0.088835809 0.007395102 #> 223 0.140660519 0.007395102 #> 224 0.151025461 0.007395102 #> 225 0.242842337 0.131879319 #> 226 0.130295577 0.146669523 #> 227 0.037011098 0.007395102 #> 228 0.045908438 0.007395102 #>   # For someone who demands reference='zero' pzero <- function(fit)   predict(fit, reference=\"sample\") + sum(coef(fit) * fit$means, na.rm=TRUE)"},{"path":"/reference/predict.survreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicted Values for a `survreg' Object — predict.survreg","title":"Predicted Values for a `survreg' Object — predict.survreg","text":"Predicted values survreg object","code":""},{"path":"/reference/predict.survreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicted Values for a `survreg' Object — predict.survreg","text":"","code":"# S3 method for survreg predict(object, newdata,   type=c(\"response\", \"link\", \"lp\", \"linear\", \"terms\", \"quantile\",     \"uquantile\"),  se.fit=FALSE, terms=NULL, p=c(0.1, 0.9), na.action=na.pass, ...)"},{"path":"/reference/predict.survreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicted Values for a `survreg' Object — predict.survreg","text":"object result model fit using survreg function. newdata data prediction.  absent predictions  subjects used original fit. type type predicted value.   can original scale data (response),  linear predictor (\"linear\", \"lp\" allowed abbreviation),  predicted quantile original scale data (\"quantile\"),  quantile linear predictor scale (\"uquantile\"), matrix terms linear predictor (\"terms\"). time \"link\" linear predictor (\"lp\") identical. se.fit TRUE, include standard errors prediction result. terms subset terms.  default residual type \"terms\" matrix  one column every term (excluding intercept) model. p vector percentiles.  used quantile predictions. na.action applies newdata argument present, defines   missing value action new data.  default include   observations. ... future methods","code":""},{"path":"/reference/predict.survreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicted Values for a `survreg' Object — predict.survreg","text":"vector matrix predicted values.","code":""},{"path":"/reference/predict.survreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predicted Values for a `survreg' Object — predict.survreg","text":"Escobar Meeker (1992). Assessing influence regression analysis  censored data. Biometrics, 48, 507-528.","code":""},{"path":[]},{"path":"/reference/predict.survreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predicted Values for a `survreg' Object — predict.survreg","text":"","code":"# Draw figure 1 from Escobar and Meeker, 1992. fit <- survreg(Surv(time,status) ~ age + I(age^2), data=stanford2,    dist='lognormal')  with(stanford2, plot(age, time, xlab='Age', ylab='Days',    xlim=c(0,65), ylim=c(.1, 10^5), log='y', type='n')) with(stanford2, points(age, time, pch=c(2,4)[status+1], cex=.7)) pred <- predict(fit, newdata=list(age=1:65), type='quantile',             p=c(.1, .5, .9))  matlines(1:65, pred, lty=c(2,1,2), col=1)    # Predicted Weibull survival curve for a lung cancer subject with #  ECOG score of 2 lfit <- survreg(Surv(time, status) ~ ph.ecog, data=lung) pct <- 1:98/100   # The 100th percentile of predicted survival is at +infinity ptime <- predict(lfit, newdata=data.frame(ph.ecog=2), type='quantile',                  p=pct, se=TRUE) matplot(cbind(ptime$fit, ptime$fit + 2*ptime$se.fit,                          ptime$fit - 2*ptime$se.fit)/30.5, 1-pct,         xlab=\"Months\", ylab=\"Survival\", type='l', lty=c(1,2,2), col=1)"},{"path":"/reference/print.aareg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print an aareg object — print.aareg","title":"Print an aareg object — print.aareg","text":"Print fit Aalen's additive regression model","code":""},{"path":"/reference/print.aareg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print an aareg object — print.aareg","text":"","code":"# S3 method for aareg print(x, maxtime, test=c(\"aalen\", \"nrisk\"),scale=1,...)"},{"path":"/reference/print.aareg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print an aareg object — print.aareg","text":"x result call aareg function maxtime upper time point used test non-zero slope test weighting used test non-zero slope. default weights based variance coefficient, function time.  alternative weight proportional number subjects still risk time point. scale scales coefficients.   data sets, coefficients Aalen model small (10-4); simply multiplies printed values constant, say 1e6, make printout easier read. ... future methods","code":""},{"path":"/reference/print.aareg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print an aareg object — print.aareg","text":"calling argument returned.","code":""},{"path":"/reference/print.aareg.html","id":"side-effects","dir":"Reference","previous_headings":"","what":"Side Effects","title":"Print an aareg object — print.aareg","text":"results fit displayed.","code":""},{"path":"/reference/print.aareg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print an aareg object — print.aareg","text":"estimated increments coefficient estimates can become quite unstable near end follow-, due small number observations still risk data set. Thus, test slope sometimes powerful last `tail' excluded.","code":""},{"path":"/reference/print.aareg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print an aareg object — print.aareg","text":"Aalen, O.O. (1989). linear regression model analysis life times. Statistics Medicine, 8:907-925.","code":""},{"path":[]},{"path":"/reference/print.summary.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for summary.coxph objects — print.summary.coxph","title":"Print method for summary.coxph objects — print.summary.coxph","text":"Produces printed summary fitted coxph model","code":""},{"path":"/reference/print.summary.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for summary.coxph objects — print.summary.coxph","text":"","code":"# S3 method for summary.coxph print(x, digits=max(getOption(\"digits\") - 3, 3),   signif.stars = getOption(\"show.signif.stars\"), expand=FALSE, ...)"},{"path":"/reference/print.summary.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for summary.coxph objects — print.summary.coxph","text":"x result call summary.coxph digits significant digits print signif.stars Show stars highlight small p-values expand summary multi-state coxph fit, print     results expanded format. ... future methods","code":""},{"path":"/reference/print.summary.survexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Survexp Summary — print.summary.survexp","title":"Print Survexp Summary — print.summary.survexp","text":"Prints results summary.survexp","code":""},{"path":"/reference/print.summary.survexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Survexp Summary — print.summary.survexp","text":"","code":"# S3 method for summary.survexp print(x, digits = max(options()$digits - 4, 3), ...)"},{"path":"/reference/print.summary.survexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Survexp Summary — print.summary.survexp","text":"x object class summary.survexp. digits number digits use printing result. ... future methods","code":""},{"path":"/reference/print.summary.survexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Survexp Summary — print.summary.survexp","text":"x, invisible flag set prevent printing.","code":""},{"path":"/reference/print.summary.survexp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Survexp Summary — print.summary.survexp","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/print.summary.survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Survfit Summary — print.summary.survfit","title":"Print Survfit Summary — print.summary.survfit","text":"Prints result summary.survfit.","code":""},{"path":"/reference/print.summary.survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Survfit Summary — print.summary.survfit","text":"","code":"# S3 method for summary.survfit print(x, digits = max(options() $digits-4, 3), ...)"},{"path":"/reference/print.summary.survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Survfit Summary — print.summary.survfit","text":"x object class \"summary.survfit\", result  summary.survfit function. digits number digits use printing numbers. ... future methods","code":""},{"path":"/reference/print.summary.survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Survfit Summary — print.summary.survfit","text":"x, invisible flag set prevent printing.","code":""},{"path":"/reference/print.summary.survfit.html","id":"side-effects","dir":"Reference","previous_headings":"","what":"Side Effects","title":"Print Survfit Summary — print.summary.survfit","text":"prints summary created summary.survfit.","code":""},{"path":[]},{"path":"/reference/print.survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a Short Summary of a Survival Curve — print.survfit","title":"Print a Short Summary of a Survival Curve — print.survfit","text":"Print number observations, number events, restricted   mean survival   standard error, median survival confidence limits   median.","code":""},{"path":"/reference/print.survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a Short Summary of a Survival Curve — print.survfit","text":"","code":"# S3 method for survfit print(x, scale=1, digits = max(options()$digits - 4,3),     print.rmean=getOption(\"survfit.print.rmean\"),     rmean = getOption('survfit.rmean'),...)"},{"path":"/reference/print.survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a Short Summary of a Survival Curve — print.survfit","text":"x result call survfit function. scale numeric value rescale survival time, e.g.,  input data survfit days,  scale=365 scale printout years. digits Number digits print print.rmean,rmean Options computation display   restricted mean. ... future results","code":""},{"path":"/reference/print.survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a Short Summary of a Survival Curve — print.survfit","text":"x, invisible flag set prevent printing.   (default print functions R return object   passed ; print.survfit complies pattern.  want   capture printed results processing, see  table component summary.survfit.)","code":""},{"path":"/reference/print.survfit.html","id":"side-effects","dir":"Reference","previous_headings":"","what":"Side Effects","title":"Print a Short Summary of a Survival Curve — print.survfit","text":"number observations, number events,  median survival confidence interval, optionally restricted mean survival (rmean) standard error, printed. multiple curves, one line output .","code":""},{"path":"/reference/print.survfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print a Short Summary of a Survival Curve — print.survfit","text":"mean variance based truncated estimator.  ,  last observation(s) death, survival curve estimate  go zero mean undefined. four possible approaches resolve , selected rmean option. first set upper limit constant, e.g.,rmean=365. case reported mean expected number days, first 365, experienced group.  useful interest focuses fixed period. options \"none\" (estimate), \"common\" \"individual\". \"common\" option uses maximum time curves object common upper limit auc calculation. \"individual\"options mean computed area curve, range 0 maximum observed time curve. Since end point random, values different curves comparable printed standard errors underestimate take account random variation.  option provided mainly backwards compatability, estimate default () one earlier releases code. Note SAS (version 9.3) uses integral last event time individual curve; consider worst choices provide option calculation. median confidence interval defined drawing horizontal  line 0.5 plot survival curve confidence bands. line intersect curve, median undefined. intersection line lower CI band defines lower limit  median's interval, similarly upper band.   intersections point use center intersection interval,  e.g., survival curve exactly equal 0.5 interval. data uncensored agrees usual definition median.","code":""},{"path":"/reference/print.survfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print a Short Summary of a Survival Curve — print.survfit","text":"Miller, Rupert G., Jr. (1981).   Survival Analysis. New York:Wiley, p 71.","code":""},{"path":[]},{"path":"/reference/pseudo.html","id":null,"dir":"Reference","previous_headings":"","what":"Pseudo values for survival. — pseudo","title":"Pseudo values for survival. — pseudo","text":"Produce pseudo values survival curve.","code":""},{"path":"/reference/pseudo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pseudo values for survival. — pseudo","text":"","code":"pseudo(fit, times, type, addNA=TRUE, data.frame=FALSE, minus1=FALSE, ...)"},{"path":"/reference/pseudo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pseudo values for survival. — pseudo","text":"fit survfit object, one inherits class. times vector time points, evaluate pseudo values. type type value, either probabilty state pstate,     cumulative hazard cumhaz expected sojourn time     state sojourn. addNA observations removed due missing values     fit object, add rows (NA) return.     causes result pseudo match original dataframe. data.frame TRUE, return data \"long\" form     data.frame id, time, pseudo variables. minus1 use n-1 multiplier rather n . ... arguments residuals.survfit function,  majority work, e.g., collapse weighted.","code":""},{"path":"/reference/pseudo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pseudo values for survival. — pseudo","text":"function computes pseudo values based first order Taylor series, also known \"infinitesimal jackknife\" (IJ) \"dfbeta\" residuals.  completely correct results perhaps called `IJ pseudo values' even pseudo psuedo-values. moderate large data, however, resulting values almost identical, numerically, ordinary jackknife. primary advantage approach computational speed. features, neither good bad, agree robust standard errors survival package estimates, based IJ, mean estimates, subjects, exactly underlying survival estimate. type variable, surv acceptable synonym pstate, rmst rmts equivalent sojourn. case insensitive. result routine simply n times IJ value, n number subjects. (survfit call included id option, n number unique id values, otherwise number rows data set.)  IJ values well defined variants Aalen-Johansen estimate, computed survfit function; indeed, basis standard errors result. Understanding properties pseudo-values, however, still evolving.  Validity shown simplest case (Kaplan-Meier), competing risks, corresponding sojourn times. hand, one must careful data includes left-truncation (P. K. Andersen, personal communication), also pseudo-values cumulative hazard. understanding evolves, treat routine's results reseach tool, production, complex models.","code":""},{"path":"/reference/pseudo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pseudo values for survival. — pseudo","text":"vector, matrix, array.  first dimension always number   observations fit object, order original   data set (less missing values removed creating   survfit object);   second, applicable, corresponds fit$states, e.g.,   multi-state   survival, last dimension selected time points.   (multiple rows given id, one   pseudovalue per unique id.) data.frame option, data frame containing values id,   time, pseudo.  original survfit call contained  id statement, values id column   taken variable.  id statement simple   form, e.g., id = patno, name id column   `patno', otherwise named `(id)'.","code":""},{"path":"/reference/pseudo.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pseudo values for survival. — pseudo","text":"code slightly faster model=TRUE option   used survfit call.  may essential   survfit/pseudo pair used inside another function.","code":""},{"path":"/reference/pseudo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pseudo values for survival. — pseudo","text":"PK Andersen M Pohar-Perme, Pseudo-observations surivival analysis, Stat Methods Medical Res, 2010; 19:71-99","code":""},{"path":[]},{"path":"/reference/pseudo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pseudo values for survival. — pseudo","text":"","code":"fit1 <- survfit(Surv(time, status) ~ 1, data=lung) yhat <- pseudo(fit1, times=c(365, 730)) dim(yhat) #> [1] 228   2 lfit <- lm(yhat[,1] ~ ph.ecog + age + sex, data=lung)  # Restricted Mean Time in State (RMST)  rms <- pseudo(fit1, times= 730, type='RMST') # 2 years rfit <- lm(rms ~ ph.ecog + sex, data=lung) rhat <- predict(rfit, newdata=expand.grid(ph.ecog=0:3, sex=1:2), se.fit=TRUE) # print it out nicely temp1 <- cbind(matrix(rhat$fit, 4,2)) temp2 <- cbind(matrix(rhat$se.fit, 4, 2)) temp3 <- cbind(temp1[,1], temp2[,1], temp1[,2], temp2[,2]) dimnames(temp3) <- list(paste(\"ph.ecog\", 0:3),                          c(\"Male RMST\", \"(se)\", \"Female RMST\", \"(se)\"))  round(temp3, 1) #>           Male RMST (se) Female RMST (se) #> ph.ecog 0     393.7 28.6       510.6 31.5 #> ph.ecog 1     307.8 19.8       424.7 24.4 #> ph.ecog 2     221.9 29.7       338.8 33.4 #> ph.ecog 3     136.1 47.9       253.0 50.5 # compare this to the fully non-parametric estimate fit2 <- survfit(Surv(time, status) ~ ph.ecog, data=lung) print(fit2, rmean=730) #> Call: survfit(formula = Surv(time, status) ~ ph.ecog, data = lung) #>  #>    1 observation deleted due to missingness  #>             n events rmean* se(rmean) median 0.95LCL 0.95UCL #> ph.ecog=0  63     37    429      32.2    394     348     574 #> ph.ecog=1 113     82    366      22.4    306     268     429 #> ph.ecog=2  50     44    256      30.0    199     156     288 #> ph.ecog=3   1      1    118       0.0    118      NA      NA #>     * restricted mean with upper limit =  730  # the estimate for ph.ecog=3 is very unstable (n=1), pseudovalues smooth it. # # In all the above we should be using the robust variance, e.g., svyglm, but #  a recommended package can't depend on external libraries. # See the vignette for a more complete exposition."},{"path":"/reference/pspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoothing splines using a pspline basis — pspline","title":"Smoothing splines using a pspline basis — pspline","text":"Specifies penalised spline basis predictor.     done fitting comparatively small set splines     penalising integrated second derivative.     Traditional smoothing splines use one basis per observation, several     authors pointed final results fit      indistinguishable number basis functions greater      2-3 times degrees freedom.      Eilers Marx point basis functions evenly spaced,     leads significant computational simplification, refer     result p-spline.","code":""},{"path":"/reference/pspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoothing splines using a pspline basis — pspline","text":"","code":"pspline(x, df=4, theta, nterm=2.5 * df, degree=3, eps=0.1, method,    Boundary.knots=range(x), intercept=FALSE, penalty=TRUE, combine, ...)  psplineinverse(x)"},{"path":"/reference/pspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smoothing splines using a pspline basis — pspline","text":"x psline: covariate vector.     function apply factor variables.     psplineinverse x result pspline call. df desired degrees freedom.     One arguments df theta' must given, .     df=0, AIC = (loglik -df) used choose     \"optimal\" degrees freedom.  AIC chosen, optional     argument `caic=T' can used specify corrected AIC     Hurvich et. al. theta roughness penalty fit.     monotone function degrees freedom, theta=1     corresponding linear fit theta=0 unconstrained fit     nterm degrees freedom. nterm number splines basis degree degree splines eps accuracy df method method choosing tuning parameter theta.     theta given, 'fixed' assumed.     degrees freedom given, 'df' assumed.     method='aic' degrees freedom chosen automatically using     Akaike's information criterion. ... optional arguments control function Boundary.knots spline linear beyond boundary knots.     default range data. intercept TRUE, basis functions include intercept. penalty FALSE large number attributes     penalized fits excluded.  useful create pspline     basis matrix uses. combine optional vector increasing integers.  two     adjacent values combine equal, corresponding     coefficients fit forced equal.  useful     monotone fits, see vignette details.","code":""},{"path":"/reference/pspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smoothing splines using a pspline basis — pspline","text":"Object class pspline, coxph.penalty containing spline basis,  appropriate attributes  recognized penalized term coxph survreg functions. psplineinverse original x vector reconstructed.","code":""},{"path":[]},{"path":"/reference/pspline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Smoothing splines using a pspline basis — pspline","text":"Eilers, Paul H. Marx, Brian D. (1996). Flexible smoothing B-splines penalties.     Statistical Science, 11, 89-121. Hurvich, C.M. Simonoff, J.S. Tsai, Chih-Ling (1998). Smoothing parameter selection nonparametric regression using         improved Akaike information criterion, JRSSB, volume 60, 271--293.","code":""},{"path":"/reference/pspline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smoothing splines using a pspline basis — pspline","text":"","code":"lfit6 <- survreg(Surv(time, status)~pspline(age, df=2), lung) plot(lung$age, predict(lfit6), xlab='Age', ylab=\"Spline prediction\") title(\"Cancer Data\")  fit0 <- coxph(Surv(time, status) ~ ph.ecog + age, lung) fit1 <- coxph(Surv(time, status) ~ ph.ecog + pspline(age,3), lung) fit3 <- coxph(Surv(time, status) ~ ph.ecog + pspline(age,8), lung) fit0 #> Call: #> coxph(formula = Surv(time, status) ~ ph.ecog + age, data = lung) #>  #>             coef exp(coef) se(coef)     z        p #> ph.ecog 0.443485  1.558128 0.115831 3.829 0.000129 #> age     0.011281  1.011345 0.009319 1.211 0.226082 #>  #> Likelihood ratio test=19.06  on 2 df, p=7.279e-05 #> n= 227, number of events= 164  #>    (1 observation deleted due to missingness) fit1 #> Call: #> coxph(formula = Surv(time, status) ~ ph.ecog + pspline(age, 3),  #>     data = lung) #>  #>                             coef se(coef)      se2    Chisq   DF       p #> ph.ecog                  0.44802  0.11707  0.11678 14.64453 1.00 0.00013 #> pspline(age, 3), linear  0.01126  0.00928  0.00928  1.47231 1.00 0.22498 #> pspline(age, 3), nonlin                             2.07924 2.08 0.37143 #>  #> Iterations: 4 outer, 12 Newton-Raphson #>      Theta= 0.861  #> Degrees of freedom for terms= 1.0 3.1  #> Likelihood ratio test=21.9  on 4.08 df, p=2e-04 #> n= 227, number of events= 164  #>    (1 observation deleted due to missingness) fit3 #> Call: #> coxph(formula = Surv(time, status) ~ ph.ecog + pspline(age, 8),  #>     data = lung) #>  #>                             coef se(coef)      se2    Chisq   DF       p #> ph.ecog                  0.47640  0.12024  0.11925 15.69732 1.00 7.4e-05 #> pspline(age, 8), linear  0.01172  0.00923  0.00923  1.61161 1.00    0.20 #> pspline(age, 8), nonlin                             6.93188 6.99    0.43 #>  #> Iterations: 5 outer, 15 Newton-Raphson #>      Theta= 0.691  #> Degrees of freedom for terms= 1 8  #> Likelihood ratio test=27.6  on 8.97 df, p=0.001 #> n= 227, number of events= 164  #>    (1 observation deleted due to missingness)"},{"path":"/reference/pyears.html","id":null,"dir":"Reference","previous_headings":"","what":"Person Years — pyears","title":"Person Years — pyears","text":"function computes person-years follow-time contributed  cohort subjects, stratified subgroups.  also computes number subjects contribute cell  output table, optionally number events /expected number  events cell.","code":""},{"path":"/reference/pyears.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Person Years — pyears","text":"","code":"pyears(formula, data, weights, subset, na.action,  rmap,        ratetable, scale=365.25, expect=c('event', 'pyears'),        model=FALSE, x=FALSE, y=FALSE, data.frame=FALSE)"},{"path":"/reference/pyears.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Person Years — pyears","text":"formula formula object.      response variable vector follow-times      subject, Surv object containing survival     time event indicator.      predictors consist optional grouping variables      separated + operators (exactly survfit),     time-dependent grouping      variables age (specified tcut), optionally      ratetable term.      latter matches subject /expected cohort. data data frame interpret variables named      formula, subset weights     argument. weights case weights. subset expression saying subset rows data      used fit. na.action missing-data filter function, applied model.frame,      subset argument used.     Default options()$na.action. rmap optional list maps data set names ratetable names.  See     details section . ratetable table event rates, survexp.uswhite. scale scaling results.  rate tables units/day,      default value 365.25 causes output reported years. expect output table include expected number events,     expected number person-years observation.  valid     rate table. data.frame return data frame rather set arrays. model, x, y true,     model frame, model matrix, /vector response times     returned components final result.","code":""},{"path":"/reference/pyears.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Person Years — pyears","text":"list components: pyears array containing person-years exposure. (units, depending  rate table scale). dimension dimnames array correspond variables right hand side model equation. n array containing number subjects contribute time cell  pyears array. event array containing observed number events.  present  response variable Surv object. expected array containing expected number events (person years  expect =\"pyears\").  present  ratetable term. data data.frame option set, data frame containing variables n, event, pyears event supplants four arrays listed , along variables corresponding dimension. one row cell arrays. offtable number person-years exposure cohort part  cell pyears array.  often useful error check;  mismatch units two variables, nearly person  years may table. tcut whether call included time-dependent cutpoints. summary summary rate-table matching. also useful error  check. call image call function. observations number observations input data set, missings removed. na.action na.action attribute contributed na.action routine, .","code":""},{"path":"/reference/pyears.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Person Years — pyears","text":"pyears may several time variables, necessary  units.  instance, call natural unit ratetable hazard per day, important futime,  age entry.dt days.  Given wide range possible inputs,  difficult routine sanity checks aspect. ratetable used may different variable names user's data set, dealt rmap argument.   rate table calculation survexp.us, call summary{survexp.us} reveals expects variables  age = age days, sex, year = date study entry, create rmap line.  sex variable mapped, therefore code assumes exists mydata correct format.  (Note: factors sex, program match unique abbreviation, ignoring case.) special function tcut needed specify time-dependent cutpoints.  instance, assume age years, desired final  arrays one margins age groups 0-2, 2-10, 10-25, 25+.  subject enters study age 4 remains observation  10 years contribute follow-time 2-10 10-25  subsets.  cut(age, c(0,2,10,25,100)) used formula,  subject classified according starting age .  tcut function arguments cut,  produces different output object allows pyears function  correctly track subject. results pyears normally used input calculations.  print routine, therefore, designed give summary  table.","code":"py <- pyears(futime ~ rx, rmap=list(age=age, sex=sex, year=entry.dt),                     ratetable=survexp.us)"},{"path":[]},{"path":"/reference/pyears.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Person Years — pyears","text":"","code":"# Look at progression rates jointly by calendar date and age #  temp.yr  <- tcut(mgus$dxyr, 55:92, labels=as.character(55:91))  temp.age <- tcut(mgus$age, 34:101, labels=as.character(34:100)) ptime <- ifelse(is.na(mgus$pctime), mgus$futime, mgus$pctime) pstat <- ifelse(is.na(mgus$pctime), 0, 1) pfit <- pyears(Surv(ptime/365.25, pstat) ~ temp.yr + temp.age + sex,  mgus,      data.frame=TRUE)  # Turn the factor back into numerics for regression tdata <- pfit$data tdata$age <- as.numeric(as.character(tdata$temp.age)) tdata$year<- as.numeric(as.character(tdata$temp.yr)) fit1 <- glm(event ~ year + age+ sex +offset(log(pyears)),              data=tdata, family=poisson) if (FALSE) { # fit a gam model  gfit.m <- gam(y ~ s(age) + s(year) + offset(log(time)),                           family = poisson, data = tdata)  }  # Example #2  Create the hearta data frame:  hearta <- by(heart, heart$id,                function(x)x[x$stop == max(x$stop),])  hearta <- do.call(\"rbind\", hearta)  # Produce pyears table of death rates on the surgical arm #  The first is by age at randomization, the second by current age fit1 <- pyears(Surv(stop/365.25, event) ~ cut(age + 48, c(0,50,60,70,100)) +         surgery, data = hearta, scale = 1) fit2 <- pyears(Surv(stop/365.25, event) ~ tcut(age + 48, c(0,50,60,70,100)) +         surgery, data = hearta, scale = 1) fit1$event/fit1$pyears  #death rates on the surgery and non-surg arm #>                                     surgery #> cut(age + 48, c(0, 50, 60, 70, 100))         0         1 #>                             (0,50]   0.7615378 0.3036881 #>                             (50,60]  2.0068681 0.9979508 #>                             (60,70]  5.1083916       NaN #>                             (70,100]       NaN       NaN  fit2$event/fit2$pyears  #death rates on the surgery and non-surg arm #>                                      surgery #> tcut(age + 48, c(0, 50, 60, 70, 100))         0         1 #>                           0+ thru  50 0.8013285 0.2636994 #>                          50+ thru  60 1.6119238 0.6564817 #>                          60+ thru  70 3.9701087       NaN #>                          70+ thru 100       NaN       NaN"},{"path":"/reference/quantile.survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantiles from a survfit object — quantile.survfit","title":"Quantiles from a survfit object — quantile.survfit","text":"Retrieve quantiles confidence intervals   survfit Surv object.","code":""},{"path":"/reference/quantile.survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantiles from a survfit object — quantile.survfit","text":"","code":"# S3 method for survfit quantile(x, probs = c(0.25, 0.5, 0.75), conf.int = TRUE,   scale, tolerance= sqrt(.Machine$double.eps), ...) # S3 method for survfitms quantile(x, probs = c(0.25, 0.5, 0.75), conf.int = TRUE,   scale, tolerance= sqrt(.Machine$double.eps), ...) # S3 method for survfit median(x, ...)"},{"path":"/reference/quantile.survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantiles from a survfit object — quantile.survfit","text":"x result survfit function probs numeric vector probabilities values [0,1] conf.int lower upper confidence limits returned? scale optional scale factor, e.g., scale=365.25     return results years fit object days. tolerance tolerance checking survival curve exactly     equals one quantiles ... optional arguments methods","code":""},{"path":"/reference/quantile.survfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantiles from a survfit object — quantile.survfit","text":"kth quantile survival curve S(t) location   horizontal line height p= 1-k intersects plot S(t).   Since S(t) step function, possible curve   horizontal segment exactly 1-k, case midpoint   horizontal segment returned.  mirrors standard behavior   median data uncensored.  survival curve   fall 1-k, quantile undefined. order consistent quantile functions, argument   prob function applies cumulative distribution   function F(t) = 1-S(t). Confidence limits values based intersection   horizontal line 1-k upper lower limits   survival curve.  Hence confidence limits use   p-value effect curve created, differ   depending conf.type option survfit.   survival curves confidence bands, confidence limits   quantiles available. horizontal segment survival curve exactly matches one   requested quantiles returned value midpoint   horizontal segment; agrees usual definition median   uncensored data.  Since survival curve computed series   products, however, may round error.   Assume instance sample size 20 tied times   censoring.  survival curve 10th death   (19/20)(18/19)(17/18) ... (10/11) = 10/20, computed result   exactly 0.5. horizontal segment whose absolute difference   requested percentile less tolerance   considered exact match.","code":""},{"path":"/reference/quantile.survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantiles from a survfit object — quantile.survfit","text":"quantiles vector survfit object contains     single curve, otherwise matrix array.      case last dimension index quantiles. confidence limits requested, result list     components  quantile, lower, upper, otherwise     vector matrix quantiles.","code":""},{"path":"/reference/quantile.survfit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantiles from a survfit object — quantile.survfit","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/quantile.survfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantiles from a survfit object — quantile.survfit","text":"","code":"fit <- survfit(Surv(time, status) ~ ph.ecog, data=lung) quantile(fit) #> $quantile #>            25  50  75 #> ph.ecog=0 285 394 655 #> ph.ecog=1 181 306 550 #> ph.ecog=2 105 199 351 #> ph.ecog=3 118 118 118 #>  #> $lower #>            25  50  75 #> ph.ecog=0 189 348 558 #> ph.ecog=1 156 268 460 #> ph.ecog=2  61 156 285 #> ph.ecog=3  NA  NA  NA #>  #> $upper #>            25  50  75 #> ph.ecog=0 350 574  NA #> ph.ecog=1 223 429 689 #> ph.ecog=2 163 288 654 #> ph.ecog=3  NA  NA  NA #>   cfit <- coxph(Surv(time, status) ~ age + strata(ph.ecog), data=lung) csurv<- survfit(cfit, newdata=data.frame(age=c(40, 60, 80)),                   conf.type =\"none\") temp <- quantile(csurv, 1:5/10) temp[2,3,]  # quantiles for second level of ph.ecog, age=80 #>  10  20  30  40  50  #>  92 144 181 218 270  quantile(csurv[2,3], 1:5/10)  # quantiles of a single curve, same result #>  10  20  30  40  50  #>  92 144 181 218 270"},{"path":"/reference/ratetable.html","id":null,"dir":"Reference","previous_headings":"","what":"Allow ratetable() terms in a model — ratetable","title":"Allow ratetable() terms in a model — ratetable","text":"function supports ratetable() terms model   statement, within survexp pyears.","code":""},{"path":"/reference/ratetable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allow ratetable() terms in a model — ratetable","text":"","code":"ratetable(...)"},{"path":"/reference/ratetable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allow ratetable() terms in a model — ratetable","text":"... named dimensions rate table","code":""},{"path":"/reference/ratetable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Allow ratetable() terms in a model — ratetable","text":"way mapping rate table's variable names user data frame   superseded, instead use rmap argument   survexp, pyears, survdiff routines.  function remains   allow older code run.","code":""},{"path":"/reference/ratetable.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Allow ratetable() terms in a model — ratetable","text":"Terry Therneau","code":""},{"path":"/reference/ratetableDate.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert date objects to ratetable form — ratetableDate","title":"Convert date objects to ratetable form — ratetableDate","text":"method converts dates various forms   internal form used ratetable objects.","code":""},{"path":"/reference/ratetableDate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert date objects to ratetable form — ratetableDate","text":"","code":"ratetableDate(x)"},{"path":"/reference/ratetableDate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert date objects to ratetable form — ratetableDate","text":"x date.  function currently methods Date, date,     POSIXt, timeDate, chron objects.","code":""},{"path":"/reference/ratetableDate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert date objects to ratetable form — ratetableDate","text":"function useful create new ratetables,   normally invisible users.   used internally survexp pyears   functions map various date formats; new method added   routines automatically adapted new date type.","code":""},{"path":"/reference/ratetableDate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert date objects to ratetable form — ratetableDate","text":"numeric vector, number days since 1/1/1960.","code":""},{"path":"/reference/ratetableDate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert date objects to ratetable form — ratetableDate","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/rats.html","id":null,"dir":"Reference","previous_headings":"","what":"Rat treatment data from Mantel et al — rats","title":"Rat treatment data from Mantel et al — rats","text":"Rat treatment data Mantel et al.   Three rats chosen 100 litters, one   treated drug, followed tumor incidence.","code":""},{"path":"/reference/rats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rat treatment data from Mantel et al — rats","text":"","code":"rats data(cancer, package=\"survival\")"},{"path":[]},{"path":"/reference/rats.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Rat treatment data from Mantel et al — rats","text":"N. Mantel, N. R. Bohidar J. L. Ciminera.   Mantel-Haenszel analyses litter-matched time response data,   modifications recovery interlitter information.   Cancer Research, 37:3863-3868, 1977.","code":""},{"path":"/reference/rats.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Rat treatment data from Mantel et al — rats","text":"E. W. Lee, L. J. Wei, D. Amato,     Cox-type regression analysis large number small groups     correlated failure time observations,     \"Survival Analysis, State Art\", Kluwer, 1992.","code":""},{"path":"/reference/rats.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Rat treatment data from Mantel et al — rats","text":"Since 2/150 male rats tumor, analyses use     females (odd numbered litters), e.g. Lee et al.","code":""},{"path":"/reference/rats2.html","id":null,"dir":"Reference","previous_headings":"","what":"Rat data from Gail et al. — rats2","title":"Rat data from Gail et al. — rats2","text":"48 rats injected carcinogen,   randomized either drug placebo.  number tumors ranges   0 13; rats  censored 6 months randomization.","code":""},{"path":"/reference/rats2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rat data from Gail et al. — rats2","text":"","code":"rats2 data(cancer, package=\"survival\")"},{"path":[]},{"path":"/reference/rats2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Rat data from Gail et al. — rats2","text":"MH Gail, TJ Santner, CC Brown (1980),   analysis comparative carcinogenesis experiments based   multiple times tumor.   Biometrics 36, 255--266.","code":""},{"path":"/reference/reliability.html","id":null,"dir":"Reference","previous_headings":"","what":"Reliability data sets — reliability","title":"Reliability data sets — reliability","text":"set data simple reliablility analyses, taken book Meeker Escobar.","code":""},{"path":"/reference/reliability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reliability data sets — reliability","text":"","code":"data(reliability, package=\"survival\")"},{"path":"/reference/reliability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reliability data sets — reliability","text":"capacitor:     Data factorial experiment life glass capacitors     function voltage operating temperature.  8 capacitors     combination temperature voltage.     Testing combination terminated fourth failure. temperature: temperature degrees celcius voltage: applied voltage time: time failure status: 1=failed, 0=censored cracks: Data time development cracks     set 167 identical turbine parts.     parts inspected 8 selected times. day: time inspection fail: number fans found cracks, inspection Data set genfan: Time failure 70 diesel engine fans. hours: hours service status: 1=failure, 0=censored Data set ifluid:     data frame two variables describing time electrical     breakdown insulating fluid. time: hours breakdown voltage: test voltage kV Data set imotor: Breakdown motor insulation function     temperature. temp: temperature test time: time failure censoring status: 0=censored, 1=failed Data set turbine:     432 turbine wheels inspected     determine whether crack developed wheel . hours: time inspection (100s hours) inspected: number inspected failed: number failed Data set valveSeat:     Time replacement valve seats 41 diesel engines.      one seat may replaced particular service, leading duplicate     times data set.  final inspection time engine     status=0. id: engine identifier time: time inspection, days status: 1=replacement occured, 0= ","code":""},{"path":"/reference/reliability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reliability data sets — reliability","text":"Meeker Escobar, Statistical Methods Reliability Data, 1998.","code":""},{"path":"/reference/reliability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reliability data sets — reliability","text":"","code":"survreg(Surv(time, status) ~ temperature + voltage, capacitor) #> Call: #> survreg(formula = Surv(time, status) ~ temperature + voltage,  #>     data = capacitor) #>  #> Coefficients: #> (Intercept) temperature     voltage  #> 13.40701688 -0.02890466 -0.00591082  #>  #> Scale= 0.3638092  #>  #> Loglik(model)= -244.2   Loglik(intercept only)= -254.5 #> \tChisq= 20.57 on 2 degrees of freedom, p= 3.41e-05  #> n= 64"},{"path":"/reference/residuals.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Residuals for a `coxph' Fit — residuals.coxph","title":"Calculate Residuals for a `coxph' Fit — residuals.coxph","text":"Calculates martingale, deviance, score Schoenfeld residuals Cox proportional hazards model.","code":""},{"path":"/reference/residuals.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Residuals for a `coxph' Fit — residuals.coxph","text":"","code":"# S3 method for coxph residuals(object,        type=c(\"martingale\", \"deviance\", \"score\", \"schoenfeld\",         \"dfbeta\", \"dfbetas\", \"scaledsch\",\"partial\"),        collapse=FALSE, weighted= (type %in% c(\"dfbeta\", \"dfbetas\")), ...) # S3 method for coxphms residuals(object,        type=c(\"martingale\", \"score\", \"schoenfeld\",         \"dfbeta\", \"dfbetas\", \"scaledsch\"),        collapse=FALSE, weighted= FALSE, ...) # S3 method for coxph.null residuals(object,        type=c(\"martingale\", \"deviance\",\"score\",\"schoenfeld\"),        collapse=FALSE, weighted= FALSE, ...)"},{"path":"/reference/residuals.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Residuals for a `coxph' Fit — residuals.coxph","text":"object object inheriting class coxph, representing fitted Cox regression model. Typically output coxph function. type character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\"', \"dfbetas\", \"scaledsch\" \"partial\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1, 2, 3,3, 4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. ... unused arguments","code":""},{"path":"/reference/residuals.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Residuals for a `coxph' Fit — residuals.coxph","text":"martingale deviance residuals, returned object vector one element subject (without collapse). score residuals matrix one row per subject one column per variable. row order match input data original fit. Schoenfeld residuals, returned object matrix one row event one column per variable.  rows ordered time within strata, attribute strata attached contains number observations strata. scaled Schoenfeld residuals used cox.zph function. score residuals individual's contribution score vector. Two transformations often useful: dfbeta approximate change coefficient vector observation dropped, dfbetas approximate change coefficients, scaled standard error coefficients.","code":""},{"path":"/reference/residuals.coxph.html","id":"note","dir":"Reference","previous_headings":"","what":"NOTE","title":"Calculate Residuals for a `coxph' Fit — residuals.coxph","text":"deviance residuals, status variable may need reconstructed. score Schoenfeld residuals, X matrix need reconstructed.","code":""},{"path":"/reference/residuals.coxph.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Residuals for a `coxph' Fit — residuals.coxph","text":"T. Therneau, P. Grambsch, T. Fleming. \"Martingale based residuals survival models\", Biometrika, March 1990.","code":""},{"path":[]},{"path":"/reference/residuals.coxph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Residuals for a `coxph' Fit — residuals.coxph","text":"","code":"fit <- coxph(Surv(start, stop, event) ~ (age + surgery)* transplant,                data=heart)  mresid <- resid(fit, collapse=heart$id)"},{"path":"/reference/residuals.survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"IJ residuals from a survfit object. — residuals.survfit","title":"IJ residuals from a survfit object. — residuals.survfit","text":"Return infinitesimal jackknife residuals survfit object,   survival, cumulative hazard, restricted mean time state (RMTS).","code":""},{"path":"/reference/residuals.survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IJ residuals from a survfit object. — residuals.survfit","text":"","code":"# S3 method for survfit residuals(object, times,      type=\"pstate\", collapse, weighted=FALSE,     method=1, ...)"},{"path":"/reference/residuals.survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IJ residuals from a survfit object. — residuals.survfit","text":"object survfit object times vector times residuals desired type type residual, see collapse add residuals subjects cluster.     survfit object used id statement, default     collapse variable. weighted weight residuals observation's weight method controls choice algorithm.  Current internal     debugging option. ... arguments methods","code":""},{"path":"/reference/residuals.survfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"IJ residuals from a survfit object. — residuals.survfit","text":"function designed efficiently compute leverage residuals small number time points; primary use creation pseudo-values. residuals time points needed, e.g. compute robust pointwise confidence interval survival curve, can done efficiently using influence argument underlying survfit function.  aware matrices can get large. residuals impact observation cluster resulting probability state curves given time points, cumulative hazard curvsurv time points, expected sojourn time state given time points. simple Kaplan-Meier survfit object contains probability \"initial\" state, .e., survival fraction. KM case sojourn time, expected amount time spent initial state, specified endpoint, commonly known restricted mean survival time (RMST). multistate model quantity also referred restricted mean time state (RMTS). can computed area respective probability state curve. program allows pstate, surv, cumhaz, chaz, sojourn, rmst, rmts auc type argument, ignoring upper/lowercase, users can choose whichever abbreviation like best. collapse=TRUE result cluster identifier (defaults id variable) dimname first dimension. fit object contains one curve, identifier reused two different curves approach work routine stop error. principle necessary, e.g., result contain two rows label, showing separate effect curve, deemed confusing.","code":""},{"path":"/reference/residuals.survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IJ residuals from a survfit object. — residuals.survfit","text":"matrix array one row per observation cluster, one column   value times.  multi-state model three   dimensions observation, time state.  cumulative hazard,   last dimension set transitions.  (competing risks   model instance 3 states 2 transitions.)","code":""},{"path":[]},{"path":"/reference/residuals.survfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"IJ residuals from a survfit object. — residuals.survfit","text":"","code":"fit <- survfit(Surv(time, status) ~ x, aml) resid(fit, times=c(24, 48), type=\"RMTS\") #>             [,1]         [,2] #>  [1,] -1.0836777 -2.076652893 #>  [2,] -0.7200413 -1.713016529 #>  [3,]  0.2004132  0.421074380 #>  [4,] -0.3237345 -1.468414256 #>  [5,]  0.1876291 -0.957050620 #>  [6,]  0.2899019  0.965676653 #>  [7,]  0.2899019 -0.359777893 #>  [8,]  0.2899019  0.008403926 #>  [9,]  0.2899019  1.726585744 #> [10,]  0.2899019  1.726585744 #> [11,]  0.2899019  1.726585744 #> [12,] -1.0057870 -1.475694444 #> [13,] -1.0057870 -1.475694444 #> [14,] -0.7557870 -1.225694444 #> [15,] -0.7557870 -1.225694444 #> [16,] -0.4224537 -0.892361111 #> [17,]  0.5636574  0.899305556 #> [18,]  0.4826389 -0.121527778 #> [19,]  0.5798611  0.267361111 #> [20,]  0.5798611  0.559027778 #> [21,]  0.5798611  0.850694444 #> [22,]  0.5798611  1.822916667 #> [23,]  0.5798611  2.017361111"},{"path":"/reference/residuals.survreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Residuals for `survreg' Objects — residuals.survreg","title":"Compute Residuals for `survreg' Objects — residuals.survreg","text":"method function residuals objects inheriting class survreg.","code":""},{"path":"/reference/residuals.survreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Residuals for `survreg' Objects — residuals.survreg","text":"","code":"# S3 method for survreg residuals(object, type=c(\"response\", \"deviance\",\"dfbeta\",\"dfbetas\", \"working\",\"ldcase\",\"ldresp\",\"ldshape\", \"matrix\"), rsigma=TRUE, collapse=FALSE, weighted=FALSE, ...)"},{"path":"/reference/residuals.survreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Residuals for `survreg' Objects — residuals.survreg","text":"object object inheriting class survreg. type type residuals, choices \"response\", \"deviance\", \"dfbeta\", \"dfbetas\", \"working\", \"ldcase\", \"lsresp\", \"ldshape\", \"matrix\". rsigma include scale parameters variance matrix, computations. (can think good reason ). collapse optional vector subject groups.  given, must length residuals, causes result per group residuals. weighted give weighted residuals?  Normally residuals unweighted. ... unused arguments","code":""},{"path":"/reference/residuals.survreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Residuals for `survreg' Objects — residuals.survreg","text":"vector matrix residuals returned. Response residuals scale original data, working residuals scale linear predictor, deviance residuals log-likelihood scale. dfbeta residuals matrix, ith row gives approximate change coefficients due addition subject . dfbetas matrix contains dfbeta residuals, column scaled standard deviation coefficient. matrix type produces matrix based derivatives log-likelihood function.  Let \\(L\\) log-likelihood, \\(p\\) linear predictor \\(X\\beta\\), \\(s\\) \\(\\log(\\sigma)\\).  6 columns matrix \\(L\\), \\(dL/dp\\),\\(\\partial^2L/\\partial p^2\\), \\(dL/ds\\), \\(\\partial^2L/\\partial s^2\\)  \\(\\partial^2L/\\partial p\\partial s\\). Diagnostics based quantities discussed book article Escobar Meeker. main ones likelihood displacement residuals perturbation case weight (ldcase), response value (ldresp), shape. transformed distribution log-normal Weibull, matrix residuals based log-likelihood transformed data log(y).  monotone function f density f(X) density X divided derivative f (Jacobian), subtract log(derivative) uncensored observation's loglik value order match loglik component result.  colums matrix residual unchanged transformation.","code":""},{"path":"/reference/residuals.survreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Residuals for `survreg' Objects — residuals.survreg","text":"Escobar, L. . Meeker, W. Q. (1992). Assessing influence regression analysis censored data. Biometrics 48, 507-528. Escobar, L. . Meeker, W. Q. (1998). Statistical Methods Reliablilty Data.  Wiley.","code":""},{"path":[]},{"path":"/reference/residuals.survreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Residuals for `survreg' Objects — residuals.survreg","text":"","code":"fit <- survreg(Surv(futime, death) ~ age + sex, mgus2) summary(fit)   # age and sex are both important #>  #> Call: #> survreg(formula = Surv(futime, death) ~ age + sex, data = mgus2) #>                Value Std. Error      z       p #> (Intercept)  8.85979    0.23842  37.16 < 2e-16 #> age         -0.05360    0.00312 -17.19 < 2e-16 #> sexM        -0.31874    0.06357  -5.01 5.3e-07 #> Log(scale)  -0.02840    0.02787  -1.02    0.31 #>  #> Scale= 0.972  #>  #> Weibull distribution #> Loglik(model)= -5528.3   Loglik(intercept only)= -5699 #> \tChisq= 341.42 on 2 degrees of freedom, p= 7.3e-75  #> Number of Newton-Raphson Iterations: 5  #> n= 1384  #>   rr  <- residuals(fit, type='matrix') sum(rr[,1]) - with(mgus2, sum(log(futime[death==1]))) # loglik #> [1] -5528.267  plot(mgus2$age, rr[,2], col= (1+mgus2$death)) # ldresp"},{"path":"/reference/retinopathy.html","id":null,"dir":"Reference","previous_headings":"","what":"Diabetic Retinopathy — retinopathy","title":"Diabetic Retinopathy — retinopathy","text":"trial laser coagulation treatment delay   diabetic retinopathy.","code":""},{"path":"/reference/retinopathy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diabetic Retinopathy — retinopathy","text":"","code":"retinopathy data(retinopathy, package=\"survival\")"},{"path":"/reference/retinopathy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Diabetic Retinopathy — retinopathy","text":"data frame 394 observations following 9 variables. id numeric subject id laser type laser used: xenon argon eye eye treated: right left age age diagnosis diabetes type type diabetes: juvenile adult,         (diagnosis age 20) trt 0 = control eye, 1 = treated eye futime time loss vision last follow-status 0 = censored, 1 = loss vision eye risk risk score eye.  high risk        subset defined score 6 greater least one eye.","code":""},{"path":"/reference/retinopathy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diabetic Retinopathy — retinopathy","text":"197 patients dataset 50% random sample patients \"high-risk\" diabetic retinopathy defined Diabetic Retinopathy Study (DRS).  patient one eye randomized laser treatment eye received treatment, two observations data set. eye, event interest time initiation treatment time visual acuity dropped 5/200 two visits row. Thus built-lag time approximately 6 months (visits every 3 months).  Survival times dataset actual time vision loss months, minus minimum possible time event (6.5 months).  Censoring caused death, dropout, end study.","code":""},{"path":"/reference/retinopathy.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Diabetic Retinopathy — retinopathy","text":"W. J. Huster, R. Brookmeyer S. G. Self (1989). Modelling paired survival data covariates, Biometrics 45:145-156. . L. Blair, D. R. Hadden, J. . Weaver, D. B. Archer, P. B. Johnston C. J. Maguire (1976).  5-year prognosis vision diabetes, American Journal Ophthalmology, 81:383-396.","code":""},{"path":"/reference/retinopathy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Diabetic Retinopathy — retinopathy","text":"","code":"coxph(Surv(futime, status) ~ type + trt, cluster= id, retinopathy) #> Call: #> coxph(formula = Surv(futime, status) ~ type + trt, data = retinopathy,  #>     cluster = id) #>  #>               coef exp(coef) se(coef) robust se      z        p #> typeadult  0.05388   1.05536  0.16211   0.17864  0.302    0.763 #> trt       -0.77893   0.45890  0.16893   0.14851 -5.245 1.56e-07 #>  #> Likelihood ratio test=22.48  on 2 df, p=1.312e-05 #> n= 394, number of events= 155"},{"path":"/reference/rhDNase.html","id":null,"dir":"Reference","previous_headings":"","what":"rhDNASE data set — rhDNase","title":"rhDNASE data set — rhDNase","text":"Results randomized trial rhDNase treatment cystic   fibrosis.","code":""},{"path":"/reference/rhDNase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rhDNASE data set — rhDNase","text":"","code":"rhDNase data(rhDNase, package=\"survival\")"},{"path":"/reference/rhDNase.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rhDNASE data set — rhDNase","text":"data frame 767 observations following 8 variables. id subject id inst enrolling institution trt treatment arm: 0=placebo, 1= rhDNase entry.dt date entry study end.dt date last follow-fev forced expriatory volume enrollment, measure     lung capacity ivstart days enrollment start IV antibiotics ivstop days enrollment cessation       IV antibiotics","code":""},{"path":"/reference/rhDNase.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"rhDNASE data set — rhDNase","text":"patients cystic fibrosis, extracellular DNA released leukocytes accumulate airways response chronic bacterial infection. excess DNA thickens mucus, cleared lung cilia.  accumulation leads exacerbations respiratory symptoms progressive deterioration lung function. time study  90% cystic fibrosis patients eventually died lung disease. Deoxyribonuclease (DNase ) human enzyme normally present mucus human lungs digests extracellular DNA. Genentech, Inc. cloned highly purified recombinant DNase (rhDNase Pulmozyme) delivered lungs aerosolized form cuts extracellular DNA, reducing viscoelasticity airway secretions improving clearance. 1992 company conducted randomized double-blind trial comparing rhDNase placebo. Patients monitored pulmonary exacerbations, along measures lung volume flow. primary endpoint time first pulmonary exacerbation; however, data exacerbations collected 169 days. definition exacerbation infection required use intravenous (IV) antibiotics.  Subjects 0--5 episodes trial, one multiple rows data set, none NA IV start end times. subjects infected time enrollment, subject 173 instance first infection interval -21 7.  count first infection \"event\", subject first enters risk set day 7. Subjects event considered risk another event course antibiotics, additional 6 days end.  (symptoms reappear immediately cessation medical standpoint new infection.) data set reproduces data Therneau Grambsch, exactly reproduce Therneau Hamilton due data set updates.","code":""},{"path":"/reference/rhDNase.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"rhDNASE data set — rhDNase","text":"T. M. Therneau P. M. Grambsch, Modeling Survival Data: Extending   Cox Model, Springer, 2000. T. M. Therneau S.. Hamilton, rhDNase example recurrent event analysis, Statistics Medicine, 16:2029-2047, 1997.","code":""},{"path":"/reference/rhDNase.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"rhDNASE data set — rhDNase","text":"","code":"# Build the start-stop data set for analysis, and #  replicate line 2 of table 8.13 in the book first <- subset(rhDNase, !duplicated(id)) #first row for each subject dnase <- tmerge(first, first, id=id, tstop=as.numeric(end.dt -entry.dt))  # Subjects whose fu ended during the 6 day window are the reason for #  this next line temp.end <- with(rhDNase, pmin(ivstop+6, end.dt-entry.dt)) dnase <- tmerge(dnase, rhDNase, id=id,                        infect=event(ivstart),                        end=  event(temp.end)) # toss out the non-at-risk intervals, and extra variables #  3 subjects had an event on their last day of fu, infect=1 and end=1 dnase <- subset(dnase, (infect==1 | end==0), c(id:trt, fev:infect)) agfit <- coxph(Surv(tstart, tstop, infect) ~ trt + fev, cluster=id,                  data=dnase)"},{"path":"/reference/ridge.html","id":null,"dir":"Reference","previous_headings":"","what":"Ridge regression — ridge","title":"Ridge regression — ridge","text":"used coxph survreg model formula, specifies ridge regression term.  likelihood penalised theta/2 time sum squared coefficients. scale=T penalty calculated coefficients based rescaling predictors unit variance. df specified theta chosen based approximate degrees freedom.","code":""},{"path":"/reference/ridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ridge regression — ridge","text":"","code":"ridge(..., theta, df=nvar/2, eps=0.1, scale=TRUE)"},{"path":"/reference/ridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ridge regression — ridge","text":"... predictors ridged theta penalty theta/2 time sum squared coefficients df Approximate degrees freedom eps Accuracy required df scale Scale variables applying penalty?","code":""},{"path":"/reference/ridge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Ridge regression — ridge","text":"expression ridge(x1, x2, x3, ...) many characters   long  internal terms() function add newlines variable name  coxph routine simply gets lost.  (labels newline  .)  One solution bundle variables single matrix  use matrix argument ridge shorten call,  e.g. mdata$many <- .matrix(mydata[,5:53]).","code":""},{"path":"/reference/ridge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ridge regression — ridge","text":"object class coxph.penalty containing data control functions.","code":""},{"path":"/reference/ridge.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ridge regression — ridge","text":"Gray (1992) \"Flexible methods analysing survival data using splines, applications breast cancer prognosis\" JASA 87:942--951","code":""},{"path":[]},{"path":"/reference/ridge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ridge regression — ridge","text":"","code":"coxph(Surv(futime, fustat) ~ rx + ridge(age, ecog.ps, theta=1),         ovarian) #> Call: #> coxph(formula = Surv(futime, fustat) ~ rx + ridge(age, ecog.ps,  #>     theta = 1), data = ovarian) #>  #>                   coef se(coef)     se2   Chisq DF      p #> rx             -0.8564   0.6161  0.6156  1.9323  1 0.1645 #> ridge(age)      0.1229   0.0385  0.0354 10.2127  1 0.0014 #> ridge(ecog.ps)  0.1093   0.5734  0.5484  0.0363  1 0.8488 #>  #> Iterations: 1 outer, 5 Newton-Raphson #> Degrees of freedom for terms= 1.0 1.8  #> Likelihood ratio test=15.6  on 2.76 df, p=0.001 #> n= 26, number of events= 12   lfit0 <- survreg(Surv(time, status) ~1, lung) lfit1 <- survreg(Surv(time, status) ~ age + ridge(ph.ecog, theta=5), lung) lfit2 <- survreg(Surv(time, status) ~ sex + ridge(age, ph.ecog, theta=1), lung) lfit3 <- survreg(Surv(time, status) ~ sex + age + ph.ecog, lung)"},{"path":"/reference/rotterdam.html","id":null,"dir":"Reference","previous_headings":"","what":"Breast cancer data set used in Royston and Altman (2013) — rotterdam","title":"Breast cancer data set used in Royston and Altman (2013) — rotterdam","text":"rotterdam data set includes 2982 primary breast cancers patients whose records included Rotterdam tumor bank.","code":""},{"path":"/reference/rotterdam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Breast cancer data set used in Royston and Altman (2013) — rotterdam","text":"","code":"rotterdam data(cancer, package=\"survival\")"},{"path":"/reference/rotterdam.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Breast cancer data set used in Royston and Altman (2013) — rotterdam","text":"data frame 2982 observations following 15 variables. pid patient identifier year year surgery age age surgery meno menopausal status (0= premenopausal, 1= postmenopausal) size tumor size, factor levels <=20 20-50 >50 grade differentiation grade nodes number positive lymph nodes pgr progesterone receptors (fmol/l) er estrogen receptors (fmol/l) hormon hormonal treatment (0=, 1=yes) chemo chemotherapy rtime days relapse last follow-recur 0= relapse, 1= relapse dtime days death last follow-death 0= alive, 1= dead","code":""},{"path":"/reference/rotterdam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Breast cancer data set used in Royston and Altman (2013) — rotterdam","text":"data sets used paper Royston Altman   referenced . Rotterdam data used create fitted model, GBSG data  validation model.  paper gives references data source. 43 subjects died without recurrence, whose death time greater censoring time recurrence. common way happens death date updated health record sometime research study ended, said value picked study data set created. Vital status information can come many sources: patient visit another condition, correspondence, financial transactions, social media. raises serious questions censoring. instance subject 40 censored recurrence 4.2 years died 6.6 years; creating endpoint recurrence free survival (earlier recurrence death), treating death 6.6 years implicitly assumes recurrence free just death. true assume progressed 2.4 year interval death (study), information also noted general medical record, also captured study data set. However, may unlikely.  Death information often centralized location electronic health records, easily accessed programmer merged study data, recurrence may require manual review.  best address open issue.","code":""},{"path":[]},{"path":"/reference/rotterdam.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Breast cancer data set used in Royston and Altman (2013) — rotterdam","text":"Patrick Royston Douglas Altman, External validation Cox prognostic model: principles methods.  BMC Medical Research Methodology 2013, 13:33","code":""},{"path":"/reference/rotterdam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Breast cancer data set used in Royston and Altman (2013) — rotterdam","text":"","code":"# liberal definition of rfs (count later deaths) rfs  <- pmax(rotterdam$recur, rotterdam$death) rfstime <- with(rotterdam, ifelse(recur==1, rtime, dtime)) fit1 <- coxph(Surv(rfstime, rfs) ~ pspline(age) + meno + size +          pspline(nodes) + er,  data = rotterdam)  # conservative (no deaths after last fu for recurrence) ignore <- with(rotterdam, recur ==0 & death==1 & rtime < dtime) table(ignore) #> ignore #> FALSE  TRUE  #>  2939    43  rfs2 <- with(rotterdam, ifelse(recur==1 | ignore, recur, death)) rfstime2 <- with(rotterdam, ifelse(recur==1 | ignore, rtime, dtime)) fit2 <- coxph(Surv(rfstime2, rfs2) ~ pspline(age) + meno + size +          pspline(nodes) + er,  data = rotterdam)  # Note: Both age and nodes show non-linear effects. # Royston and Altman used fractional polynomials for the nonlinear terms"},{"path":"/reference/royston.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Royston's D for a Cox model — royston","title":"Compute Royston's D for a Cox model — royston","text":"Compute D statistic proposed Royston Sauerbrei along   several pseudo- R square values.","code":""},{"path":"/reference/royston.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Royston's D for a Cox model — royston","text":"","code":"royston(fit, newdata, ties = TRUE, adjust = FALSE)"},{"path":"/reference/royston.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Royston's D for a Cox model — royston","text":"fit coxph fit newdata optional validation data set ties make correction ties risk score adjust adjust possible overfitting","code":""},{"path":"/reference/royston.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Royston's D for a Cox model — royston","text":"values called pseudo R-squared since involve   linear predictor, outcome.   R.D value corresponsds Royston Sauerbrei   \\(D\\) statistic.  R.KO value proposed Kent   O'Quigley, R.N value proposed Nagelkerke,   C.GH corresponds Goen Heller's concordance measure. adjustment D based ratio   r= (number events)/(number coefficients). models   sufficient sample size (r>20) adjustment small. Nagelkirke value Cox-Snell R-squared divided scaling   constant. two separate values present result   summary.coxph 2 element vector rsq, listed   \"Rsquare\" \"max possible\" older versions print routine.   (Since superseded default printout concordance.)   Nagelkirke estimate returned newdata present.","code":""},{"path":"/reference/royston.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Royston's D for a Cox model — royston","text":"vector containing value D, estimated standard error   D, three four pseudo R-squared values.","code":""},{"path":"/reference/royston.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Royston's D for a Cox model — royston","text":"M. Goen G. Heller, Concordance probability discriminatory power proportional hazards regression.  Biometrika 92:965-970, 2005. N. Nagelkerke, J. Oosting, J. . Hart, simple test goodness fit Cox's proportional hazards model.  Biometrics 40:483-486, 1984. P. Royston W. Sauerbrei, new measure prognostic separation survival data.  Statistics Medicine 23:723-748, 2004.","code":""},{"path":"/reference/royston.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Royston's D for a Cox model — royston","text":"","code":"# An example used in Royston and Sauerbrei pbc2 <- na.omit(pbc)  # no missing values cfit <- coxph(Surv(time, status==2) ~ age + log(bili) + edema + albumin +                    stage + copper, data=pbc2, ties=\"breslow\") royston(cfit) #>         D     se(D)       R.D      R.KO       R.N      C.GH  #> 2.6917766 0.2273352 0.6336693 0.5554885 0.4714442 0.7735923"},{"path":"/reference/rttright.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute redistribute-to-the-right weights — rttright","title":"Compute redistribute-to-the-right weights — rttright","text":"many survival estimands, one approach redistribute  censored observation's weight observations longer  survival time (think distributing estate heirs).  compute remaining, uncensored data.","code":""},{"path":"/reference/rttright.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute redistribute-to-the-right weights — rttright","text":"","code":"rttright(formula, data, weights, subset, na.action, times, id, timefix = TRUE,          renorm= TRUE)"},{"path":"/reference/rttright.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute redistribute-to-the-right weights — rttright","text":"formula formula object, must      Surv object       response left ~ operator , desired, terms       separated + operators right.      unique combination predictors define separate strata. data data frame interpret variables named formula,      subset weights arguments. weights weights must nonnegative strongly recommended       strictly positive, since zero weights ambiguous, compared      use subset argument. subset expression saying subset rows data      used fit. na.action missing-data filter function, applied model frame,      subset argument used.      Default options()$na.action. times vector time points, return updated     weights.  missing, time largest time data     assumed. id optional: data set multiple rows per subject,     variable containing subect identifier row. timefix correct possible round-error renorm resulting weights sum 1 within group","code":""},{"path":"/reference/rttright.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute redistribute-to-the-right weights — rttright","text":"formula argument treated exactly   survfit function. Redistribution recursive: redistribute weight first   censored observation longer time, may include   censored observations.  redistribute next smallest   etc. specified time value.   re-distributing weight censored observation   observations censored, ordinary non-censored methods can   often applied.  example, redistribution weights,   followed computation weighted cumulative distribution   function, reprises Kaplan-Meier estimator. primary use routine illustration methods   exploration new methods.  Methods use RTTR directly,   Brier score, often compuations internally. covariate right hand side formula causes   redistribution occur within group; censoring group 1   redistributes weights others group 1, etc.  appropriate   censoring pattern depends upon group.","code":""},{"path":"/reference/rttright.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute redistribute-to-the-right weights — rttright","text":"vector matrix weights, one column requested time","code":""},{"path":[]},{"path":"/reference/rttright.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute redistribute-to-the-right weights — rttright","text":"","code":"afit <- survfit(Surv(time, status) ~1, data=aml) rwt  <- rttright(Surv(time, status) ~1, data=aml)  # Reproduce a Kaplan-Meier index <- order(aml$time) cdf <- cumsum(rwt[index])  # weighted CDF cdf <- cdf[!duplicated(aml$time[index], fromLast=TRUE)]  # remove duplicate times cbind(time=afit$time, KM= afit$surv, RTTR= 1-cdf) #>       time         KM       RTTR #>  [1,]    5 0.91304348  -1.000000 #>  [2,]    8 0.82608696  -3.000000 #>  [3,]    9 0.78260870  -4.000000 #>  [4,]   12 0.73913043  -5.000000 #>  [5,]   13 0.69565217  -6.000000 #>  [6,]   16 0.69565217  -6.000000 #>  [7,]   18 0.64596273  -7.142857 #>  [8,]   23 0.54658385  -9.428571 #>  [9,]   27 0.49689441 -10.571429 #> [10,]   28 0.49689441 -10.571429 #> [11,]   30 0.44168392 -11.841270 #> [12,]   31 0.38647343 -13.111111 #> [13,]   33 0.33126294 -14.380952 #> [14,]   34 0.27605245 -15.650794 #> [15,]   43 0.22084196 -16.920635 #> [16,]   45 0.16563147 -18.190476 #> [17,]   48 0.08281573 -20.095238 #> [18,]  161 0.08281573 -20.095238  # Hormonal patients have a diffent censoring pattern wt2 <- rttright(Surv(dtime, death) ~ hormon, rotterdam, times= 365*c(3, 5)) dim(wt2) #> [1] 2982    2"},{"path":"/reference/solder.html","id":null,"dir":"Reference","previous_headings":"","what":"Data from a soldering experiment — solder","title":"Data from a soldering experiment — solder","text":"1988 experiment designed implemented one &T's factories investigate alternatives \"wave soldering\" procedure mounting electronic componentes printed circuit boards. experiment varied number factors relevant process. response, measured eye, number visible solder skips.","code":""},{"path":"/reference/solder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data from a soldering experiment — solder","text":"","code":"solder data(solder, package=\"survival\")"},{"path":"/reference/solder.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data from a soldering experiment — solder","text":"data frame 900 observations following 6 variables. Opening amount clearance around mounting       pad (3 levels) Solder amount solder (Thick Thin) Mask type thickness material used       solder mask (A1.5, A3, A6, B3, B6) PadType geometry size mounting pad (10 levels) Panel board divided 3 panels skips number skips","code":""},{"path":"/reference/solder.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data from a soldering experiment — solder","text":"data set used detailed example chapter 1 Chambers Hastie. Observations 1-360 541-900 form balanced design 3*2*10*3= 180 observations four pad types (A1.5, A3, B3, B6), rows 361-540 match 3 6 Solder*Opening combinations pad type A6 3 pad type A3.","code":""},{"path":"/reference/solder.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data from a soldering experiment — solder","text":"J Chambers T Hastie, Statistical models S.  Chapman Hall, 1993.","code":""},{"path":"/reference/solder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data from a soldering experiment — solder","text":"","code":"# The balanced subset used by Chambers and Hastie #   contains the first 180 of each mask and deletes mask A6.  index <- 1 + (1:nrow(solder)) - match(solder$Mask, solder$Mask) solder.balance <- droplevels(subset(solder, Mask != \"A6\" & index <= 180))"},{"path":"/reference/stanford2.html","id":null,"dir":"Reference","previous_headings":"","what":"More Stanford Heart Transplant data — stanford2","title":"More Stanford Heart Transplant data — stanford2","text":"contains Stanford Heart Transplant data different   format.  main data set heart.","code":""},{"path":"/reference/stanford2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"More Stanford Heart Transplant data — stanford2","text":"","code":"stanford2"},{"path":[]},{"path":[]},{"path":"/reference/stanford2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"More Stanford Heart Transplant data — stanford2","text":"LA Escobar WQ Meeker Jr (1992),   Assessing influence regression analysis censored data.   Biometrics 48, 507--528.   Page 519.","code":""},{"path":"/reference/statefig.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw a state space figure. — statefig","title":"Draw a state space figure. — statefig","text":"multi-state survival models useful figure   shows states possible transitions .   function creates simple \"box arrows\" figure.  goal   simplicity.","code":""},{"path":"/reference/statefig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw a state space figure. — statefig","text":"","code":"statefig(layout, connect, margin = 0.03, box = TRUE, cex = 1, col = 1,   lwd=1, lty=1, bcol=col, acol=col, alwd=lwd, alty=lty, offset=0)"},{"path":"/reference/statefig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw a state space figure. — statefig","text":"layout describes layout boxes page.  See     detailed description . connect square matrix one row state.   connect[,j] !=0 arrow drawn state   state j.  row names matrix used labels   states. margin fraction white space label     surrounding box, box arrows, function     plot region size. box boxes drawn?  TRUE FALSE. cex, col, lty, lwd default graphical parameters used   text boxes.  last 3 can vector values. bcol color box, differs used   text. acol, alwd, alty color, line type line width arrows. offset used slight offset arrows two boxes x y   transition directions.  default 0   leads double headed arrow case -- arrows drawn   coincide.  positive value causes arrow shift   left, view someone standing foot arrow   looking towards arrowhead, negative offset shifts right.   value 1 corresponds size plotting region.","code":""},{"path":"/reference/statefig.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draw a state space figure. — statefig","text":"arguments color, line type line width can vectors,   case recycled needed.  Boxes text drawn   order rownames connect, arrows drawn   usual R matrix order. layout argument normally vector integers, e.g.,   vector (1, 3, 2) describes layout 3 columns.  first   single state, second column 3 states third 2.   coordinates plotting region 0 1 x y.   Within column centers boxes evenly spaced, 1/2   space boxes margin, e.g., 4 boxes 1/8,   3/8, 5/8 7/8.  layout 1 column matrix values   (1, 3, 2) layout three rows 1, 3, 2   boxes per row, respectively.  Alternatively, user can supply   2 column matrix directly gives centers. values connect matrix 0 pairs states   transition values 0 2 .   States connected arc passes centers   two boxes third point .  Specifically,   consider line segment joining two centers erect second   segment right angles midpoint length d times distance   center midpoint.  arc passes point.  value   d=0 gives straight line, d=1 right hand half circle centered   midpoint d= -1 left hand half circle.     connect matrix contains values d+1 -1 < d < 1. connecting arrow drawn (center box 1 + offset)   (center box 2 + offset), amount offset (white   space) determined box margin parameters.   pair states close together can result   arrow points wrong way.","code":""},{"path":"/reference/statefig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw a state space figure. — statefig","text":"matrix containing centers boxes, invisible   attribute set.","code":""},{"path":"/reference/statefig.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Draw a state space figure. — statefig","text":"Terry Therneau","code":""},{"path":"/reference/statefig.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Draw a state space figure. — statefig","text":"goal function make ``good enough'' figures simply   possible,   thereby encourage users draw .   layout argument inspired diagram package,   can draw complex well decorated figures, e.g., many   different shapes, shading,    multiple types connecting lines, etc.,   price greater complexity. curved lines drawn set short line segments, line   types almost effect case.","code":""},{"path":"/reference/statefig.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw a state space figure. — statefig","text":"","code":"# Draw a simple competing risks figure states <- c(\"Entry\", \"Complete response\", \"Relapse\", \"Death\") connect <- matrix(0, 4, 4, dimnames=list(states, states)) connect[1, -1] <- c(1.1, 1, 0.9) statefig(c(1, 3), connect)"},{"path":"/reference/strata.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify Stratification Variables — strata","title":"Identify Stratification Variables — strata","text":"special function used context Cox survival model.  identifies stratification variables appear right hand  side formula.","code":""},{"path":"/reference/strata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify Stratification Variables — strata","text":"","code":"strata(..., na.group=FALSE, shortlabel, sep=', ')"},{"path":"/reference/strata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify Stratification Variables — strata","text":"... number variables.  must length. na.group logical variable, TRUE, missing values treated  distinct level variable. shortlabel TRUE omit variable names resulting   factor labels.  default action omit names   arguments factors, none named. sep character used separate groups, created label","code":""},{"path":"/reference/strata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify Stratification Variables — strata","text":"new factor, whose levels possible combinations factors  supplied arguments.","code":""},{"path":"/reference/strata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify Stratification Variables — strata","text":"used outside coxph formula result function essentially identical interaction function,  though labels strata often verbose.","code":""},{"path":[]},{"path":"/reference/strata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify Stratification Variables — strata","text":"","code":"a <- factor(rep(1:3,4), labels=c(\"low\", \"medium\", \"high\")) b <- factor(rep(1:4,3)) levels(strata(b)) #> [1] \"1\" \"2\" \"3\" \"4\" levels(strata(a,b,shortlabel=TRUE)) #>  [1] \"low, 1\"    \"low, 2\"    \"low, 3\"    \"low, 4\"    \"medium, 1\" \"medium, 2\" #>  [7] \"medium, 3\" \"medium, 4\" \"high, 1\"   \"high, 2\"   \"high, 3\"   \"high, 4\"    coxph(Surv(futime, fustat) ~ age + strata(rx), data=ovarian)  #> Call: #> coxph(formula = Surv(futime, fustat) ~ age + strata(rx), data = ovarian) #>  #>        coef exp(coef) se(coef)     z       p #> age 0.13735   1.14723  0.04741 2.897 0.00376 #>  #> Likelihood ratio test=12.69  on 1 df, p=0.0003678 #> n= 26, number of events= 12"},{"path":"/reference/summary.aareg.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize an aareg fit — summary.aareg","title":"Summarize an aareg fit — summary.aareg","text":"Creates overall test statistics Aalen additive regression model","code":""},{"path":"/reference/summary.aareg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize an aareg fit — summary.aareg","text":"","code":"# S3 method for aareg summary(object, maxtime, test=c(\"aalen\", \"nrisk\"), scale=1,...)"},{"path":"/reference/summary.aareg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize an aareg fit — summary.aareg","text":"object result call aareg function maxtime truncate input model time \"maxtime\" test relative time weights used compute test scale scales coefficients.   data sets, coefficients Aalen model small (10-4); simply multiplies printed values constant, say 1e6, make printout easier read. ... future methods","code":""},{"path":"/reference/summary.aareg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize an aareg fit — summary.aareg","text":"list returned following components table matrix rows intercept covariate, columns giving slope estimate, test statistic, standard error, z-score p-value test time weighting used computing test statistics test.statistic vector test statistics test.var model based variance matrix test statistic test.var2 optionally, robust variance matrix test statistic chisq overall test (ignoring intercept term) significance variable n vector containing number observations, number unique death times used computation, total number unique death times","code":""},{"path":"/reference/summary.aareg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize an aareg fit — summary.aareg","text":"uncommon right-hand tail plot large outlying values, particularly standard error.   maxtime parameter can used truncate range avoid . gives updated value test statistics, without refitting model. slope based weighted linear regression cumulative coefficient plot, may useful measure overall size effect.  instance two models include common variable, \"age\" instance, may help assess much fit changed due variables, leiu overlaying two plots.  (course plots often highly non-linear, rough substitute). slope directly related test statistic, latter invariant monotone transformation time.","code":""},{"path":[]},{"path":[]},{"path":"/reference/summary.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for Cox models — summary.coxph","title":"Summary method for Cox models — summary.coxph","text":"Produces summary fitted coxph model","code":""},{"path":"/reference/summary.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for Cox models — summary.coxph","text":"","code":"# S3 method for coxph summary(object, conf.int=0.95, scale=1,...)"},{"path":"/reference/summary.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for Cox models — summary.coxph","text":"object result coxph fit conf.int level computation confidence intervals.      set FALSE confidence intervals printed scale vector scale factors coefficients, defaults 1.      printed coefficients, se, confidence intervals     associated one scale unit. ... future methods","code":""},{"path":"/reference/summary.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for Cox models — summary.coxph","text":"object class summary.coxph, components: n, nevent number observations number events,     respectively, fit loglik log partial likelihood initial final     values coefficients matrix one row coefficient,     columns containing coefficient, hazard ratio exp(coef),     standard error, Wald statistic, P value. conf.int matrix one row coefficient, containing     confidence limits exp(coef) logtest, sctest, waldtest overall likelihood ratio, score,     Wald test statistics model concordance concordance statistic standard error used.robust whether asymptotic robust variance used rsq approximate R^2 based Nagelkirke (Biometrika 1991). fail message, underlying coxph call failed call copy call na.action information missing values","code":""},{"path":"/reference/summary.coxph.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Summary method for Cox models — summary.coxph","text":"pseudo r-squared Nagelkirke attractive simple,   work shown poor properties now   deprecated.  value longer printed default,   eventually removed object.","code":""},{"path":[]},{"path":"/reference/summary.coxph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for Cox models — summary.coxph","text":"","code":"fit <- coxph(Surv(time, status) ~ age + sex, lung)  summary(fit) #> Call: #> coxph(formula = Surv(time, status) ~ age + sex, data = lung) #>  #>   n= 228, number of events= 165  #>  #>          coef exp(coef)  se(coef)      z Pr(>|z|)    #> age  0.017045  1.017191  0.009223  1.848  0.06459 .  #> sex -0.513219  0.598566  0.167458 -3.065  0.00218 ** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>     exp(coef) exp(-coef) lower .95 upper .95 #> age    1.0172     0.9831    0.9990    1.0357 #> sex    0.5986     1.6707    0.4311    0.8311 #>  #> Concordance= 0.603  (se = 0.025 ) #> Likelihood ratio test= 14.12  on 2 df,   p=9e-04 #> Wald test            = 13.47  on 2 df,   p=0.001 #> Score (logrank) test = 13.72  on 2 df,   p=0.001 #>"},{"path":"/reference/summary.pyears.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for pyears objecs — summary.pyears","title":"Summary function for pyears objecs — summary.pyears","text":"Create printable table person-years result.","code":""},{"path":"/reference/summary.pyears.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for pyears objecs — summary.pyears","text":"","code":"# S3 method for pyears summary(object, header = TRUE, call = header, n = TRUE, event = TRUE, pyears = TRUE, expected = TRUE, rate = FALSE, rr =expected, ci.r = FALSE, ci.rr = FALSE, totals=FALSE, legend = TRUE, vline = FALSE, vertical= TRUE, nastring=\".\", conf.level = 0.95, scale = 1, ...)"},{"path":"/reference/summary.pyears.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for pyears objecs — summary.pyears","text":"object pyears object header print header giving total number     observations, events, person-years, total time ()     omitted table call print copy call n, event, pyears, expected logical arguments:     elements printed table? rate, ci.r logical arguments: incidence rate /    confidence interval given table? rr, ci.rr logical arguments: hazard ratio /    confidence interval given table? totals row column totals added? legend legend included printout? vline vertical lines included printed tables? vertical single predictor,     table printed predictor left (vertical=TRUE)     across top (vertical=FALSE)? nastring use missing values table.    structural, e.g., risk ratios cell follow-time. conf.level confidence level confidence intervals scale scaling factor printed rates ... optional arguments passed     format function; common choices digits=2 nsmall=1.","code":""},{"path":"/reference/summary.pyears.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary function for pyears objecs — summary.pyears","text":"pyears function often used create initial   descriptions survival time--event variable; type   material often found ``table 1'' paper.  summary   routine prints information using one pandoc table styles.   primary reason choosing style Rstudio able   automatically render results multiple formats: html, rtf,   latex, etc. pyears call single covariate table   covariate one margin statistics interest   .   pyears call two predictors two predictors   used margins table, cell table   contains statistics interest multiple rows within cell.   two predictors multiple tables   produced, order standard R printout array. \"N\" entry pyears object number observations   contributed particular cell.  original call includes   tcut objects single observation may contribute   multiple cells.","code":""},{"path":"/reference/summary.pyears.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Summary function for pyears objecs — summary.pyears","text":"pandoc system four table types: without vertical bars,   single multiple rows data cell.   routine produces 4 styles depending options, currently   recognized Rstudio-pandoc pipeline.   (yet see .)","code":""},{"path":"/reference/summary.pyears.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary function for pyears objecs — summary.pyears","text":"copy object","code":""},{"path":"/reference/summary.pyears.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary function for pyears objecs — summary.pyears","text":"Terry Therneau Elizabeth Atkinson","code":""},{"path":[]},{"path":"/reference/summary.survexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for a survexp object — summary.survexp","title":"Summary function for a survexp object — summary.survexp","text":"Returns list containing values survival   specified times.","code":""},{"path":"/reference/summary.survexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for a survexp object — summary.survexp","text":"","code":"# S3 method for survexp summary(object, times, scale = 1, ...)"},{"path":"/reference/summary.survexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for a survexp object — summary.survexp","text":"object result call survexp function times vector times;      returned matrix contain 1 row time.      Missing values allowed. scale numeric value rescale survival time, e.g., input data      survfit      days, scale = 365.25 scale output years. ... future methods","code":""},{"path":"/reference/summary.survexp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary function for a survexp object — summary.survexp","text":"primary use function retrieve survival fixed time   points, properly interpolated function.","code":""},{"path":"/reference/summary.survexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary function for a survexp object — summary.survexp","text":"list following components: surv estimate survival time t. time timepoints curve. n.risk expected survival subject data set matched hypothetical person parent population, matched characteristics parent population. number risk number hypothetical subject still part calculation.","code":""},{"path":"/reference/summary.survexp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary function for a survexp object — summary.survexp","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/summary.survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of a Survival Curve — summary.survfit","title":"Summary of a Survival Curve — summary.survfit","text":"Returns list containing survival curve, confidence limits    curve, information.","code":""},{"path":"/reference/summary.survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of a Survival Curve — summary.survfit","text":"","code":"# S3 method for survfit summary(object, times, censored=FALSE, scale=1,   extend=FALSE, rmean=getOption('survfit.rmean'), ...)"},{"path":"/reference/summary.survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of a Survival Curve — summary.survfit","text":"object result call survfit function. times vector times;      returned matrix contain 1 row time.      vector sorted increasing order;     missing values allowed.      censored=T, default times vector contains     unique times fit, otherwise     default times vector uses event (death) times. censored logical value:  censoring times included output?     ignored times argument present. scale numeric value rescale survival time, e.g., input data      survfit      days, scale = 365.25 scale output years. extend logical value: TRUE, prints information specified times,      even subjects left end specified     times.      used times argument present. rmean Show restricted mean: see   print.survfit details ... future methods","code":""},{"path":"/reference/summary.survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of a Survival Curve — summary.survfit","text":"list following components: surv estimate survival time t+0. time timepoints curve. n.risk number subjects risk time t-0  (see comments weights survfit help file). n.event times argument missing, column number  events occurred time t.  Otherwise, cumulative number events occurred  since last time listed time t+0. n.entered present counting process survival data. times argument  missing, column number subjects entered time t.  Otherwise, cumulative number subjects entered  since last time listed time t. n.exit.censored times argument  missing, column number subjects left without  event time t.  Otherwise, cumulative number subjects left  without event  since last time listed time t+0.   present counting process survival data. std.err standard error survival value. conf.int level confidence confidence intervals survival. lower lower confidence limits curve. upper upper confidence limits curve. strata indicates stratification curve estimation.   strata NULL,  multiple curves result surv, time, n.risk, etc.   vectors contain multiple curves, pasted end end.   levels strata (factor) labels curves. call statement used create fit object. na.action fit, present. table table information returned print.survfit function. type type data censoring.  Passed fit object.","code":""},{"path":"/reference/summary.survfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary of a Survival Curve — summary.survfit","text":"routine two uses: printing survival curve specified time points (often yearly), extracting values specified time points processing. first case normally want extend=FALSE, .e., print data past end curve.  times option contains values beyond last point curve nothing print error message result. second usage almost always want extend=TRUE, results predictable length. survfit object row information censoring event time, save information unique entry time.  printout two time points t1, t2, function give number risk smallest event times >= t1 >= t2, respectively, survival curve largest recorded times <= t1 <= t2, number events censorings interval t1 < t <= t2. routine called counting process data many users confused counts large. example, Surv(c(0,0, 5, 5), c(2, 3, 8, 10), c(1, 0, 1, 0)) followed request values time 4. survfit object entries times 2, 3, 8, 10; 2 subjects risk time 8, printed.","code":""},{"path":[]},{"path":"/reference/summary.survfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of a Survival Curve — summary.survfit","text":"","code":"summary( survfit( Surv(futime, fustat)~1, data=ovarian)) #> Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian) #>  #>  time n.risk n.event survival std.err lower 95% CI upper 95% CI #>    59     26       1    0.962  0.0377        0.890        1.000 #>   115     25       1    0.923  0.0523        0.826        1.000 #>   156     24       1    0.885  0.0627        0.770        1.000 #>   268     23       1    0.846  0.0708        0.718        0.997 #>   329     22       1    0.808  0.0773        0.670        0.974 #>   353     21       1    0.769  0.0826        0.623        0.949 #>   365     20       1    0.731  0.0870        0.579        0.923 #>   431     17       1    0.688  0.0919        0.529        0.894 #>   464     15       1    0.642  0.0965        0.478        0.862 #>   475     14       1    0.596  0.0999        0.429        0.828 #>   563     12       1    0.546  0.1032        0.377        0.791 #>   638     11       1    0.497  0.1051        0.328        0.752 summary( survfit( Surv(futime, fustat)~rx, data=ovarian)) #> Call: survfit(formula = Surv(futime, fustat) ~ rx, data = ovarian) #>  #>                 rx=1  #>  time n.risk n.event survival std.err lower 95% CI upper 95% CI #>    59     13       1    0.923  0.0739        0.789        1.000 #>   115     12       1    0.846  0.1001        0.671        1.000 #>   156     11       1    0.769  0.1169        0.571        1.000 #>   268     10       1    0.692  0.1280        0.482        0.995 #>   329      9       1    0.615  0.1349        0.400        0.946 #>   431      8       1    0.538  0.1383        0.326        0.891 #>   638      5       1    0.431  0.1467        0.221        0.840 #>  #>                 rx=2  #>  time n.risk n.event survival std.err lower 95% CI upper 95% CI #>   353     13       1    0.923  0.0739        0.789        1.000 #>   365     12       1    0.846  0.1001        0.671        1.000 #>   464      9       1    0.752  0.1256        0.542        1.000 #>   475      8       1    0.658  0.1407        0.433        1.000 #>   563      7       1    0.564  0.1488        0.336        0.946 #>"},{"path":"/reference/Surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Survival Object — Surv","title":"Create a Survival Object — Surv","text":"Create survival object, usually used response variable model  formula. Argument matching special function, see Details .","code":""},{"path":"/reference/Surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Survival Object — Surv","text":"","code":"Surv(time, time2, event,     type=c('right', 'left', 'interval', 'counting', 'interval2', 'mstate'),     origin=0) is.Surv(x)"},{"path":"/reference/Surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Survival Object — Surv","text":"time right censored data, follow time.  interval     data, first argument starting time interval. event status indicator, normally 0=alive, 1=dead.  choices     TRUE/FALSE (TRUE = death) 1/2 (2=death).     interval censored data, status indicator 0=right censored,     1=event time, 2=left censored, 3=interval censored.     multiple endpoint data event variable factor,     whose first level treated censoring.     Although unusual, event indicator can omitted, case     subjects assumed event. time2 ending time interval interval censored  counting     process data .  Intervals assumed open left     closed right, (start, end].  counting process     data, event indicates whether event occurred end     interval. type character string specifying type censoring. Possible values     \"right\", \"left\", \"counting\",     \"interval\", \"interval2\" \"mstate\". origin counting process data, hazard function origin.  option     intended used conjunction model containing     time dependent     strata order align subjects properly cross     one strata another, rarely proven useful. x R object.","code":""},{"path":"/reference/Surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Survival Object — Surv","text":"object class Surv.  methods print,  .na, subscripting survival objects.   Surv objects   implemented matrix 2 3 columns   attributes. include type (left censored, right censored,   counting process, etc.) labels states multi-state   objects.  attributes input arguments also preserved   inputAttributes.  may useful packages   attached information data items labels; none   routines survival package make use   values, however. case .Surv, logical value TRUE x inherits class \"Surv\", otherwise FALSE.","code":""},{"path":"/reference/Surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Survival Object — Surv","text":"type argument missing code assumes type based   following rules: two unnamed arguments, match time      event order.  three unnamed arguments      match time, time2 event. event variable factor type mstate      assumed.  Otherwise type right time2      argument, type counting . consequence type argument normally omitted. survival type \"mstate\" status variable    treated factor.  first level factor taken    represent censoring remaining ones transition given    state.  (status variable factor mstate assumed.) Interval censored data can represented two ways.  first    use type = \"interval\" codes shown .  usage    value time2 argument ignored unless event=3.    second approach think observation time    interval (-infinity, t2) left censored, (t1, infinity)    right censored, (t,t) exact (t1, t2) interval.    approach used type = interval2.  Infinite values can    represented either actual infinity (Inf) NA.    second form proven useful one. Presently, methods allowing interval censored data  parametric models computed survreg survival curves computed survfit; ,  distinction open closed intervals unimportant.   distinction important counting process data  Cox model. function tries distinguish use 0/1 1/2 coding  censored data via condition  (max(status)==2).  1/2 coding used subjects censored,  guess wrong. questionable case safer use logical coding, e.g., Surv(time, status==3) indicate '3' code event. multi-state survival status variable factor, whose first level assumed correspond censoring. Surv objects can subscripted either vector, e.g. x[1:3] using single subscript, case drop argument ignored result survival object;  matrix using two subscripts. second subscript missing drop=F (default), result subscripting Surv object, e.g.,  x[1:3,,drop=F], otherwise result matrix (vector), accordance default behavior subscripting matrices.","code":""},{"path":"/reference/Surv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Create a Survival Object — Surv","text":"use 1/2 coding status interesting historical   artifact.   data contained punch cards, IBM 360 Fortran treated blank zero,   led policy within Mayo Clinic section Biostatistics never   use \"0\" data value since one distinguish   missing value.   Policy became habit, often case, use 1/2 coding   alive/dead endured long demise punch cards   sired practice.   time Surv written many Mayo data sets still used   obsolete convention, e.g., lung data set found package.","code":""},{"path":[]},{"path":"/reference/Surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Survival Object — Surv","text":"","code":"with(aml, Surv(time, status)) #>  [1]   9   13   13+  18   23   28+  31   34   45+  48  161+   5    5    8    8  #> [16]  12   16+  23   27   30   33   43   45  survfit(Surv(time, status) ~ ph.ecog, data=lung) #> Call: survfit(formula = Surv(time, status) ~ ph.ecog, data = lung) #>  #>    1 observation deleted due to missingness  #>             n events median 0.95LCL 0.95UCL #> ph.ecog=0  63     37    394     348     574 #> ph.ecog=1 113     82    306     268     429 #> ph.ecog=2  50     44    199     156     288 #> ph.ecog=3   1      1    118      NA      NA Surv(heart$start, heart$stop, heart$event)  #>   [1] (  0.0,  50.0]  (  0.0,   6.0]  (  0.0,   1.0+] (  1.0,  16.0]  #>   [5] (  0.0,  36.0+] ( 36.0,  39.0]  (  0.0,  18.0]  (  0.0,   3.0]  #>   [9] (  0.0,  51.0+] ( 51.0, 675.0]  (  0.0,  40.0]  (  0.0,  85.0]  #>  [13] (  0.0,  12.0+] ( 12.0,  58.0]  (  0.0,  26.0+] ( 26.0, 153.0]  #>  [17] (  0.0,   8.0]  (  0.0,  17.0+] ( 17.0,  81.0]  (  0.0,  37.0+] #>  [21] ( 37.0,1387.0]  (  0.0,   1.0]  (  0.0,  28.0+] ( 28.0, 308.0]  #>  [25] (  0.0,  36.0]  (  0.0,  20.0+] ( 20.0,  43.0]  (  0.0,  37.0]  #>  [29] (  0.0,  18.0+] ( 18.0,  28.0]  (  0.0,   8.0+] (  8.0,1032.0]  #>  [33] (  0.0,  12.0+] ( 12.0,  51.0]  (  0.0,   3.0+] (  3.0, 733.0]  #>  [37] (  0.0,  83.0+] ( 83.0, 219.0]  (  0.0,  25.0+] ( 25.0,1800.0+] #>  [41] (  0.0,1401.0+] (  0.0, 263.0]  (  0.0,  71.0+] ( 71.0,  72.0]  #>  [45] (  0.0,  35.0]  (  0.0,  16.0+] ( 16.0, 852.0]  (  0.0,  16.0]  #>  [49] (  0.0,  17.0+] ( 17.0,  77.0]  (  0.0,  51.0+] ( 51.0,1587.0+] #>  [53] (  0.0,  23.0+] ( 23.0,1572.0+] (  0.0,  12.0]  (  0.0,  46.0+] #>  [57] ( 46.0, 100.0]  (  0.0,  19.0+] ( 19.0,  66.0]  (  0.0,   4.5+] #>  [61] (  4.5,   5.0]  (  0.0,   2.0+] (  2.0,  53.0]  (  0.0,  41.0+] #>  [65] ( 41.0,1408.0+] (  0.0,  58.0+] ( 58.0,1322.0+] (  0.0,   3.0]  #>  [69] (  0.0,   2.0]  (  0.0,  40.0]  (  0.0,   1.0+] (  1.0,  45.0]  #>  [73] (  0.0,   2.0+] (  2.0, 996.0]  (  0.0,  21.0+] ( 21.0,  72.0]  #>  [77] (  0.0,   9.0]  (  0.0,  36.0+] ( 36.0,1142.0+] (  0.0,  83.0+] #>  [81] ( 83.0, 980.0]  (  0.0,  32.0+] ( 32.0, 285.0]  (  0.0, 102.0]  #>  [85] (  0.0,  41.0+] ( 41.0, 188.0]  (  0.0,   3.0]  (  0.0,  10.0+] #>  [89] ( 10.0,  61.0]  (  0.0,  67.0+] ( 67.0, 942.0+] (  0.0, 149.0]  #>  [93] (  0.0,  21.0+] ( 21.0, 343.0]  (  0.0,  78.0+] ( 78.0, 916.0+] #>  [97] (  0.0,   3.0+] (  3.0,  68.0]  (  0.0,   2.0]  (  0.0,  69.0]  #> [101] (  0.0,  27.0+] ( 27.0, 842.0+] (  0.0,  33.0+] ( 33.0, 584.0]  #> [105] (  0.0,  12.0+] ( 12.0,  78.0]  (  0.0,  32.0]  (  0.0,  57.0+] #> [109] ( 57.0, 285.0]  (  0.0,   3.0+] (  3.0,  68.0]  (  0.0,  10.0+] #> [113] ( 10.0, 670.0+] (  0.0,   5.0+] (  5.0,  30.0]  (  0.0,  31.0+] #> [117] ( 31.0, 620.0+] (  0.0,   4.0+] (  4.0, 596.0+] (  0.0,  27.0+] #> [121] ( 27.0,  90.0]  (  0.0,   5.0+] (  5.0,  17.0]  (  0.0,   2.0]  #> [125] (  0.0,  46.0+] ( 46.0, 545.0+] (  0.0,  21.0]  (  0.0, 210.0+] #> [129] (210.0, 515.0+] (  0.0,  67.0+] ( 67.0,  96.0]  (  0.0,  26.0+] #> [133] ( 26.0, 482.0+] (  0.0,   6.0+] (  6.0, 445.0+] (  0.0, 428.0+] #> [137] (  0.0,  32.0+] ( 32.0,  80.0]  (  0.0,  37.0+] ( 37.0, 334.0]  #> [141] (  0.0,   5.0]  (  0.0,   8.0+] (  8.0, 397.0+] (  0.0,  60.0+] #> [145] ( 60.0, 110.0]  (  0.0,  31.0+] ( 31.0, 370.0+] (  0.0, 139.0+] #> [149] (139.0, 207.0]  (  0.0, 160.0+] (160.0, 186.0]  (  0.0, 340.0]  #> [153] (  0.0, 310.0+] (310.0, 340.0+] (  0.0,  28.0+] ( 28.0, 265.0+] #> [157] (  0.0,   4.0+] (  4.0, 165.0]  (  0.0,   2.0+] (  2.0,  16.0]  #> [161] (  0.0,  13.0+] ( 13.0, 180.0+] (  0.0,  21.0+] ( 21.0, 131.0+] #> [165] (  0.0,  96.0+] ( 96.0, 109.0+] (  0.0,  21.0]  (  0.0,  38.0+] #> [169] ( 38.0,  39.0+] (  0.0,  31.0+] (  0.0,  11.0+] (  0.0,   6.0]"},{"path":"/reference/Surv2.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a survival object — Surv2","title":"Create a survival object — Surv2","text":"Create survival object timeline style data set.   almost always response variable formula.","code":""},{"path":"/reference/Surv2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a survival object — Surv2","text":"","code":"Surv2(time, event, repeated=FALSE)"},{"path":"/reference/Surv2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a survival object — Surv2","text":"time timeline variable, age, time enrollment,     date, etc. event outcome time.  can 0/1 variable,     TRUE/FALSE, factor.     latter, first level factor corresponds     `event observed time'. repeated level outcome repeats, without     intervening event another type, treated new event?","code":""},{"path":"/reference/Surv2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a survival object — Surv2","text":"object class Surv2.  methods print,  .na subscripting.","code":""},{"path":"/reference/Surv2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a survival object — Surv2","text":"function still experimental. used coxph survfit model,   Surv2 acts trigger internally convert timeline style data   set counting process style data, acted   routine. repeated argument controls repeated instances event   code treated.  TRUE, treated new events, example   might desired repeated infections subject.   FALSE, repeats new   event.  example data set wanted use   diabetes, say, endpoint, repeated medical   visit.","code":""},{"path":[]},{"path":"/reference/Surv2data.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data from timecourse to (time1,time2) style — Surv2data","title":"Convert data from timecourse to (time1,time2) style — Surv2data","text":"multi-state survival functions coxph survfit   allow two forms input data.  routine converts .   function normally called behind scenes Surv2   response.","code":""},{"path":"/reference/Surv2data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data from timecourse to (time1,time2) style — Surv2data","text":"","code":"Surv2data(formula, data, subset, id)"},{"path":"/reference/Surv2data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data from timecourse to (time1,time2) style — Surv2data","text":"formula model formula data data frame subset optional, selects rows data retained id variable identified multiple rows     subject, normally found referenced data set","code":""},{"path":"/reference/Surv2data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data from timecourse to (time1,time2) style — Surv2data","text":"list elements mf updated model frame (fewer rows, unchanged columns) S2.y constructed response variable S2.state current state rows","code":""},{"path":"/reference/Surv2data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert data from timecourse to (time1,time2) style — Surv2data","text":"timeline style data, row uniquely identified (identifier, time) pair.  time date, time entry study, age, etc, (may often one time variable). identifier time missing. remaining covariates represent values observed time point. Often, given covariate observed subset times missing others.  time death, particular, often identifier, time, status indicator known. resulting data set missing covariates replaced last known value, response y Surv(time1, time2, endpoint) object.","code":""},{"path":"/reference/survcheck.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks of a survival data set — survcheck","title":"Checks of a survival data set — survcheck","text":"Perform set consistency checks survival data","code":""},{"path":"/reference/survcheck.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks of a survival data set — survcheck","text":"","code":"survcheck(formula, data, subset, na.action, id, istate, istate0=\"(s0)\",  timefix=TRUE,...)"},{"path":"/reference/survcheck.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks of a survival data set — survcheck","text":"formula model formula Surv object     response data data frame find id,     istate formula variables subset expression indicating subset rows data     used fit.    observations included default. na.action missing-data filter function.  applied model.frame          subset argument used.  Default options()\\$na.action. id identifier labels unique subjects istate optional vector giving current state start     interval istate0 default label initial state subject (    first interval) istate missing timefix process times aeqSurv function   eliminate potential roundoff issues. ... arguments, ignored (give     error someone added weights instance)","code":""},{"path":"/reference/survcheck.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Checks of a survival data set — survcheck","text":"routine examine multi-state data set consistency   data.  basic rules subject risk   somewhere, can two states , make   sensible transitions state state.  reports number   instances following conditions: overlap two observations subject overlap       time, e.g. intervals (0, 100) (90, 120).         y simple (time, status) survival observation       intervals implicitly start 0, case duplicate       identifiers generate overlap. jump hole subject's timeline, one       state end prior interval, new state       start subsequent interval. gap one gaps subject's timeline; presumably       state return left. teleport two adjacent intervals subject,       first interval ending one state subsequent interval       starting another.  instantaneously changed states       experiencing transition. total number occurences present flags   vector. Optional components give location identifiers   flagged observations.","code":""},{"path":"/reference/survcheck.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks of a survival data set — survcheck","text":"list components states vector possible states transitions matrix giving count transitions one     state another statecount table number visits per state, e.g., 18     subjects 2 visits \"infection\" state flags vector giving counts check istate copy istate vector, supplied;     otherwise constructed istate satisfies checks overlap list row number id overlaps (    present overlaps) gaps list row number id gaps (present     gaps) teleport list row number id inconsistent     rows (present none) jumps list row number id jumps (present     jumps","code":""},{"path":"/reference/survcheck.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Checks of a survival data set — survcheck","text":"data sets time-dependent covariates, given subject often intermediate rows status `event time'.  (numeric value 0). instance subject started state 1 time 0, transitioned state 2 time 10, covariate x change 135 156 time 20, final transition state 3 time 30. response Surv(c(0, 10, 20), c(10, 20, 30), c(2,0,3)): status variable records changes state, change time 20. istate variable (1, 2, 2); contains current state, value unchanged status = censored. Thus, intermediate observations istate simply lagged version status, may challenging create. One approach let survcheck work: call istate argument correct first row subject, istate argument , insert returned value ones data frame.","code":""},{"path":"/reference/survcondense.html","id":null,"dir":"Reference","previous_headings":"","what":"Shorten a (time1, time2) survival dataset — survcondense","title":"Shorten a (time1, time2) survival dataset — survcondense","text":"Counting process data sets can sometimes grow unweildy, can   used compact one.","code":""},{"path":"/reference/survcondense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shorten a (time1, time2) survival dataset — survcondense","text":"","code":"survcondense(formula, data, subset, weights, na.action= na.pass, id,               start = \"tstart\", end = \"tstop\", event = \"event\")"},{"path":"/reference/survcondense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shorten a (time1, time2) survival dataset — survcondense","text":"formula formula object, response left ~ operator,      terms right.  response must survival object      returned Surv function. data data.frame interpret variables named      formula id argument     argument. subset optional subset expression apply data set weights optional variable name case weights na.action optional removal missing values id variable name identifies subjects start optional character string, giving name start     time variable result end optional character string, giving name stop     time variable result event optional character string, giving name event     variable result","code":""},{"path":"/reference/survcondense.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Shorten a (time1, time2) survival dataset — survcondense","text":"use survSplit tmerge functions,   counting process data set gain rows data.   Occassionally useful collapse surplus back , e.g.,   interest focused covariates,   debugging.  right hand side formula often   variables, use. row data censored, represents covariates   identifier row , two rows can merged   together using single (time1, time2) interval.  compression can   sometimes large. start, stop end options used   left hand side formula expressions simple   name, e.g. Surv(time1, time2, death | progression)   case event used set outcome variable's name.","code":""},{"path":"/reference/survcondense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shorten a (time1, time2) survival dataset — survcondense","text":"data frame","code":""},{"path":"/reference/survcondense.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Shorten a (time1, time2) survival dataset — survcondense","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/survcondense.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shorten a (time1, time2) survival dataset — survcondense","text":"","code":"dim(aml) #> [1] 23  3 test1 <- survSplit(Surv(time, status) ~ ., data=aml,                     cut=c(10, 20, 30), id=\"newid\") dim(test1) #> [1] 62  5  # remove the added rows test2 <- survcondense(Surv(tstart, time, status) ~ x, test1, id=newid) dim(test2) #> [1] 23  5"},{"path":"/reference/survdiff.html","id":null,"dir":"Reference","previous_headings":"","what":"Test Survival Curve Differences — survdiff","title":"Test Survival Curve Differences — survdiff","text":"Tests difference two survival curves using \\(G^\\rho\\) family tests, single curve known alternative.","code":""},{"path":"/reference/survdiff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test Survival Curve Differences — survdiff","text":"","code":"survdiff(formula, data, subset, na.action, rho=0, timefix=TRUE)"},{"path":"/reference/survdiff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test Survival Curve Differences — survdiff","text":"formula formula expression survival models, form Surv(time, status) ~ predictors.  one-sample test, predictors must consist single offset(sp) term, sp vector giving survival probability subject.  k-sample test, unique combination predictors defines subgroup. strata term may used produce stratified test. cause missing values predictors treated separate group, rather omitted, use strata function na.group=T argument. data optional data frame interpret variables occurring formula. subset expression indicating subset rows data used fit.  can logical vector (replicated length equal number observations), numeric vector indicating observation numbers included (excluded negative), character vector row names included.  observations included default. na.action missing-data filter function.  applied model.frame subset argument used.  Default options()$na.action. rho scalar parameter controls type test. timefix process times aeqSurv function   eliminate potential roundoff issues.","code":""},{"path":"/reference/survdiff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test Survival Curve Differences — survdiff","text":"list components: n number subjects group. obs weighted observed number events group. strata, matrix one column per stratum. exp weighted expected number events group. strata, matrix one column per stratum. chisq chisquare statistic test equality. var variance matrix test. strata optionally, number subjects contained stratum. pvalue p-value corresponding Chisquare statistic","code":""},{"path":"/reference/survdiff.html","id":"description","dir":"Reference","previous_headings":"","what":"Description","title":"Test Survival Curve Differences — survdiff","text":"function implements G-rho family Harrington Fleming (1982), weights death \\(S(t)^\\rho\\), \\(S(t)\\) Kaplan-Meier estimate survival. rho = 0 log-rank Mantel-Haenszel test, rho = 1 equivalent Peto & Peto modification Gehan-Wilcoxon test. Peto Peto show Gehan-Wilcoxon test can badly biased two groups different censoring patterns, proposed alternative.  Prentice Marek later showed actual example issue occurs.  data sets Gehan-Wilcoxon Peto-Peto-Prentice variant hardly differ, however. right hand side formula consists offset term, one sample test done. cause missing values predictors treated separate group, rather omitted, use factor function exclude argument recode righ-hand-side covariate.","code":""},{"path":"/reference/survdiff.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test Survival Curve Differences — survdiff","text":"Harrington, D. P. Fleming, T. R. (1982). class rank test procedures censored survival data.  Biometrika, 553-566. Peto R. Peto Peto, J. (1972) Asymptotically efficient rank invariant   test procedures (discussion), JRSSA, 185-206. Prentice, R. Marek, P. (1979)  qualitative discrepancy   censored data rank tests, Biometics, 861--867.","code":""},{"path":"/reference/survdiff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test Survival Curve Differences — survdiff","text":"","code":"## Two-sample test survdiff(Surv(futime, fustat) ~ rx,data=ovarian) #> Call: #> survdiff(formula = Surv(futime, fustat) ~ rx, data = ovarian) #>  #>       N Observed Expected (O-E)^2/E (O-E)^2/V #> rx=1 13        7     5.23     0.596      1.06 #> rx=2 13        5     6.77     0.461      1.06 #>  #>  Chisq= 1.1  on 1 degrees of freedom, p= 0.3   ## Stratified 7-sample test  survdiff(Surv(time, status) ~ pat.karno + strata(inst), data=lung) #> Call: #> survdiff(formula = Surv(time, status) ~ pat.karno + strata(inst),  #>     data = lung) #>  #> n=224, 4 observations deleted due to missingness. #>  #>                N Observed Expected (O-E)^2/E (O-E)^2/V #> pat.karno=30   2        1    0.692   0.13720   0.15752 #> pat.karno=40   2        1    1.099   0.00889   0.00973 #> pat.karno=50   4        4    1.166   6.88314   7.45359 #> pat.karno=60  30       27   16.298   7.02790   9.57333 #> pat.karno=70  41       31   26.358   0.81742   1.14774 #> pat.karno=80  50       38   41.938   0.36978   0.60032 #> pat.karno=90  60       38   47.242   1.80800   3.23078 #> pat.karno=100 35       21   26.207   1.03451   1.44067 #>  #>  Chisq= 21.4  on 7 degrees of freedom, p= 0.003   ## Expected survival for heart transplant patients based on ## US mortality tables expect <- survexp(futime ~ 1, data=jasa, cohort=FALSE,                   rmap= list(age=(accept.dt - birth.dt), sex=1, year=accept.dt),                   ratetable=survexp.us) ## actual survival is much worse (no surprise) survdiff(Surv(jasa$futime, jasa$fustat) ~ offset(expect)) #> Call: #> survdiff(formula = Surv(jasa$futime, jasa$fustat) ~ offset(expect)) #>  #> Observed Expected        Z        p  #>   75.000    0.644  -92.681    0.000   # The free light chain data set is close to the population. e2 <- survexp(futime ~ 1, data=flchain, cohort=FALSE,               rmap= list(age= age*365.25, sex=sex,                           year=as.Date(paste0(sample.yr, \"-07-01\"))),               ratetable= survexp.mn) survdiff(Surv(futime, death) ~ offset(e2), flchain) #> Call: #> survdiff(formula = Surv(futime, death) ~ offset(e2), data = flchain) #>  #>  Observed  Expected         Z         p  #> 2169.0000 2073.9133   -2.0880    0.0368"},{"path":"/reference/survexp.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Expected Survival — survexp.fit","title":"Compute Expected Survival — survexp.fit","text":"Compute expected survival times.","code":""},{"path":"/reference/survexp.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Expected Survival — survexp.fit","text":"","code":"survexp.fit(group, x, y, times, death, ratetable)"},{"path":"/reference/survexp.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Expected Survival — survexp.fit","text":"group multiple survival curves identifies group,  otherwise constant.  Must integer. x matrix whose columns match dimensions ratetable,  correct order. y follow time subject. times vector times result computed. death logical value, TRUE conditional survival computed,  FALSE cohort survival computed. See survexp details. ratetable rate table, survexp.uswhite.","code":""},{"path":"/reference/survexp.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Expected Survival — survexp.fit","text":"list containing number subjects expected survival(s)  time point.  multiple groups,  matrices one column per group.","code":""},{"path":"/reference/survexp.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Expected Survival — survexp.fit","text":"conditional survival y must time last follow-death  subject.  cohort survival must potential censoring time  subject, ignoring death. exact estimate times superset y,  subject risk risk entire sub-interval time.  large data set, however, can use inordinate amount  storage /compute time.  times spacing coarse  , actuarial approximation used , however, extremely  accurate long returned values > .99. subgroup size 1 times > y,  conditional method reduces exp(-h)  h expected cumulative hazard subject / observation time.  used compute individual expected survival.","code":""},{"path":"/reference/survexp.fit.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Compute Expected Survival — survexp.fit","text":"users call higher level routine survexp.  Consequently, function error checks input arguments.","code":""},{"path":[]},{"path":"/reference/survexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Expected Survival — survexp","title":"Compute Expected Survival — survexp","text":"Returns either expected survival cohort subjects,  individual expected survival subject.","code":""},{"path":"/reference/survexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Expected Survival — survexp","text":"","code":"survexp(formula, data, weights, subset, na.action, rmap, times,         method=c(\"ederer\", \"hakulinen\", \"conditional\", \"individual.h\",                  \"individual.s\"),         cohort=TRUE, conditional=FALSE,         ratetable=survival::survexp.us, scale=1,         se.fit, model=FALSE, x=FALSE, y=FALSE)"},{"path":"/reference/survexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Expected Survival — survexp","text":"formula formula object.  response variable vector follow-times  optional.  predictors consist optional grouping variables  separated + operator (survfit), often ~1, .e., expected survival entire group. data data frame interpret variables named  formula, subset weights arguments. weights case weights.  useful conditional survival known   population desired, e.g., data set contain unique   age/sex combinations weights proportion . subset expression indicating subset rows data used fit. na.action function filter missing data. applied model frame   subset applied.  Default options()$na.action. rmap optional list maps data set names ratetable names.  See  details section . times vector follow-times resulting survival curve   evaluated.  absent, result reported unique   value vector times supplied response value formula. method computational method creating survival curves.   individual option create curve, rather   retrieves predicted survival individual.s cumulative   hazard individual.h subject.   default use method='ederer' formula   response,  method='hakulinen' otherwise. cohort logical value.  argument superseded   method argument.  maintain backwards compatability,   present FALSE, implies method='individual.s'. conditional logical value.  argument superseded   method argument.  maintain backwards compatability,   present TRUE implies method='conditional'. ratetable table event rates,   survexp.mn, fitted Cox model.   Note survival:: prefix default argument present   avoid (rare) case user expects default table   just happens object named \"survexp.us\"   directory. scale numeric value scale results.  ratetable units/day,  scale = 365.25 causes output reported years. se.fit compute standard error predicted survival.   argument currently ignored.  Standard errors defined concept population rate tables (treated coming complete census), Cox models calculation hard.  Despite good intentions standard errors latter case coded validated. model,x,y flags control returned.  true, model frame, model matrix, /vector response times returned components final result, names flag arguments.","code":""},{"path":"/reference/survexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Expected Survival — survexp","text":"cohort=TRUE object class survexp,  otherwise vector per-subject expected survival values.  former contains number subjects risk  expected survival cohort requested time. cohort survival hypothetical survival cohort subjects enrolled population large, matching data set factors found rate table.","code":""},{"path":"/reference/survexp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Expected Survival — survexp","text":"Individual expected survival usually used models testing,  `correct' age sex composition group subjects.  instance, assume birth date, entry date study,  sex actual survival time known group subjects.  survexp.us population tables contain expected death rates  based calendar year, sex age.  gives subject total hazard experienced observed  death time last follow-time (variable fu.time)  probability can used rescaled time value models: first model, test intercept=0 one sample log-rank  test whether observed group subjects equivalent survival  baseline population.  second model tests effect variable  x adjustment age sex. ratetable used may different variable names user's data set, dealt rmap argument.   rate table calculation survexp.us, call summary{survexp.us} reveals expects variables  age = age days, sex, year = date study entry, create rmap line.  sex variable mapped, therefore function assumes exists mydata correct format.  (Note: factors sex, program match unique abbreviation, ignoring case.) Cohort survival used produce overall survival curve.   added Kaplan-Meier plot study group visual comparison  subjects population large.  three common  methods computing cohort survival.  \"exact method\" Ederer cohort censored, case  response variable required formula. Hakulinen recommends censoring  cohort anticipated censoring time patient, Verheul  recommends censoring cohort actual observation time  patient.  last conditional method.  obtained using respective time values  follow-time response formula.","code":"haz <- survexp(fu.time ~ 1, data=mydata,                        rmap = list(year=entry.dt, age=(birth.dt-entry.dt)),                       method='individual.h')) glm(status ~ 1 + offset(log(haz)), family=poisson)  glm(status ~ x + offset(log(haz)), family=poisson)"},{"path":"/reference/survexp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Expected Survival — survexp","text":"Berry, G. (1983). analysis mortality subject-years method.  Biometrics, 39:173-84. Ederer, F., Axtell, L. Cutler, S. (1961).  relative survival rate: statistical methodology.  Natl Cancer Inst Monogr, 6:101-21. Hakulinen, T. (1982).  Cancer survival corrected heterogeneity patient withdrawal.  Biometrics, 38:933-942. Therneau, T. Grambsch, P. (2000). Modeling survival data: Extending Cox model. Springer.  Chapter 10. Verheul, H., Dekker, E., Bossuyt, P., Moulijn, . Dunning, . (1993).  Background mortality clinical survival studies.  Lancet, 341: 872-875.","code":""},{"path":[]},{"path":"/reference/survexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Expected Survival — survexp","text":"","code":"#  # Stanford heart transplant data #  We don't have sex in the data set, but know it to be nearly all males. # Estimate of conditional survival   fit1 <- survexp(futime ~ 1, rmap=list(sex=\"male\", year=accept.dt,              age=(accept.dt-birth.dt)), method='conditional', data=jasa) summary(fit1, times=1:10*182.5, scale=365) #expected survival by 1/2 years #> Call: survexp(formula = futime ~ 1, data = jasa, rmap = list(sex = \"male\",  #>     year = accept.dt, age = (accept.dt - birth.dt)), method = \"conditional\") #>  #>  time n.risk survival #>   0.5     41    0.996 #>   1.0     28    0.993 #>   1.5     21    0.989 #>   2.0     16    0.986 #>   2.5     13    0.983 #>   3.0      8    0.980 #>   3.5      7    0.977 #>   4.0      3    0.972 #>   4.5      1    0.969  # Estimate of expected  survival stratified by prior surgery  survexp(~ surgery, rmap= list(sex=\"male\", year=accept.dt,     age=(accept.dt-birth.dt)), method='ederer', data=jasa,         times=1:10 * 182.5)  #> Call: #> survexp(formula = ~surgery, data = jasa, rmap = list(sex = \"male\",  #>     year = accept.dt, age = (accept.dt - birth.dt)), times = 1:10 *  #>     182.5, method = \"ederer\") #>  #>   age ranges from 8.8 to 64.4 years #>   male: 103  female: 0  #>   date of entry from 1967-09-13 to 1974-03-22  #>  #>  time nrisk1 nrisk2 surgery=0 surgery=1 #>   182     87     16     0.996     0.996 #>   365     87     16     0.991     0.993 #>   548     87     16     0.987     0.989 #>   730     87     16     0.982     0.985 #>   912     87     16     0.978     0.981 #>  1095     87     16     0.973     0.977 #>  1278     87     16     0.968     0.973 #>  1460     87     16     0.963     0.969 #>  1642     87     16     0.958     0.964 #>  1825     87     16     0.952     0.960  ## Compare the survival curves for the Mayo PBC data to Cox model fit ##  pfit <-coxph(Surv(time,status>0) ~ trt + log(bili) + log(protime) + age +                 platelet, data=pbc) plot(survfit(Surv(time, status>0) ~ trt, data=pbc), mark.time=FALSE) lines(survexp( ~ trt, ratetable=pfit, data=pbc), col='purple')"},{"path":"/reference/survexp.object.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected Survival Curve Object — survexp.object","title":"Expected Survival Curve Object — survexp.object","text":"class objects returned survexp class functions represent fitted survival curve. Objects class methods summary, inherit print, plot, points lines methods survfit.","code":""},{"path":"/reference/survexp.object.html","id":"structure","dir":"Reference","previous_headings":"","what":"Structure","title":"Expected Survival Curve Object — survexp.object","text":"following components must included legitimate  survfit  object.","code":""},{"path":"/reference/survexp.object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected Survival Curve Object — survexp.object","text":"surv estimate survival time t+0.  may vector matrix. n.risk number subjects contribute time. time time points curve step. std.err standard error cumulative hazard -log(survival). strata multiple curves, component gives number elements  time etc. vectors corresponding first curve, second curve,  .  names elements labels curves. method estimation method used.  One \"Ederer\", \"Hakulinen\",   \"conditional\". na.action returned value na.action function, .  used  printout curve, e.g., number observations deleted due  missing values. call image call produced object.","code":""},{"path":"/reference/survexp.object.html","id":"subscripts","dir":"Reference","previous_headings":"","what":"Subscripts","title":"Expected Survival Curve Object — survexp.object","text":"Survexp objects contain multiple survival curves can subscripted.  often used plot subset curves.","code":""},{"path":"/reference/survexp.object.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expected Survival Curve Object — survexp.object","text":"expected survival subject data set matched hypothetical person parent population, matched characteristics parent population. number risk printed number hypothetical subject still part calculation. particular, Ederer method hypotheticals retained time, n.risk constant.","code":""},{"path":[]},{"path":"/reference/survexp.us.html","id":null,"dir":"Reference","previous_headings":"","what":"Census Data Sets for the Expected Survival and Person Years Functions — ratetables","title":"Census Data Sets for the Expected Survival and Person Years Functions — ratetables","text":"Census data sets expected survival person years functions.","code":""},{"path":"/reference/survexp.us.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Census Data Sets for the Expected Survival and Person Years Functions — ratetables","text":"","code":"data(survexp, package=\"survival\")"},{"path":"/reference/survexp.us.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Census Data Sets for the Expected Survival and Person Years Functions — ratetables","text":"survexp.us total United States population, age sex, 1940 2012. survexp.usr United States population, age, sex race, 1940 2014.       Race white black.  1960 1970 black       population values reported separately, nonwhite       values used.  (years, reported tables       differed wrt reporting non-white /black.) survexp.mn total Minnesota population, age sex, 1970 2013. tables contains daily hazard rate matched   subject population, defined \\(-\\log(1-q)/365.25\\)   \\(q\\) 1 year probability death reported original   tables US Census.  age 25 1970, instance,   \\(p = 1-q\\)   probability subject becomes 25 years age 1970   achieve /26th birthday.  tables recast terms   hazard per day computational convenience. table stored array, additional attributes,   can subset manipulated standard R arrays.   See help page ratetable details. numeric dimensions rate table must units.    survexp.us rate table contains daily hazard rates, age    cutpoints days, calendar year cutpoints Date.","code":""},{"path":[]},{"path":"/reference/survexp.us.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Census Data Sets for the Expected Survival and Person Years Functions — ratetables","text":"","code":"survexp.uswhite <- survexp.usr[,,\"white\",]"},{"path":"/reference/survfit.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a Survival Curve from a Cox model — survfit.coxph","title":"Compute a Survival Curve from a Cox model — survfit.coxph","text":"Computes predicted survivor function Cox proportional  hazards model.","code":""},{"path":"/reference/survfit.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a Survival Curve from a Cox model — survfit.coxph","text":"","code":"# S3 method for coxph survfit(formula, newdata,          se.fit=TRUE, conf.int=.95, individual=FALSE, stype=2, ctype,         conf.type=c(\"log\",\"log-log\",\"plain\",\"none\", \"logit\", \"arcsin\"),         censor=TRUE, start.time, id, influence=FALSE,         na.action=na.pass, type, ...) # S3 method for coxphms survfit(formula, newdata,          se.fit=FALSE, conf.int=.95, individual=FALSE, stype=2, ctype,         conf.type=c(\"log\",\"log-log\",\"plain\",\"none\", \"logit\", \"arcsin\"),         censor=TRUE, start.time, id, influence=FALSE,         na.action=na.pass, type, p0=NULL, ...)"},{"path":"/reference/survfit.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a Survival Curve from a Cox model — survfit.coxph","text":"formula coxph object. newdata data frame variable names appear      coxph formula. One curve produced per row.     curve(s) produced representative cohort whose      covariates correspond values newdata. se.fit logical value indicating whether standard errors      computed.  Default TRUE standard models, FALSE     multi-state (code yet present case.) conf.int level two-sided confidence interval survival curve(s).      Default 0.95. individual deprecated argument, replaced general     id stype computation survival curve, 1=direct, 2=     exponenial cumulative hazard. ctype whether cumulative hazard computation     correction ties, 1=, 2=yes. conf.type One \"none\", \"plain\", \"log\" (default),     \"log-log\" \"logit\".      enough string uniquely identify necessary.     first option causes confidence intervals     generated.  second causes standard intervals     curve +- k *se(curve), k determined     conf.int.  log option calculates intervals based     cumulative hazard log(survival). log-log option uses     log hazard log(-log(survival)), logit     log(survival/(1-survival)). censor FALSE time points events (    censoring) included result. id optional variable name subject identifiers.      present, search newdata data frame.     group rows newdata subject id represents     covariate path time single subject, result     contain one curve per subject.  coxph fit     strata must also specified newdata.     newid present,     individual row newdata presumed represent distinct     subject. start.time optional starting time, single numeric value.     present returned curve contains survival     start.time conditional surviving start.time. influence option return influence values na.action na.action used newdata argument type older argument encompassed stype     ctype, now deprecated p0 optional, vector probabilities.  returned curve     cohort mixture starting states.      often single state chosen ... future methods","code":""},{"path":"/reference/survfit.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a Survival Curve from a Cox model — survfit.coxph","text":"object class \"survfit\".   See survfit.object  details. Methods defined survfit objects   print, plot,  lines, points.","code":""},{"path":"/reference/survfit.coxph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute a Survival Curve from a Cox model — survfit.coxph","text":"routine produces Pr(state) curves based coxph   model fit. single state models produces single curve   S(t) = Pr(remain initial state time t), known survival   curve; multi-state models matrix giving probabilities states.   stype argument states type estimate, defaults   exponential cumulative hazard, better known Breslow   estimate.  multi-state Cox model involves exponential     matrix.    argument stype=1 uses non-exponential `direct'   estimate.  single endpoint coxph model code evaluates   Kalbfleich-Prentice estimate, multi-state model uses   analog Aalen-Johansen estimator.  latter approach     default mstate package. ctype option affects estimated cumulative hazard,   stype=2 estimated P(state) curves well.    present chosen concordant    ties option coxph call. (multistate   coxphms objects ctype=1 currently implemented.)   Likewise   choice model based robust variance estimate   curve mirror choice made coxph call,   clustering also inherited parent model. newdata argument missing, curve produced   single \"pseudo\" subject   covariate values equal means component fit.   resulting curve(s) almost never make sense,    default remains due unwarranted attachment option shown   users packages.  Two particularly egregious examples   factor variables interactions.  Suppose one studying   interspecies transmission virus, data set factor   variable levels (\"pig\", \"chicken\") equal numbers   observations .  ``mean'' covariate level 0.5 --   flying pig?  interactions assume data sex coded 0/1,   ages ranging 50 80, model age*sex.  ``mean''   value age:sex interaction term 30, value   occur data.   Users strongly advised use newdata argument.   reasons predictions multistate coxph model require   newdata argument. coxph model contained offset term, data set   newdata argument also contain variable. original model contains time-dependent covariates, path covariate time needs specified order obtain predicted curve. requires newdata contain multiple lines hypothetical subject gives covariate values, time interval, strata line (subject can change strata), along id variable  demarks rows belong subject. time interval must (start, stop, status) variables original model: although status variable used thus can set dummy value 0 1, necessary response recognized Surv object. Last, although predictions time-dependent covariate path can useful, easy create prediction senseless.  Users encouraged seek text discusses issue detail. model contains strata time-dependent covariates user routine choice. newdata argument contain strata variables returned object matrix survival curves one row strata model one column row newdata. (historical behavior routine.) newdata contain strata variables, result contain one curve per row newdata, based indicated stratum original model.  rare case model strata covariate interactions strata variable must included newdata, routine allow omitted (predictions become confusing). (Note model Surv(time, status) ~ age*strata(sex) expands internally strata(sex) + age:sex; sex variable needed second term model.) See survfit details counts (number events, number risk, etc.)","code":""},{"path":"/reference/survfit.coxph.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Compute a Survival Curve from a Cox model — survfit.coxph","text":"following pair lines used inside another function model=TRUE argument must added coxph call: fit <- coxph(...); survfit(fit). consequence non-standard evaluation process used model.frame function formula involved. Let \\(\\log[S(t; z)]\\) log survival curve fixed covariate vector \\(z\\), \\(\\log[S(t; x)]= e^{(x-z)\\beta}\\log[S(t; z)]\\) log curve new covariate vector \\(x\\).   unfortunate tendency refer reference curve \\(z=0\\) `' baseline hazard.  However, \\(z\\) can used reference point, importantly, \\(x-z\\) large compuation can suffer severe roundoff error.  always safest provide desired \\(x\\) values directly via newdata.","code":""},{"path":"/reference/survfit.coxph.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute a Survival Curve from a Cox model — survfit.coxph","text":"Fleming, T. H. Harrington, D. P. (1984).  Nonparametric estimation  survival distribution censored data.  Comm. Statistics   13, 2469-86. Kalbfleisch, J. D. Prentice, R. L. (1980). Statistical Analysis Failure Time Data. New York:Wiley. Link, C. L. (1984). Confidence intervals survival  function using Cox's proportional hazards model   covariates.  Biometrics   40, 601-610. Therneau T Grambsch P (2000), Modeling Survival Data: Extending Cox Model, Springer-Verlag. Tsiatis, . (1981). large sample study estimate  integrated hazard function Cox's regression  model survival data. Annals Statistics   9, 93-108.","code":""},{"path":[]},{"path":"/reference/survfit.formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a Survival Curve for Censored Data — survfit.formula","title":"Compute a Survival Curve for Censored Data — survfit.formula","text":"Computes estimate survival curve censored data using   Aalen-Johansen estimator.  ordinary (single event) survival   reduces Kaplan-Meier estimate.","code":""},{"path":"/reference/survfit.formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a Survival Curve for Censored Data — survfit.formula","text":"","code":"# S3 method for formula survfit(formula, data, weights, subset, na.action,           stype=1, ctype=1, id, cluster, robust, istate, timefix=TRUE,         etype, model=FALSE, error, ...)"},{"path":"/reference/survfit.formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a Survival Curve for Censored Data — survfit.formula","text":"formula formula object, must      Surv object       response left ~ operator , desired, terms       separated + operators right.      One terms may strata object.     single survival curve right hand side ~ 1. data data frame interpret variables named formula,      subset weights arguments. weights weights must nonnegative strongly recommended       strictly positive, since zero weights ambiguous, compared      use subset argument. subset expression saying subset rows data      used fit. na.action missing-data filter function, applied model frame,      subset argument used.      Default options()$na.action. stype method used estimation survival curve:     1 = direct,  2 = exp(cumulative hazard). ctype method used estimation cumulative     hazard: 1 = Nelson-Aalen formula, 2 = Fleming-Harrington correction     tied events. id identifies individual subjects, given person can multiple     lines data. cluster used group observations infinitesimal     jackknife variance estimate, defaults value id. robust logical, function compute robust variance.     multi-state survival curves true default.     single state data see details, . istate multi-state models, identifies initial state     subject observation timefix process times aeqSurv function   eliminate potential roundoff issues. etype variable giving type event.  superseded     multi-state Surv objects deprecated; see example . model include copy model frame output error argument longer used ... following additional arguments passed internal functions     called survfit. se.fit logical value, default TRUE.  FALSE \tstandard error computations omitted. conf.type One \"none\", \"plain\", \"log\" (default), \t\"log-log\", \"logit\" \"arcsin\".  \tenough string uniquely identify necessary. \tfirst option causes confidence intervals \tgenerated.  second causes standard intervals \tcurve +- k *se(curve), k determined \tconf.int.  log option calculates intervals based \tcumulative hazard log(survival). log-log option bases \tintervals log hazard log(-log(survival)), \tlogit option log(survival/(1-survival)) \tarcsin arcsin(survival). conf.lower character string specify modified lower limits curve,  \tupper limit remains unchanged.   \tPossible values \"usual\" (unmodified),  \t\"peto\",  \t\"modified\".  modified lower limit  \tbased \"effective n\" argument.  confidence  \tbands agree usual calculation death time, unlike  \tusual bands confidence interval becomes wider censored  \tobservation.  extra width obtained multiplying usual  \tvariance factor m/n, n number currently risk  \tm number risk last death time.  (bands thus agree  \tun-modified bands death time.)  \tespecially useful survival curves long flat tail. Peto lower limit based \"effective n\" argument  \tmodified limit, also replaces usual Greenwood variance term  \tsimple approximation.  known conservative. start.time numeric value specifying time start calculating survival \tinformation. \tresulting curve survival conditional surviving \tstart.time. conf.int level two-sided confidence interval survival curve(s).  \tDefault 0.95. se.fit logical value indicating whether standard errors  \tcomputed.  Default TRUE. influence logical value indicating whether return \tinfinitesimal jackknife (influence) values subject. \tcontain values derivative value \trespect case weights subject : \t\\(\\partial p/\\partial w_i\\), \tevaluated vector weights.  resulting object \tcontain influence.surv influence.chaz \tcomponents.  Alternatively, options influence=1 \tinfluence=2 return values \tsurvival hazard curves, respectively. p0 applies multi-state curves.  \toptional vector giving initial probability across \tstates. missing, p0 estimated using \tfrequency starting states observations risk \tstart.time, specified, \ttime first event. type older argument combined stype \tctype, now deprecated.  Legal values \"kaplan-meier\" \tequivalent stype=1, ctype=1, \"fleming-harrington\" \tequivalent stype=2, ctype=1, \"fh2\" \tequivalent stype=2, ctype=2.","code":""},{"path":"/reference/survfit.formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a Survival Curve for Censored Data — survfit.formula","text":"object class \"survfit\".   See survfit.object  details. Methods defined survfit objects   print, plot,  lines, points.","code":""},{"path":"/reference/survfit.formula.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute a Survival Curve for Censored Data — survfit.formula","text":"data argument, variables formula,   codeweights, subset, id, cluster   istate arguments searched data set. routine returns estimated probability state   estimated cumulative hazard estimate.   cumulative hazard estimate Nelson-Aalen (NA) estimate   Fleming-Harrington (FH) estimate, latter includes correction   tied event times.  estimated probability state can estimated   either using exponential cumulative hazard, direct   estimate using Aalen-Johansen approach.   single state data AJ estimate reduces Kaplan-Meier   probability state survival curve;    competing risks data AJ reduces cumulative incidence (CI)   estimator.   backward compatability type argument can used instead. data set includes left censored interval censored data (),   EM approach Turnbull used compute overall curve.   Currently algorithm slow, survival curve   produced, support robust variance. Robust variance:   robust TRUE, multi-state   curves, standard   errors results based infinitesimal jackknife (IJ)   estimate, otherwise standard model based estimate used.   single state curves, default robust TRUE    one : cluster argument,   non-integer weights, id statement   least one id values multiple events, FALSE otherwise.   default represents best guess one   often desire robust variance.   non-integer case weights (time1, time2) survival   data routine impasse: robust variance likely called   , requires either id cluster information   done correctly; default robust=FALSE. One unanticipated side effect defaulting robust variance   non integer case weights fit using   interval censored data, iterates underlying KM using   updated weight vector, now returns robust variance default.   Based Sun (2001) may preferred, naive estimate   ignores estimation weights.  prior behavior can   obtained robust= FALSE. IJ estimate, leverage values can returned   arrays dimensions: number subjects, number unique times,   multi-state model, number unique states.   forwarned arrays can huge.    cluster argument first dimension number   clusters variance grouped IJ estimate; can   important tool reducing size.   numeric value influence argument allows finer   control: 0= return neither (FALSE), 1= return influence   array probability state, 2= return influence array   cumulative hazard, 3= return (TRUE).","code":""},{"path":"/reference/survfit.formula.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute a Survival Curve for Censored Data — survfit.formula","text":"Dorey, F. J. Korn, E. L. (1987).  Effective sample sizes confidence  intervals survival probabilities.  Statistics Medicine  6, 679-87. Fleming, T. H. Harrington, D. P. (1984).  Nonparametric estimation  survival distribution censored data.  Comm. Statistics   13, 2469-86. Kalbfleisch, J. D. Prentice, R. L. (1980). Statistical Analysis Failure Time Data. New York:Wiley. Kyle, R. . (1997). Moncolonal gammopathy undetermined significance solitary       plasmacytoma. Implications progression overt multiple myeloma}, Hematology/Oncology Clinics N. Amer. 11, 71-87. Link, C. L. (1984). Confidence intervals survival  function using Cox's proportional hazards model   covariates.  Biometrics   40, 601-610. Sun, J. (2001). Variance estimation survival function interval-censored data. Stat Med 20, 1949-1957. Turnbull, B. W. (1974).  Nonparametric estimation survivorship function doubly censored data. J Stat Assoc, 69, 169-173.","code":""},{"path":[]},{"path":"/reference/survfit.formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a Survival Curve for Censored Data — survfit.formula","text":"","code":"#fit a Kaplan-Meier and plot it  fit <- survfit(Surv(time, status) ~ x, data = aml)  plot(fit, lty = 2:3)  legend(100, .8, c(\"Maintained\", \"Nonmaintained\"), lty = 2:3)    #fit a Cox proportional hazards model and plot the   #predicted survival for a 60 year old  fit <- coxph(Surv(futime, fustat) ~ age, data = ovarian)  plot(survfit(fit, newdata=data.frame(age=60)),      xscale=365.25, xlab = \"Years\", ylab=\"Survival\")    # Here is the data set from Turnbull #  There are no interval censored subjects, only left-censored (status=3), #  right-censored (status 0) and observed events (status 1) # #                             Time #                         1    2   3   4 # Type of observation #           death        12    6   2   3 #          losses         3    2   0   3 #      late entry         2    4   2   5 # tdata <- data.frame(time  =c(1,1,1,2,2,2,3,3,3,4,4,4),                     status=rep(c(1,0,2),4),                     n     =c(12,3,2,6,2,4,2,0,2,3,3,5)) fit  <- survfit(Surv(time, time, status, type='interval') ~1,                data=tdata, weight=n)  # # Three curves for patients with monoclonal gammopathy. #  1. KM of time to PCM, ignoring death (statistically incorrect) #  2. Competing risk curves (also known as \"cumulative incidence\") #  3. Multi-state, showing Pr(in each state, at time t) # fitKM <- survfit(Surv(stop, event=='pcm') ~1, data=mgus1,                     subset=(start==0)) fitCR <- survfit(Surv(stop, event) ~1,                     data=mgus1, subset=(start==0)) fitMS <- survfit(Surv(start, stop, event) ~ 1, id=id, data=mgus1) if (FALSE) { # CR curves show the competing risks plot(fitCR, xscale=365.25, xmax=7300, mark.time=FALSE,             col=2:3, xlab=\"Years post diagnosis of MGUS\",             ylab=\"P(state)\") lines(fitKM, fun='event', xmax=7300, mark.time=FALSE,             conf.int=FALSE) text(3652, .4, \"Competing risk: death\", col=3) text(5840, .15,\"Competing risk: progression\", col=2) text(5480, .30,\"KM:prog\") }"},{"path":"/reference/survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Create survival curves — survfit","title":"Create survival curves — survfit","text":"function creates survival curves either formula (e.g.  Kaplan-Meier), previously fitted Cox model, previously fitted accelerated failure time model.","code":""},{"path":"/reference/survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create survival curves — survfit","text":"","code":"survfit(formula, ...)"},{"path":"/reference/survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create survival curves — survfit","text":"formula either formula previously fitted model ... arguments specific method","code":""},{"path":"/reference/survfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create survival curves — survfit","text":"survival curve based tabulation number risk   number events unique death time.  time floating   point number definition \"unique\" subject interpretation.   code uses factor() define set.   details see documentation appropriate method, .e.,   ?survfit.formula ?survfit.coxph. survfit object may contain single curve, set curves (vector),   matrix curves, even 3 way array: dim(fit) reveal   dimensions.   Predicted curves coxph model one row   stratum Cox model fit one column specified   covariate set.   Curves multi-state model one row stratum   column state, strata correspond predictors   right hand side equation.  default printing plotting   order curves column, matrices.","code":""},{"path":"/reference/survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create survival curves — survfit","text":"object class survfit containing one survival curves.","code":""},{"path":"/reference/survfit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create survival curves — survfit","text":"Terry Therneau","code":""},{"path":"/reference/survfit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Create survival curves — survfit","text":"Older releases code also allowed specification  single curve omit right hand formula, .e., survfit(Surv(time, status)), case formula argument actually formula. Handling case required non-standard fairly fragile  manipulations, case longer supported.","code":""},{"path":[]},{"path":"/reference/survfit.matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","title":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","text":"allows one create Aalen-Johansen estimate P, matrix   one column per state one row per time, starting   individual hazard estimates.  row P sum 1.   Note routine superseded use multi-state   Cox models, eventually removed.","code":""},{"path":"/reference/survfit.matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","text":"","code":"# S3 method for matrix survfit(formula, p0, method = c(\"discrete\", \"matexp\"),         start.time, ...)"},{"path":"/reference/survfit.matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","text":"formula matrix lists, element either NULL     survival curve object. p0 initial state vector.  names vector used   names states output object.    multiple curves p0 can matrix one row per curve. method use product discrete hazards, product matrix exponentials.     See details . start.time optional; start calculations given starting     point ... arguments used survfit methods","code":""},{"path":"/reference/survfit.matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","text":"input matrix contain set predicted curves   possible transition, NULL positions.    predictions obtained relevant Cox model.    approach multistate curves easy use   caveats.     First, input curves must consistent.   routine checks best can, can easy fooled.   instance, one fit two Cox models, obtain   predictions males females one, treatment B   , routine create two curves   meaningful.   second issue standard errors produced. names resulting states taken names   vector initial state probabilities.  missing,   dimnames input matrix used, lacking labels   '1', '2', etc. used. usual Aalen-Johansen estimator multiplier event   time matrix hazards H (also written + dA).   using predicted survival curves Cox model, however,   possible get predicted hazards greater 1,   leads probabilities less 0.   method argument supplied input   curves derived Cox model routine instead uses   approximation expm(H-) multiplier, always gives valid   probabilities.   (also standard approach ordinary   survival curves Cox model.)","code":""},{"path":"/reference/survfit.matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","text":"survfitms object","code":""},{"path":"/reference/survfit.matrix.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","text":"Terry Therneau","code":""},{"path":"/reference/survfit.matrix.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","text":"R syntax creating matrix lists fussy.","code":""},{"path":[]},{"path":"/reference/survfit.matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Aalen-Johansen estimates of multi-state survival from\r\n  a matrix of hazards. — survfit.matrix","text":"","code":"etime <- with(mgus2, ifelse(pstat==0, futime, ptime)) event <- with(mgus2, ifelse(pstat==0, 2*death, 1)) event <- factor(event, 0:2, labels=c(\"censor\", \"pcm\", \"death\"))  cfit1 <- coxph(Surv(etime, event==\"pcm\") ~ age + sex, mgus2) cfit2 <- coxph(Surv(etime, event==\"death\") ~ age + sex, mgus2)  # predicted competing risk curves for a 72 year old with mspike of 1.2 # (median values), male and female. # The survfit call is a bit faster without standard errors. newdata <- expand.grid(sex=c(\"F\", \"M\"), age=72, mspike=1.2)  AJmat <- matrix(list(), 3,3) AJmat[1,2] <- list(survfit(cfit1, newdata, std.err=FALSE)) AJmat[1,3] <- list(survfit(cfit2, newdata, std.err=FALSE)) csurv  <- survfit(AJmat, p0 =c(entry=1, PCM=0, death=0))"},{"path":"/reference/survfit.object.html","id":null,"dir":"Reference","previous_headings":"","what":"Survival Curve Object — survfit.object","title":"Survival Curve Object — survfit.object","text":"class objects returned survfit class functions represent fitted survival curve. multi-state model object class c('survfitms', 'survfit'). Objects class methods functions print, summary, plot, points lines. print.survfit method computation typical print method documented separate page.","code":""},{"path":"/reference/survfit.object.html","id":"structure","dir":"Reference","previous_headings":"","what":"Structure","title":"Survival Curve Object — survfit.object","text":"following components must included legitimate  survfit survfitms object.","code":""},{"path":"/reference/survfit.object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Survival Curve Object — survfit.object","text":"n total number subjects curve. time time points curve step. n.risk number subjects risk t. n.event number events occur time t. n.enter counting process data , id     argument, number subjects enter risk set     current interval.  event/censoring times 1, 3, 5     instance, someone enters time 1 counted (1, 3]     interval, .e., appears row time 3. n.censor counting process data ,     number subjects exit risk set,     without event,  time t.      (right censored data, number can computed successive     values number risk). surv estimate survival time t+0.      may vector matrix. latter occurs set     survival curves created single Cox model, case     one column covariate set. pstate multi-state survival pstate component     instead surv.     matrix containing estimated probability     state time, one column per state. std.err survival curve contains standard error cumulative     hazard -log(survival), multi-state curve contains     standard error prev.  difference reflection     fact natural calculation case. cumhaz optional.  Contains cumulative     hazard possible transition. strata multiple curves, component gives number     elements time  vector corresponding first curve,     second curve, .     names elements labels curves. upper optional     upper confidence limit survival curve pstate lower options      lower confidence limit survival curve pstate start.time optional, starting time curve     0 p0, sp0 multistate object, distribution starting     states.  curve strata dimension, matrix     one row per stratum.  sp0 element standard error     p0, p0 estimated. newdata survival curves fitted model, contains     covariate values curves n.total number observations available     counting process data, time      start.time argument used,      may used creating curve, case value     larger n .     print plot routines package use     value, information . conf.type approximation used compute confidence limits. conf.int level confidence limits, e.g. 90 95%. transitions multi-state data, total number     transitions type. na.action returned value na.action function, .  used      printout curve, e.g., number observations deleted due      missing values. call image call produced object. type type survival censoring. influence.p, influence.c optional influence     matrices pstate (surv)     cumhaz estimates.     list one element per stratum,     element list array indexed subject, time, state. version version object.  missing, 2, 3","code":""},{"path":"/reference/survfit.object.html","id":"subscripts","dir":"Reference","previous_headings":"","what":"Subscripts","title":"Survival Curve Object — survfit.object","text":"Survfit objects can subscripted.  often used plot subset curves, instance. user's point view survfit object appears vector, matrix, array curves. first dimension always underlying number curves ``strata''; multi-state models state always last dimension. Predicted curves Cox model can second dimension number different covariate prediction vectors.","code":""},{"path":"/reference/survfit.object.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Survival Curve Object — survfit.object","text":"survfit object evolved time: first created thought multi-state models instance.  evolution almost entirely accomplished addition new elements. One change survival version 3 addition survfitconf routine compute confidence intervals survfit object. allows computation CI intervals deferred later, desired, rather making permanent part object. Later iterations base routines may omit confidence intervals. survfit object starts first observation time, survival curves normally plotted time 0. helper routine survfit0 can used add first time point align data.","code":""},{"path":[]},{"path":"/reference/survfit0.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert the format of a survfit object. — survfit0","title":"Convert the format of a survfit object. — survfit0","text":"Add point starting time (time 0) survfit object's   elements.  useful plotting.","code":""},{"path":"/reference/survfit0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert the format of a survfit object. — survfit0","text":"","code":"survfit0(x, start.time=0)"},{"path":"/reference/survfit0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert the format of a survfit object. — survfit0","text":"x survfit object start.time desired starting time; see details .","code":""},{"path":"/reference/survfit0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert the format of a survfit object. — survfit0","text":"reformulated version object initial data point   start.time added.    time, surv, pstate, cumhaz,  std.err, std.cumhaz components aligned,   make plots summaries easier produce.","code":""},{"path":"/reference/survfit0.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert the format of a survfit object. — survfit0","text":"Survival curves traditionally plotted forward time 0,   since true starting time known part data,   survfit routine include time 0 value   resulting object.   Someone might look cumulative mortgage defaults versus calendar   year, instance, `time' value Date object.   plotted curve probably start 0 = 1970/01/01.   Due uncertainty, decided include \"time 0\"   part survfit object.  original survfit call   included start.time argument, value course   retained. Whether (1989) decision wise   foolish, now far late change . (tried   trial, resulting 20 errors survival test suite.    extrapolate might break 1/2 - 2/3 CRAN packages   depend survival, made default.)   original survfit call   included start.time argument, value course   retained. One problem choice functions must choose   starting point, plots example.   utility function used plot.survfit   summary.survfit , adding new time point front   curve consistent way: optional argument survfit0   function first choice (supplied),   user's start.time present,   otherwise min(0, x$time).  resulting object   guarranteed work functions manipulate   survfit object subscripting, aggregation, pseudovalues,   etc. (remember 20 errors).  Rather intended penultimate   step, often creating plot.","code":""},{"path":"/reference/survfitcoxph.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"A direct interface to the `computational engine' of survfit.coxph — survfitcoxph.fit","title":"A direct interface to the `computational engine' of survfit.coxph — survfitcoxph.fit","text":"program mainly supplied allow packages invoke   survfit.coxph function `data' level rather `user' level.   checks input data provided, can lead   unexpected errors data wrong.","code":""},{"path":"/reference/survfitcoxph.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A direct interface to the `computational engine' of survfit.coxph — survfitcoxph.fit","text":"","code":"survfitcoxph.fit(y, x, wt, x2, risk, newrisk, strata, se.fit, survtype, vartype, varmat, id, y2, strata2, unlist=TRUE)"},{"path":"/reference/survfitcoxph.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A direct interface to the `computational engine' of survfit.coxph — survfitcoxph.fit","text":"y response variable used Cox model.  (Missing values     removed course.) x covariate matrix used Cox model wt weight vector Cox model. model unweighted   use vector 1s. x2 matrix describing hypothetical subjects     curve desired.  Must number columns x. risk risk score exp(X beta) fitted Cox model.   model offset, include argument exp. newrisk risk scores hypothetical subjects strata strata variable used Cox model. factor. se.fit TRUE standard errors curve(s) returned survtype 1=Kalbfleisch-Prentice, 2=Nelson-Aalen, 3=Efron.      usual match approximation ties used     coxph model: KP `exact', N-`breslow' Efron `efron'. vartype 1=Greenwood, 2=Aalen, 3=Efron varmat variance matrix coefficients id optional; present NULL     vector identifiers length nrow(x2).     mon-null value signifies x2 contains time dependent     covariates, case identifies rows x2 go     subject. y2 survival times, time dependent prediction.  gives     time range (time1,time2] row x2.  Note:     must Surv object thus contains status indicator,     never used routine, however. strata2 vector strata indicators x2.  must     factor. unlist FALSE result list one     element strata.  Otherwise strata ``unpacked''     form found survfit object.","code":""},{"path":"/reference/survfitcoxph.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A direct interface to the `computational engine' of survfit.coxph — survfitcoxph.fit","text":"list containing nearly components survfit object.  missing add confidence intervals,   type original model's response (coxph object),   class.","code":""},{"path":"/reference/survfitcoxph.fit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"A direct interface to the `computational engine' of survfit.coxph — survfitcoxph.fit","text":"source code function   survfit.coxph written using noweb.  complete   documentation see inst/sourcecode.pdf file.","code":""},{"path":"/reference/survfitcoxph.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A direct interface to the `computational engine' of survfit.coxph — survfitcoxph.fit","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/survival-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated functions in package survival — survival-deprecated","title":"Deprecated functions in package survival — survival-deprecated","text":"functions temporarily retained compatability older programs,   may transition defunct status.","code":""},{"path":"/reference/survival-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated functions in package survival — survival-deprecated","text":"","code":"survConcordance(formula, data, weights, subset, na.action) # use concordance survConcordance.fit(y, x, strata, weight)    # use concordancefit"},{"path":"/reference/survival-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated functions in package survival — survival-deprecated","text":"formula formula object, response left ~ operator,      terms right.  response must survival object      returned Surv function. data data frame weights,subset,na.action coxph x, y, strata, weight predictor, response, strata, weight   vectors direct call","code":""},{"path":[]},{"path":"/reference/survival-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal survival functions — survival-internal","title":"Internal survival functions — survival-internal","text":"Internal survival functions","code":""},{"path":"/reference/survival-internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal survival functions — survival-internal","text":"","code":"survreg.fit(x, y, weights, offset, init, controlvals, dist, scale = 0,     nstrat = 1, strata, parms = NULL,assign) survpenal.fit(x, y, weights, offset, init, controlvals, dist, scale = 0,     nstrat = 1, strata, pcols, pattr, assign, parms = NULL) survdiff.fit(y, x, strat, rho = 0) match.ratetable(R, ratetable) # S3 method for ratetable as.matrix(x, ...) # S3 method for coxph.penalty is.na(x) coxpenal.df(hmat, hinv, fdiag, assign.list, ptype, nvar, pen1,     pen2, sparse) coxpenal.fit(x, y, strata, offset, init, control, weights, method,     rownames, pcols, pattr, assign, nocenter) coxph.wtest(var, b, toler.chol = 1e-09) agexact.fit(x, y, strata, offset, init, control, weights, method,     rownames, resid=TRUE, nocenter=NULL)  survfitCI(X, Y, weights,  id, cluster, robust, istate,                        stype=1, ctype=1,                         se.fit=TRUE,                        conf.int= .95,                        conf.type=c('log',  'log-log',  'plain', 'none',                                    'logit', 'arcsin'),                        conf.lower=c('usual', 'peto', 'modified'),                        influence=FALSE, start.time, p0, type) survfitKM(x, y, weights=rep(1,length(x)),                        stype=1, ctype=1,                         se.fit=TRUE,                        conf.int= .95,                        conf.type=c('log',  'log-log',  'plain', 'none',                                    'logit', 'arcsin'),                        conf.lower=c('usual', 'peto', 'modified'),                        start.time, id, cluster, robust,                        influence=FALSE, type)  survfitTurnbull(x, y, weights,                        type=c('kaplan-meier', 'fleming-harrington', 'fh2'),                        error=c('greenwood', \"tsiatis\"), se.fit=TRUE,                        conf.int= .95,                        conf.type=c('log',  'log-log',  'plain', 'none',                                    'logit', 'arcsin'),                        conf.lower=c('usual', 'peto', 'modified'),                        start.time, robust, cluster)"},{"path":"/reference/survival-internal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal survival functions — survival-internal","text":"arguments routines guaranteed stay release release -- call risk!","code":""},{"path":"/reference/Survmethods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for Surv objects — Surv-methods","title":"Methods for Surv objects — Surv-methods","text":"list methods apply Surv objects","code":""},{"path":"/reference/Survmethods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for Surv objects — Surv-methods","text":"","code":"# S3 method for Surv anyDuplicated(x, ...)     # S3 method for Surv as.character(x, ...)     # S3 method for Surv as.data.frame(x, ...)     # S3 method for Surv as.integer(x, ...)     # S3 method for Surv as.matrix(x, ...)     # S3 method for Surv as.numeric(x, ...)     # S3 method for Surv c(...)     # S3 method for Surv duplicated(x, ...)     # S3 method for Surv format(x, ...)     # S3 method for Surv head(x, ...)     # S3 method for Surv is.na(x)     # S3 method for Surv length(x)     # S3 method for Surv mean(x, ...)     # S3 method for Surv median(x, na.rm=FALSE, ...)     # S3 method for Surv names(x)     # S3 method for Surv names(x) <- value     # S3 method for Surv quantile(x, probs, na.rm=FALSE, ...)     # S3 method for Surv plot(x, ...)     # S3 method for Surv rep(x, ...)     # S3 method for Surv rep.int(x, ...)     # S3 method for Surv rep_len(x, ...)     # S3 method for Surv rev(x)     # S3 method for Surv t(x)     # S3 method for Surv tail(x, ...)     # S3 method for Surv unique(x, ...)"},{"path":"/reference/Survmethods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for Surv objects — Surv-methods","text":"x Surv object probs vector probabilities na.rm remove missing values calculation value character vector length x,     NULL ... arguments method","code":""},{"path":"/reference/Survmethods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for Surv objects — Surv-methods","text":"functions extend standard methods Surv objects.    arguments results mostly expected,    following details: .character function uses \"5+\" right censored      time 5, \"5-\" left censored time 5, \"[2,7]\"      observation interval censored 2 7,      \"(1,6]\" counting process data denoting observation      risk time 1 6, event time 6,      \"(1,6+]\" observation interval ending      event.      multi-state survival object type event appended      event time using \":type\". print format methods make use      .character. .numeric .integer methods perform      actions survival times, affect      censoring indicator. .matrix t methods return matrix length Surv object number      survival times contains, number items required      encode , e.g., x <- Surv(1:4, 5:9, c(1,0,1,0)); length(x)      value 4.      Likewise names(x) NULL vector length 4.      (technical reasons, names actually stored      rownames attribute object.) multi-state survival object levels returns      names endpoints, otherwise NULL. median, quantile plot methods      first construct survival curve using survfit, apply      appropriate method curve. concatonation method c() asymmetric, first      argument determines exection path.  instance      c(Surv(1:4), Surv(5:6)) concatonate two objects,      c(Surv(1:4), 5:6) give error,      c(5:6, Surv(1:4)) equivalent      c(5:6, .vector(Surv(1:4))).","code":""},{"path":[]},{"path":"/reference/survobrien.html","id":null,"dir":"Reference","previous_headings":"","what":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","title":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","text":"Peter O'Brien's test association single variable survival  test proposed Biometrics, June 1978.","code":""},{"path":"/reference/survobrien.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","text":"","code":"survobrien(formula, data, subset, na.action, transform)"},{"path":"/reference/survobrien.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","text":"formula valid formula cox model. data data.frame interpret variables named      formula, subset weights     argument. subset expression indicating subset rows data used      fit.    observations included default. na.action missing-data filter function.  applied model.frame          subset argument used.  Default options()\\$na.action. transform transformation function applied   time point. default O'Brien's suggestion logit(tr)   tr = (rank(x)- 1/2)/ length(x) rank shifted range   0-1 logit(x) = log(x/(1-x)) logit transform.","code":""},{"path":"/reference/survobrien.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","text":"new data frame.  response variables column names   returned Surv function, .e., \"time\" \"status\"   simple survival data, \"start\", \"stop\", \"status\" counting   process data.  individual event time identified   value variable .strata..  variables retain   original names.  predictor variable factor protected (),  retained .  predictor variables replaced  time-dependent logit scores. new data frame many  rows original data, approximately original number rows * number deaths/2.","code":""},{"path":"/reference/survobrien.html","id":"method","dir":"Reference","previous_headings":"","what":"Method","title":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","text":"time-dependent cox model can now fit new data.  univariate statistic, originally proposed, equivalent  single variable score tests time-dependent model.  equivalence rationale using time dependent model  multivariate extension original paper. O'Brien's method, x variables re-ranked death time.   simpler method, proposed Prentice, ranks data  start. results usually similar.","code":""},{"path":"/reference/survobrien.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","text":"O'Brien, Peter, \"Nonparametric Test Association Censored Data\",  Biometrics 34: 243-250, 1978.","code":""},{"path":"/reference/survobrien.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","text":"prior version routine returned new time variables rather   strata.  Unfortunately, strategy work original   formula strata statement.  new data set   size, coxph routine process slightly faster.","code":""},{"path":[]},{"path":"/reference/survobrien.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"O'Brien's Test for Association of a Single Variable with Survival — survobrien","text":"","code":"xx <- survobrien(Surv(futime, fustat) ~ age + factor(rx) + I(ecog.ps),               data=ovarian)  coxph(Surv(time, status) ~ age + strata(.strata.), data=xx)  #> Call: #> coxph(formula = Surv(time, status) ~ age + strata(.strata.),  #>     data = xx) #>  #>       coef exp(coef) se(coef)     z       p #> age 0.5681    1.7649   0.1816 3.128 0.00176 #>  #> Likelihood ratio test=10.55  on 1 df, p=0.001165 #> n= 230, number of events= 12"},{"path":"/reference/survreg.control.html","id":null,"dir":"Reference","previous_headings":"","what":"Package options for survreg and coxph — survreg.control","title":"Package options for survreg and coxph — survreg.control","text":"functions checks packages fitting options  survreg","code":""},{"path":"/reference/survreg.control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Package options for survreg and coxph — survreg.control","text":"","code":"survreg.control(maxiter=30, rel.tolerance=1e-09,  toler.chol=1e-10, iter.max, debug=0, outer.max=10)"},{"path":"/reference/survreg.control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Package options for survreg and coxph — survreg.control","text":"maxiter maximum number iterations rel.tolerance relative tolerance declare convergence toler.chol Tolerance declare Cholesky decomposition singular iter.max maxiter debug print debugging information outer.max maximum number outer iterations choosing     penalty parameters","code":""},{"path":"/reference/survreg.control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Package options for survreg and coxph — survreg.control","text":"list elements input","code":""},{"path":[]},{"path":"/reference/survreg.distributions.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Survival Distributions — survreg.distributions","title":"Parametric Survival Distributions — survreg.distributions","text":"List distributions accelerated failure models.   location-scale families transformation time. entry   describes  cdf \\(F\\) density \\(f\\) canonical member   family.","code":""},{"path":"/reference/survreg.distributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric Survival Distributions — survreg.distributions","text":"","code":"survreg.distributions"},{"path":"/reference/survreg.distributions.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Parametric Survival Distributions — survreg.distributions","text":"two basic formats, first defines distribution de novo, second defines new distribution terms old one. define one distribution terms another","code":""},{"path":"/reference/survreg.distributions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric Survival Distributions — survreg.distributions","text":"four basic distributions:extreme, gaussian, logistic t. last three parametrised way distributions already present R. extreme value cdf $$F=1-e^{-e^t}.$$ logarithm survival time one first three distributions obtain respectively weibull, lognormal, loglogistic. location-scale parameterization Weibull distribution found survreg parameterization rweibull. predefined distributions defined terms . exponential rayleigh distributions Weibull distributions fixed scale 1 0.5 respectively, loggaussian synonym lognormal. speed parts three commonly used distributions hardcoded C; reason elements survreg.distributions names \"Extreme value\", \"Logistic\" \"Gaussian\" modified.  (order list important, recognition name.) alternative modifying survreg.distributions new distribution can specified separate list. preferred method addition illustrated .","code":""},{"path":[]},{"path":"/reference/survreg.distributions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric Survival Distributions — survreg.distributions","text":"","code":"# time transformation survreg(Surv(time, status) ~ ph.ecog + sex, dist='weibull', data=lung) #> Call: #> survreg(formula = Surv(time, status) ~ ph.ecog + sex, data = lung,  #>     dist = \"weibull\") #>  #> Coefficients: #> (Intercept)     ph.ecog         sex  #>   5.8195907  -0.3557319   0.4013684  #>  #> Scale= 0.7310495  #>  #> Loglik(model)= -1133.1   Loglik(intercept only)= -1147.4 #> \tChisq= 28.73 on 2 degrees of freedom, p= 5.76e-07  #> n=227 (1 observation deleted due to missingness) # change the transformation to work in years # intercept changes by log(365), everything else stays the same my.weibull <- survreg.distributions$weibull my.weibull$trans <- function(y) log(y/365) my.weibull$itrans <- function(y) 365*exp(y) survreg(Surv(time, status) ~ ph.ecog + sex, lung, dist=my.weibull) #> Call: #> survreg(formula = Surv(time, status) ~ ph.ecog + sex, data = lung,  #>     dist = my.weibull) #>  #> Coefficients: #> (Intercept)     ph.ecog         sex  #> -0.08030664 -0.35573188  0.40136844  #>  #> Scale= 0.7310495  #>  #> Loglik(model)= -1133.1   Loglik(intercept only)= -1147.4 #> \tChisq= 28.73 on 2 degrees of freedom, p= 5.76e-07  #> n=227 (1 observation deleted due to missingness)  # Weibull parametrisation y<-rweibull(1000, shape=2, scale=5) survreg(Surv(y)~1, dist=\"weibull\") #> Call: #> survreg(formula = Surv(y) ~ 1, dist = \"weibull\") #>  #> Coefficients: #> (Intercept)  #>    1.616131  #>  #> Scale= 0.5009065  #>  #> Loglik(model)= -2212.3   Loglik(intercept only)= -2212.3 #> n= 1000  # survreg scale parameter maps to 1/shape, linear predictor to log(scale)  # Cauchy fit mycauchy <- list(name='Cauchy',                  init= function(x, weights, ...)                        c(median(x), mad(x)),                  density= function(x, parms) {                       temp <- 1/(1 + x^2)                       cbind(.5 + atan(x)/pi, .5+ atan(-x)/pi,                             temp/pi, -2 *x*temp, 2*temp*(4*x^2*temp -1))                       },                  quantile= function(p, parms) tan((p-.5)*pi),                  deviance= function(...) stop('deviance residuals not defined')                  ) survreg(Surv(log(time), status) ~ ph.ecog + sex, lung, dist=mycauchy) #> Call: #> survreg(formula = Surv(log(time), status) ~ ph.ecog + sex, data = lung,  #>     dist = mycauchy) #>  #> Coefficients: #> (Intercept)     ph.ecog         sex  #>   5.4517240  -0.3979387   0.4692383  #>  #> Scale= 0.4788955  #>  #> Loglik(model)= -274.6   Loglik(intercept only)= -294.9 #> \tChisq= 40.75 on 2 degrees of freedom, p= 1.42e-09  #> n=227 (1 observation deleted due to missingness)"},{"path":"/reference/survreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression for a Parametric Survival Model — survreg","title":"Regression for a Parametric Survival Model — survreg","text":"Fit parametric survival regression model. location-scale models arbitrary transform time variable; common cases use log transformation, leading accelerated failure time models.","code":""},{"path":"/reference/survreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression for a Parametric Survival Model — survreg","text":"","code":"survreg(formula, data, weights, subset,          na.action, dist=\"weibull\", init=NULL, scale=0,          control,parms=NULL,model=FALSE, x=FALSE,         y=TRUE, robust=FALSE, cluster, score=FALSE, ...)"},{"path":"/reference/survreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression for a Parametric Survival Model — survreg","text":"formula formula expression regression models.  response usually survival object returned Surv function.  See documentation Surv, lm formula details. data data frame interpret variables named  formula, weights subset arguments. weights optional vector case weights subset subset observations used fit na.action missing-data filter function, applied model.frame,  subset argument used.  Default options()\\$na.action. dist assumed distribution y variable.  argument character string, assumed name element survreg.distributions. include \"weibull\", \"exponential\", \"gaussian\", \"logistic\",\"lognormal\" \"loglogistic\". Otherwise, assumed user defined list conforming format described survreg.distributions. parms list fixed parameters.  t-distribution instance degrees freedom; distributions parameters. init optional vector initial values parameters. scale optional fixed value scale.  set <=0 scale estimated. control list control values, format produced survreg.control. default value survreg.control() model,x,y flags control returned.  true, model frame, model matrix, /vector response times returned components final result, names flag arguments. score return score vector. (expected zero upon successful convergence.) robust Use robust sandwich error instead asymptotic   formula.  Defaults TRUE cluster argument. cluster Optional variable identifies groups subjects,   used computing robust variance.  Like model variables,   searched dataset pointed data   argument. ... arguments passed survreg.control.","code":""},{"path":"/reference/survreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regression for a Parametric Survival Model — survreg","text":"object class survreg returned.","code":""},{"path":"/reference/survreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regression for a Parametric Survival Model — survreg","text":"distributions cast location-scale framework, based   chapter 2.2 Kalbfleisch Prentice.  resulting   parameterization distributions sometimes (e.g. gaussian)   identical usual form found statistics textbooks,   times (e.g. Weibull) .  See book detailed formulas. using weights aware difference replication   weights sampling weights.  former, weight '2' means   two identical observations, combined   single row data.  sampling weights single   observed value, weight used achieve balance respect   population.  get proper variance replication weights use   default variance, sampling weights use robust variance.   Replication weights common (computer memory much   smaller) now rare.","code":""},{"path":[]},{"path":"/reference/survreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regression for a Parametric Survival Model — survreg","text":"Kalbfleisch, J. D. Prentice, R. L., statistical analysis   failure time data, Wiley, 2002.","code":""},{"path":"/reference/survreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression for a Parametric Survival Model — survreg","text":"","code":"# Fit an exponential model: the two fits are the same survreg(Surv(futime, fustat) ~ ecog.ps + rx, ovarian, dist='weibull',                                     scale=1) #> Call: #> survreg(formula = Surv(futime, fustat) ~ ecog.ps + rx, data = ovarian,  #>     dist = \"weibull\", scale = 1) #>  #> Coefficients: #> (Intercept)     ecog.ps          rx  #>   6.9618376  -0.4331347   0.5815027  #>  #> Scale fixed at 1  #>  #> Loglik(model)= -97.2   Loglik(intercept only)= -98 #> \tChisq= 1.67 on 2 degrees of freedom, p= 0.434  #> n= 26  survreg(Surv(futime, fustat) ~ ecog.ps + rx, ovarian,         dist=\"exponential\") #> Call: #> survreg(formula = Surv(futime, fustat) ~ ecog.ps + rx, data = ovarian,  #>     dist = \"exponential\") #>  #> Coefficients: #> (Intercept)     ecog.ps          rx  #>   6.9618376  -0.4331347   0.5815027  #>  #> Scale fixed at 1  #>  #> Loglik(model)= -97.2   Loglik(intercept only)= -98 #> \tChisq= 1.67 on 2 degrees of freedom, p= 0.434  #> n= 26   # # A model with different baseline survival shapes for two groups, i.e., #   two different scale parameters survreg(Surv(time, status) ~ ph.ecog + age + strata(sex), lung) #> Call: #> survreg(formula = Surv(time, status) ~ ph.ecog + age + strata(sex),  #>     data = lung) #>  #> Coefficients: #> (Intercept)     ph.ecog         age  #>  6.73234505 -0.32443043 -0.00580889  #>  #> Scale: #>     sex=1     sex=2  #> 0.7834211 0.6547830  #>  #> Loglik(model)= -1137.3   Loglik(intercept only)= -1146.2 #> \tChisq= 17.8 on 2 degrees of freedom, p= 0.000137  #> n=227 (1 observation deleted due to missingness)  # There are multiple ways to parameterize a Weibull distribution. The survreg  # function embeds it in a general location-scale family, which is a  # different parameterization than the rweibull function, and often leads # to confusion. #   survreg's scale  =    1/(rweibull shape) #   survreg's intercept = log(rweibull scale) #   For the log-likelihood all parameterizations lead to the same value. y <- rweibull(1000, shape=2, scale=5) survreg(Surv(y)~1, dist=\"weibull\") #> Call: #> survreg(formula = Surv(y) ~ 1, dist = \"weibull\") #>  #> Coefficients: #> (Intercept)  #>    1.609913  #>  #> Scale= 0.5058801  #>  #> Loglik(model)= -2210   Loglik(intercept only)= -2210 #> n= 1000   # Economists fit a model called `tobit regression', which is a standard # linear regression with Gaussian errors, and left censored data. tobinfit <- survreg(Surv(durable, durable>0, type='left') ~ age + quant,               data=tobin, dist='gaussian')"},{"path":"/reference/survreg.object.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Survival Model Object — survreg.object","title":"Parametric Survival Model Object — survreg.object","text":"class objects returned survreg function represent fitted parametric survival model. Objects class methods functions print, summary, predict, residuals.","code":""},{"path":"/reference/survreg.object.html","id":"components","dir":"Reference","previous_headings":"","what":"COMPONENTS","title":"Parametric Survival Model Object — survreg.object","text":"following components must included legitimate survreg object. coefficients coefficients linear.predictors, multiply      columns model     matrix.     include estimate error (sigma).     names coefficients names     single-degree--freedom effects (columns     model matrix).     model -determined     missing values coefficients corresponding non-estimable     coefficients. icoef coefficients baseline model, contain intercept     log(scale), multiple scale factors stratified model. var variance-covariance matrix parameters, including log(scale)     parameter(s). loglik vector length 2, containing log-likelihood baseline     full models. iter number iterations required linear.predictors linear predictor subject. df degrees freedom final model.  penalized model     vector one element per term. scale scale factor(s), length equal number strata. idf degrees freedom initial model. means vector column means coefficient matrix. dist distribution used fit. weights included weighted fit. object also following components found    model results (optional):   linear predictors, weights, x, y, model,    call, terms formula.   See lm.","code":""},{"path":[]},{"path":"/reference/survregDtest.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify a survreg distribution — survregDtest","title":"Verify a survreg distribution — survregDtest","text":"routine called survreg verify distribution object valid.","code":""},{"path":"/reference/survregDtest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify a survreg distribution — survregDtest","text":"","code":"survregDtest(dlist, verbose = F)"},{"path":"/reference/survregDtest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify a survreg distribution — survregDtest","text":"dlist list describing survival distribution verbose return simple TRUE/FALSE test validity (default), verbose description flaws.","code":""},{"path":"/reference/survregDtest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify a survreg distribution — survregDtest","text":"survreg function rejects user-supplied distribution invalid, routine tell .","code":""},{"path":"/reference/survregDtest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify a survreg distribution — survregDtest","text":"TRUE distribution object passes tests, either FALSE vector character strings .","code":""},{"path":"/reference/survregDtest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Verify a survreg distribution — survregDtest","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/survregDtest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify a survreg distribution — survregDtest","text":"","code":"# An invalid distribution (it should have \"init =\" on line 2) #  surveg would give an error message mycauchy <- list(name='Cauchy',                  init<- function(x, weights, ...)                        c(median(x), mad(x)),                  density= function(x, parms) {                       temp <- 1/(1 + x^2)                       cbind(.5 + atan(temp)/pi, .5+ atan(-temp)/pi,                             temp/pi, -2 *x*temp, 2*temp^2*(4*x^2*temp -1))                       },                  quantile= function(p, parms) tan((p-.5)*pi),                  deviance= function(...) stop('deviance residuals not defined')                  )  survregDtest(mycauchy, TRUE) #> [1] \"Missing or invalid init function\""},{"path":"/reference/survSplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Split a survival data set at specified times — survSplit","title":"Split a survival data set at specified times — survSplit","text":"Given survival data set set specified cut times, split   record multiple subrecords cut time.  new data   set `counting process' format, start time, stop   time, event status record.","code":""},{"path":"/reference/survSplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split a survival data set at specified times — survSplit","text":"","code":"survSplit(formula, data, subset, na.action=na.pass,             cut, start=\"tstart\", id, zero=0, episode,                               end=\"tstop\", event=\"event\")"},{"path":"/reference/survSplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split a survival data set at specified times — survSplit","text":"formula model formula data data frame subset, na.action rows data retained cut vector timepoints cut start character string name start time variable (    created needed) id character string name new id variable     create (optional).  can useful data set     already contain identifier. zero start already exist, time     original records start. episode character string name new episode     variable (optional) end character string name event time variable event character string name censoring indicator","code":""},{"path":"/reference/survSplit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split a survival data set at specified times — survSplit","text":"New, longer, data frame.","code":""},{"path":"/reference/survSplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split a survival data set at specified times — survSplit","text":"interval original data cut given points;   original row (15, 60] cut vector (10,30, 40)   resulting data set intervals (15,30], (30,40]   (40, 60]. row final data set lie completely within one   cut intervals. interval row output shown   episode variable, 1= less first cutpoint, 2=   first second, etc.   example values 2, 3, 4. routine called formula first   argument.    right hand side formula can used delimit variables   retained; normally one use  ~ .   shorthand retain .  routine   try retain variable names, e.g. Surv(adam, joe, fred)~.   result data set variable names   tstart, end, event options rather   defaults.  user specified values options   used present, course.   However, routine sophisticated;   substitution simple names.  call Surv(time, stat==2)   instance retain \"stat\" name event variable. Rows data missing time status copied across   unchanged, unless na.action argument changed default   value na.pass.  latter case row   missing variable removed, rarely   desired.","code":""},{"path":[]},{"path":"/reference/survSplit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split a survival data set at specified times — survSplit","text":"","code":"fit1 <- coxph(Surv(time, status) ~ karno + age + trt, veteran) plot(cox.zph(fit1)[1])  # a cox.zph plot of the data suggests that the effect of Karnofsky score #  begins to diminish by 60 days and has faded away by 120 days. # Fit a model with separate coefficients for the three intervals. # vet2 <- survSplit(Surv(time, status) ~., veteran,                    cut=c(60, 120), episode =\"timegroup\") fit2 <- coxph(Surv(tstart, time, status) ~ karno* strata(timegroup) +                 age + trt, data= vet2) c(overall= coef(fit1)[1],   t0_60  = coef(fit2)[1],   t60_120= sum(coef(fit2)[c(1,4)]),   t120   = sum(coef(fit2)[c(1,5)])) #> overall.karno   t0_60.karno       t60_120          t120  #>  -0.034443897  -0.049176157  -0.011031558  -0.007629841"},{"path":"/reference/tcut.html","id":null,"dir":"Reference","previous_headings":"","what":"Factors for person-year calculations — tcut","title":"Factors for person-year calculations — tcut","text":"Attaches categories person-year calculations variable without losing underlying continuous representation","code":""},{"path":"/reference/tcut.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Factors for person-year calculations — tcut","text":"","code":"tcut(x, breaks, labels, scale=1) # S3 method for tcut levels(x)"},{"path":"/reference/tcut.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Factors for person-year calculations — tcut","text":"x numeric/date variable breaks breaks categories, right-continuous labels labels categories scale Multiply x breaks .","code":""},{"path":"/reference/tcut.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Factors for person-year calculations — tcut","text":"object class tcut","code":""},{"path":[]},{"path":"/reference/tcut.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Factors for person-year calculations — tcut","text":"","code":"# For pyears, all time variable need to be on the same scale; but # futime is in months and age is in years test <- mgus2 test$years <- test$futime/30.5   # follow-up in years  # first grouping based on years from starting age (= current age) # second based on years since enrollment (all start at 0) test$agegrp <- tcut(test$age, c(0,60, 70, 80, 100),                       c(\"<=60\", \"60-70\", \"70-80\", \">80\")) test$fgrp  <- tcut(rep(0, nrow(test)), c(0, 1, 5, 10, 100),                    c(\"0-1yr\", \"1-5yr\", \"5-10yr\", \">10yr\"))  # death rates per 1000, by age group pfit1 <- pyears(Surv(years, death) ~ agegrp, scale =1000, data=test) round(pfit1$event/ pfit1$pyears)  #> agegrp #>  <=60 60-70 70-80   >80  #>    89   128   245   479   #death rates per 100, by follow-up year and age # there are excess deaths in the first year, within each age stratum pfit2 <- pyears(Surv(years, death) ~ fgrp + agegrp, scale =1000, data=test) round(pfit2$event/ pfit2$pyears)   #>         agegrp #> fgrp     <=60 60-70 70-80  >80 #>   0-1yr   139   137   234  437 #>   1-5yr    68   117   241  499 #>   5-10yr   91   145   300  476 #>   >10yr     0   424     0 2440"},{"path":"/reference/tmerge.html","id":null,"dir":"Reference","previous_headings":"","what":"Time based merge for survival data — tmerge","title":"Time based merge for survival data — tmerge","text":"common task survival analysis creation start,stop data   sets multiple intervals subject, along   covariate values apply interval.  function aids   creation data sets.","code":""},{"path":"/reference/tmerge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time based merge for survival data — tmerge","text":"","code":"tmerge(data1, data2,  id,..., tstart, tstop, options)"},{"path":"/reference/tmerge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time based merge for survival data — tmerge","text":"data1 primary data set, new variables /    observation added data2 second data set arguments     found id subject identifier ... operations add new variables intervals, see     tstart optional variable define valid time range     subject, used initial call tstop optional variable define valid time range     subject, used initial call options list options.  Valid ones idname, tstartname,     tstopname, delay, na.rm, tdcstart.  See explanation .","code":""},{"path":"/reference/tmerge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Time based merge for survival data — tmerge","text":"program often run multiple passes, first  defines basic structure, subsequent ones add new  variables structure.  complete explanation  routine works refer vignette time-dependent variables. 4 types operational arguments: time dependent covariate  (tdc), cumulative count (cumtdc), event (event) cumulative event  (cumevent).  Time dependent covariates change values event,  events outcomes. newname = tdc(y, x, init) new time dependent covariate      variable created.     argument y assumed    scale start end time, instance describes    occurrence \"condition\" time.    second argument x optional.  case    x missing count variable starts 0 subject    becomes 1 time event.    x present value time dependent covariate    initialized value init, present,    tdcstart option otherwise, updated    value x observation.    option na.rm=TRUE missing values x    first removed, .e., update create missing values.   newname = cumtdc(y,x, init) Similar tdc, except event    count accumulated time subject.  variable    x must numeric. newname = event(y,x) Mark event time y.    usual case x missing new 0/1 variable    similar 0/1 status variable survival time. newname = cumevent(y,x) Cumulative events. function adds three new variables output data set:  tstart, tstop, id.  options argument can used change names. , first call, id argument simple name, variable name used default idname option. data1 contains tstart variable used starting point created time intervals, otherwise initial interval id begin 0 default. lead invalid interval subsequent error say death time <= 0. na.rm option affects creation time-dependent covariates. data row data2 missing value variable ignored generate observation value NA?  default TRUE causes last non-missing value carried forward. delay option causes time-dependent covariate's new value delayed, see vignette example.","code":""},{"path":"/reference/tmerge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time based merge for survival data — tmerge","text":"data frame two extra attributes tm.retain  tcount.   first contains names key variables, names   correspond tdc event variables.   tcount variable contains counts match types.   New time values occur first interval subject   \"early\", last interval subject \"late\",   fall gap type \"gap\".    considered outside specified time frame   given subject.  event type discarded.   observation data2 whose identifier matches rows  data1 type \"missid\" also discarded.   time-dependent covariate value applied later intervals   generate new time point output. common type usually \"within\", corresponding   new times   fall inside existing interval cause split two.   Observations fall exactly edge interval within   (min, max] time subject counted   \"leading\" edge, \"trailing\" edge \"boundary\".   first corresponds instance   occurrence 17 someone intervals (0,15] (17, 35].   tdc time 17  affect interval   event 17 ignored.  event occurrence 15 count (0,15] interval.   last case main data set touching   intervals subject, e.g. (17, 28] (28,35] new occurrence   lands join.  Events go earlier interval counts   latter one.  last column shows number additions   id time point identical.   occurs, tdc event operators use   final value data (last edit wins), ignoring missing,   cumtdc cumevent operators add values. extra attributes ephemeral discarded   dataframe modified.  intentional, since   become invalid instance subset selected.","code":""},{"path":"/reference/tmerge.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Time based merge for survival data — tmerge","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/tmerge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time based merge for survival data — tmerge","text":"","code":"# The pbc data set contains baseline data and follow-up status # for a set of subjects with primary biliary cirrhosis, while the # pbcseq data set contains repeated laboratory values for those # subjects.   # The first data set contains data on 312 subjects in a clinical trial plus # 106 that agreed to be followed off protocol, the second data set has data # only on the trial subjects. temp <- subset(pbc, id <= 312, select=c(id:sex, stage)) # baseline data pbc2 <- tmerge(temp, temp, id=id, endpt = event(time, status)) pbc2 <- tmerge(pbc2, pbcseq, id=id, ascites = tdc(day, ascites),                bili = tdc(day, bili), albumin = tdc(day, albumin),                protime = tdc(day, protime), alk.phos = tdc(day, alk.phos))  fit <- coxph(Surv(tstart, tstop, endpt==2) ~ protime + log(bili), data=pbc2)"},{"path":"/reference/tobin.html","id":null,"dir":"Reference","previous_headings":"","what":"Tobin's Tobit data — tobin","title":"Tobin's Tobit data — tobin","text":"Economists fit parametric censored data model called   ‘tobit’.  data Tobin's original paper.","code":""},{"path":"/reference/tobin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tobin's Tobit data — tobin","text":"","code":"tobin data(tobin, package=\"survival\")"},{"path":"/reference/tobin.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Tobin's Tobit data — tobin","text":"data frame 20 observations following 3 variables. durable Durable goods purchase age Age years quant Liquidity ratio (x 1000)","code":""},{"path":"/reference/tobin.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Tobin's Tobit data — tobin","text":"J Tobin (1958),   Estimation relationships limited dependent variables.   Econometrica 26, 24--36.","code":""},{"path":"/reference/tobin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tobin's Tobit data — tobin","text":"","code":"tfit <- survreg(Surv(durable, durable>0, type='left') ~age + quant,                 data=tobin, dist='gaussian')  predict(tfit,type=\"response\") #>  [1] -3.04968679 -4.31254182 -0.54163315 -0.25607164 -1.85017727 -2.40987803 #>  [7] -3.50629220 -0.74041486 -4.05145594 -3.55880518 -0.32223237 -3.68044619 #> [13] -3.65997456 -2.63254564  0.22382063  0.02177674 -0.09571284 -3.17696755 #> [19] -0.61521215 -3.13913903"},{"path":"/reference/transplant.html","id":null,"dir":"Reference","previous_headings":"","what":"Liver transplant waiting list — transplant","title":"Liver transplant waiting list — transplant","text":"Subjects liver transplant waiting list 1990-1999,   disposition: received transplant, died waiting, withdrew   list, censored.","code":""},{"path":"/reference/transplant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Liver transplant waiting list — transplant","text":"","code":"transplant data(transplant, package=\"survival\")"},{"path":"/reference/transplant.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Liver transplant waiting list — transplant","text":"data frame 815 (transplant) observations   following 6 variables. age age addition waiting list sex m f abo blood type: , B, AB  O year year entered waiting list futime time entry final disposition event final disposition: censored,       death,       ltx withdraw","code":""},{"path":"/reference/transplant.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Liver transplant waiting list — transplant","text":"represents transplant experience particular region, time period liver transplant became much widely recognized viable treatment modality. number liver transplants rises period, number subjects added liver transplant waiting list grew much faster. Important questions addressed data change waiting time, waits, whether consequent increase deaths list. Blood type important consideration.  Donor livers subjects blood type O can used patients , B, AB 0 blood types, whereas AB liver can used AB recipient. Thus type O subjects waiting list disadvantage, since pool competitors larger type O donor livers. data historical interest provides useful example competing risks, little relevance current practice.  Liver allocation policies evolved now depend directly individual patient's risk need, assessments regularly updated patient waiting list. overall organ shortage remains acute, however. transplant data set version used early analysis, transplant2 several additions corrections, final data set matches paper.","code":""},{"path":"/reference/transplant.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Liver transplant waiting list — transplant","text":"Kim WR, Therneau TM, Benson JT, Kremers WK, Rosen CB, Gores GJ, Dickson  ER.   Deaths liver transplant waiting list: analysis competing risks.   Hepatology 2006 Feb; 43(2):345-51.","code":""},{"path":"/reference/transplant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Liver transplant waiting list — transplant","text":"","code":"#since event is a factor, survfit creates competing risk curves pfit <- survfit(Surv(futime, event) ~ abo, transplant) pfit[,2]  #time to liver transplant, by blood type #> Call: survfit(formula = Surv(futime, event) ~ abo, data = transplant) #>  #>                 n nevent   rmean* #> abo=A, death  325     21 164.9734 #> abo=B, death  103     10 202.4902 #> abo=AB, death  41      3 137.8293 #> abo=O, death  346     32 182.1075 #>    *restricted mean time in state (max time = 2055 ) plot(pfit[,2], mark.time=FALSE, col=1:4, lwd=2, xmax=735,        xscale=30.5, xlab=\"Months\", ylab=\"Fraction transplanted\",        xaxt = 'n') temp <- c(0, 6, 12, 18, 24) axis(1, temp*30.5, temp) legend(450, .35, levels(transplant$abo), lty=1, col=1:4, lwd=2)   # competing risks for type O plot(pfit[4,], xscale=30.5, xmax=735, col=1:3, lwd=2) legend(450, .4, c(\"Death\", \"Transpant\", \"Withdrawal\"), col=1:3, lwd=2)"},{"path":"/reference/udca.html","id":null,"dir":"Reference","previous_headings":"","what":"Data from a trial of usrodeoxycholic acid — udca","title":"Data from a trial of usrodeoxycholic acid — udca","text":"Data trial ursodeoxycholic acid (UDCA) patients primary   biliary cirrohosis (PBC).","code":""},{"path":"/reference/udca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data from a trial of usrodeoxycholic acid — udca","text":"","code":"udca udca2 data(udca, package=\"survival\")"},{"path":"/reference/udca.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data from a trial of usrodeoxycholic acid — udca","text":"data frame 170 observations following 15 variables. id subject identifier trt treatment 0=placebo, 1=UDCA entry.dt date entry study last.dt date last -study visit stage stage disease bili bilirubin value entry riskscore Mayo PBC risk score entry death.dt date death tx.dt date liver transplant hprogress.dt date histologic progression varices.dt appearance esphogeal varices ascites.dt appearance ascites enceph.dt appearance encephalopathy double.dt doubling initial bilirubin worsen.dt worsening symptoms two stages","code":""},{"path":"/reference/udca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data from a trial of usrodeoxycholic acid — udca","text":"data set used Therneau Grambsh.  udca1   data set contains baseline variables along time   first endpoint (death, transplant, ..., worsening).   udca2 data set treats endpoints parallel   events stratum .","code":""},{"path":"/reference/udca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data from a trial of usrodeoxycholic acid — udca","text":"T. M. Therneau P. M. Grambsch, Modeling survival data: extending Cox model.  Springer, 2000. K. D. Lindor, E. R. Dickson, W. P Baldus, R.. Jorgensen, J. Ludwig, P. . Murtaugh, J. M. Harrison, R. H. Weisner, M. L. Anderson, S. M. Lange, G. LeSage, S. S. Rossi . F. Hofman. Ursodeoxycholic acid treatment primary biliary cirrhosis. Gastroenterology, 106:1284-1290, 1994.","code":""},{"path":"/reference/udca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data from a trial of usrodeoxycholic acid — udca","text":"","code":"# values found in table 8.3 of the book fit1 <- coxph(Surv(futime, status) ~ trt + log(bili) + stage,           cluster =id , data=udca1) fit2 <- coxph(Surv(futime, status) ~ trt + log(bili) + stage +           strata(endpoint), cluster=id,  data=udca2)"},{"path":"/reference/untangle.specials.html","id":null,"dir":"Reference","previous_headings":"","what":"Help Process the `specials' Argument of the `terms' Function. — untangle.specials","title":"Help Process the `specials' Argument of the `terms' Function. — untangle.specials","text":"Given terms structure desired special name, returns index appropriate subscripting terms structure another appropriate data frame.","code":""},{"path":"/reference/untangle.specials.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Help Process the `specials' Argument of the `terms' Function. — untangle.specials","text":"","code":"untangle.specials(tt, special, order=1)"},{"path":"/reference/untangle.specials.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Help Process the `specials' Argument of the `terms' Function. — untangle.specials","text":"tt terms object. special name special function, presumably used terms object. order order desired terms.  set 2, interactions special function included.","code":""},{"path":"/reference/untangle.specials.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Help Process the `specials' Argument of the `terms' Function. — untangle.specials","text":"list two components: vars vector variable names, found data frame, specials. terms numeric vector, suitable subscripting terms structure, indexes terms expanded model formula involve special.","code":""},{"path":"/reference/untangle.specials.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Help Process the `specials' Argument of the `terms' Function. — untangle.specials","text":"","code":"formula <- Surv(tt,ss) ~ x + z*strata(id) tms <- terms(formula, specials=\"strata\") ## the specials attribute attr(tms, \"specials\") #> $strata #> [1] 4 #>  ## main effects  untangle.specials(tms, \"strata\") #> $vars #> [1] \"strata(id)\" #>  #> $tvar #> [1] 3 #>  #> $terms #> [1] 3 #>  ## and interactions untangle.specials(tms, \"strata\", order=1:2) #> $vars #> [1] \"strata(id)\" #>  #> $tvar #> [1] 3 #>  #> $terms #> [1] 3 4 #>"},{"path":"/reference/uspop2.html","id":null,"dir":"Reference","previous_headings":"","what":"Projected US Population — uspop2","title":"Projected US Population — uspop2","text":"US population age sex, 2000 2020","code":""},{"path":"/reference/uspop2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Projected US Population — uspop2","text":"data matrix dimensions age, sex, calendar year.   Age goes 0 100, value age 100 total   ages 100 greater.","code":""},{"path":"/reference/uspop2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Projected US Population — uspop2","text":"data often used \"standardized\" population   epidemiology studies.","code":""},{"path":"/reference/uspop2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Projected US Population — uspop2","text":"NP2008_D1:  Projected Population Single Year Age, Sex, Race, Hispanic  Origin United States: July 1, 2000 July 1, 2050, www.census.gov/population/projections.","code":""},{"path":[]},{"path":"/reference/uspop2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Projected US Population — uspop2","text":"","code":"us50 <- uspop2[51:101,, \"2000\"]  #US 2000 population, 50 and over age <- as.integer(dimnames(us50)[[1]]) smat <- model.matrix( ~ factor(floor(age/5)) -1) ustot <- t(smat) %*% us50  #totals by 5 year age groups temp <- c(50,55, 60, 65, 70, 75, 80, 85, 90, 95) dimnames(ustot) <- list(c(paste(temp, temp+4, sep=\"-\"), \"100+\"),                          c(\"male\", \"female\"))"},{"path":"/reference/vcov.coxph.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance-covariance matrix — vcov.coxph","title":"Variance-covariance matrix — vcov.coxph","text":"Extract return variance-covariance matrix.","code":""},{"path":"/reference/vcov.coxph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance-covariance matrix — vcov.coxph","text":"","code":"# S3 method for coxph vcov(object, complete=TRUE, ...) # S3 method for survreg vcov(object, complete=TRUE, ...)"},{"path":"/reference/vcov.coxph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance-covariance matrix — vcov.coxph","text":"object fitted model object complete logical indicating full variance-covariance     matrix returned.  effect     -determined fit coefficients undefined,     coef(object) contains corresponding NA values.     complete=TRUE returned matrix row/column     coefficient, FALSE contain rows/columns     corresponding non-missing coefficients.     coef() function simpilar complete argument. ... additional arguments method functions","code":""},{"path":"/reference/vcov.coxph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance-covariance matrix — vcov.coxph","text":"matrix","code":""},{"path":"/reference/vcov.coxph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variance-covariance matrix — vcov.coxph","text":"coxph survreg functions returned matrix particular generalized inverse:  row column corresponding NA coefficients zero.  side effect generalized cholesky decomposion used unerlying compuatation.","code":""},{"path":"/reference/veteran.html","id":null,"dir":"Reference","previous_headings":"","what":"Veterans' Administration Lung Cancer study — veteran","title":"Veterans' Administration Lung Cancer study — veteran","text":"Randomised trial two treatment regimens lung cancer.   standard survival analysis data set.","code":""},{"path":"/reference/veteran.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Veterans' Administration Lung Cancer study — veteran","text":"","code":"veteran data(cancer, package=\"survival\")"},{"path":[]},{"path":"/reference/veteran.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Veterans' Administration Lung Cancer study — veteran","text":"D Kalbfleisch RL Prentice (1980),   Statistical Analysis Failure Time Data.   Wiley, New York.","code":""},{"path":"/reference/xtfrm.Surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Sorting order for Surv objects — xtfrm.Surv","title":"Sorting order for Surv objects — xtfrm.Surv","text":"Sort survival objects partial order, one   used internally many calculations.","code":""},{"path":"/reference/xtfrm.Surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sorting order for Surv objects — xtfrm.Surv","text":"","code":"# S3 method for Surv xtfrm(x)"},{"path":"/reference/xtfrm.Surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sorting order for Surv objects — xtfrm.Surv","text":"x Surv object","code":""},{"path":"/reference/xtfrm.Surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sorting order for Surv objects — xtfrm.Surv","text":"creates partial ordering survival objects.   result sorted time order, tied pairs times right censored   events come observed events (censor death), left   censored events sorted observed events.   counting process data (tstart, tstop, status) ordering   stop time, status, start time, censoring last.   Interval censored data sorted using midpoint interval. xtfrm routine used internally order   sort, results carry routines.","code":""},{"path":"/reference/xtfrm.Surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sorting order for Surv objects — xtfrm.Surv","text":"vector integers sort order  x.","code":""},{"path":"/reference/xtfrm.Surv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sorting order for Surv objects — xtfrm.Surv","text":"Terry Therneau","code":""},{"path":[]},{"path":"/reference/xtfrm.Surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sorting order for Surv objects — xtfrm.Surv","text":"","code":"test <- c(Surv(c(10, 9,9, 8,8,8,7,5,5,4), rep(1:0, 5)), Surv(6.2, NA)) test #>  [1] 10.0   9.0+  9.0   8.0+  8.0   8.0+  7.0   5.0+  5.0   4.0+  6.2? sort(test) #>  [1]  4+  5   5+  7   8   8+  8+  9   9+ 10"},{"path":"/reference/yates.html","id":null,"dir":"Reference","previous_headings":"","what":"Population prediction — yates","title":"Population prediction — yates","text":"Compute population marginal means (PMM) model fit,   chosen population statistic.","code":""},{"path":"/reference/yates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Population prediction — yates","text":"","code":"yates(fit, term, population = c(\"data\", \"factorial\", \"sas\"), levels, test = c(\"global\", \"trend\", \"pairwise\"), predict = \"linear\", options, nsim = 200, method = c(\"direct\", \"sgtt\"))"},{"path":"/reference/yates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Population prediction — yates","text":"fit model fit.  Examples using lm, glm, coxph objects     given vignette. term term model whic evaluated.   can written character string formula. population population used adjusting     variables.  User can supply data frame select one     built choices.     argument also allows \"empirical\" \"yates\" aliases     data factorial, respectively, ignores case. levels optional, values term used. test test comparing population predictions. predict predict.  glm model might   'link' 'response'.  coxph model can linear, risk,   survival.  User written functions allowed. options optional arguments prediction method. nsim number simulations used compute variance   predictions.  needed linear predictor. method computational approach testing equality   population predictions.  Either direct approach algorithm   used SAS glim procedure \"type 3\" tests.","code":""},{"path":"/reference/yates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Population prediction — yates","text":"many options details function best described   vignette population prediction.","code":""},{"path":"/reference/yates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Population prediction — yates","text":"object class yates components estimate data frame one row level term,     columns containing level, mean population predicted     value (mppv) standard deviation. tests matrix giving test statistics mvar full variance-covariance matrix mppv values summary optional: summary values provided     prediction method.","code":""},{"path":"/reference/yates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Population prediction — yates","text":"Terry Therneau","code":""},{"path":"/reference/yates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Population prediction — yates","text":"","code":"fit1 <- lm(skips ~ Solder*Opening + Mask, data = solder) yates(fit1, ~Opening, population = \"factorial\") #>  Opening     pmm     std        test chisq df    ss      Pr #>        L  3.2638 0.33460      global 573.4  2 15980 < 1e-08 #>        M  3.5700 0.30480                                    #>        S 12.3519 0.31251                                     fit2 <- coxph(Surv(time, status) ~ factor(ph.ecog)*sex + age, lung) yates(fit2, ~ ph.ecog, predict=\"risk\")  # hazard ratio #>  factor(ph.ecog)     pmm     std                 test chisq df Pr #>                0 0.94238  0.4213      factor(ph.ecog)    NA NA NA #>                1 1.42677  0.7227                                  #>                2 1.74848  3.3454                                  #>                3      NA 17.4530"},{"path":"/reference/yates_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Method for adding new models to the yates function. — yates_setup","title":"Method for adding new models to the yates function. — yates_setup","text":"method called yates   function, order setup code handle particular   model type.  Methods glm, coxph, default part   survival package.","code":""},{"path":"/reference/yates_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Method for adding new models to the yates function. — yates_setup","text":"","code":"yates_setup(fit, ...)"},{"path":"/reference/yates_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Method for adding new models to the yates function. — yates_setup","text":"fit fitted model object ... optional arguments methods","code":""},{"path":"/reference/yates_setup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Method for adding new models to the yates function. — yates_setup","text":"predicted value linear predictor, function return NULL.  yates routine particularly efficient code case. Otherwise return prediction function list two elements containing prediction function summary function. prediction function passed linear predictor single argument return vector predicted values.","code":""},{"path":"/reference/yates_setup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Method for adding new models to the yates function. — yates_setup","text":"Terry Therneau","code":""},{"path":"/reference/yates_setup.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Method for adding new models to the yates function. — yates_setup","text":"See vignette population prediction details.","code":""},{"path":[]}]
